{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Jupyter4NFDI","text":"<p>Jupyter4NFDI is an interactive, browser-based platform designed to provide seamless access to multiple cloud resources. Whether you are working on large-scale simulations, machine learning models, or data analytics, Jupyter4NFDI gives you the flexibility to perform these tasks interactively through familiar Jupyter Notebooks. While in the current phase only a one system is available, we will increase the number of resource providers in the future.</p> <p>If you feel a feature is missing in Jupyter4NFDI, don't hesitate to reach out to us at <code>jupyter4nfdi at lists.nfdi.de</code>. We welcome your feedback to help expand the possibilities within Jupyter4NFDI.</p>"},{"location":"#exploring-jupyterhub-options-within-nfdi","title":"Exploring JupyterHub options within NFDI","text":"<p>Jupyter4NFDI provides a central JupyterHub instance accessible to everyone within the NFDI. Additionally, various consortia and partners host their own JupyterHubs tailored to meet the specific needs of their users, resources, or environments. These dedicated JupyterHubs are often optimized for and restricted to particular user groups. You can explore the other available JupyterHubs here.</p>"},{"location":"#why-use-jupyter4nfdi","title":"Why Use Jupyter4NFDI?","text":"<p>By using Jupyter4NFDI, you gain access to:</p>  1. Cloud Power in Your Browser <p>Jupyter4NFDI connects you to cloud resources, offering scalable computing power for your workflows, including smaller data analysis tasks, web applications, and development environments.</p>  2. Easy-to-Use Interface <p>The platform uses the popular Jupyter Notebook interface, making it easy for users of all skill levels to interact with powerful computational resources. You can run code, develop models, and perform analyses all from your web browser.</p>  3. Interactive Development <p>Develop and test code interactively with instant feedback, enabling fast iteration of data science workflows, simulations, and machine learning models. </p>  4. Use Custom Docker Images <p>Jupyter4NFDI supports custom Docker images, meaning you can define and use your own computing environment. This flexibility allows you to pre-install specific dependencies, configure your environment exactly as needed, and run reproducible computational workflows across multiple sessions.</p>  5. GitHub-Based Environment with Binder <p>Through repo2docker integration, Jupyter4NFDI allows you to use the mybinder.org infrastructure to build Docker images directly from your GitHub repositories. This feature enables you to turn a GitHub repo into a fully functional environment without manually building Docker images, making your code and environment highly portable and shareable.</p>  6. Access to Specialized Libraries and Tools <p>Jupyter4NFDI provides pre-configured environments with libraries optimized for cloud use cases, including scientific computing and machine learning tools such as TensorFlow, PyTorch, and more.</p>"},{"location":"#use-cases","title":"Use Cases","text":"<p>Jupyter4NFDI is ideal for:</p> <ul> <li>Machine Learning: Train machine learning models at scale using cloud resources.</li> <li>Data Science and Analytics: Analyze and visualize large datasets interactively, leveraging cloud resources depending on your requirements.</li> <li>Scientific Research: From bioinformatics to materials science, accelerate your research using cloud resources.</li> <li>Workshops and Training: Jupyter4NFDI is a great platform for hands-on workshops and training sessions. Instructors can create custom environments, share notebooks, and guide participants through interactive coding exercises on cloud infrastructure. This makes it ideal for educational and professional development settings.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To begin using Jupyter4NFDI, just follow these simple steps:</p> <ol> <li>Visit the website: Go to hub.nfdi-jupyter.de.</li> <li>Login: Authenticate via Helmholtz ID. More information here.</li> <li>Select a system: Choose between multiple Cloud resources.</li> <li>Start and have fun: Launch your Jupyter environment and start working on your projects, whether they involve data science, machine learning, simulations, or training workshops.</li> </ol> <p>Enjoy the power of cloud resources right from your browser!</p>"},{"location":"2fa/","title":"2-Factor authentication","text":"Introduction to 2-Factor Authentication Introduction <p>       2-Factor Authentication (2FA), sometimes referred to as two-factor verification, is a security method in which you provide two different authentication factors to identify yourself at login. This process is performed to better protect both your credentials and the resources that you can access.     </p> <p>       In the first login step, you start with the usual entry of a good password. The service then confirms the correctness of the password entered. This does not, however, lead directly to the desired entrance - but to a further barrier.     </p> <p>       The second login step prevents unauthorized third parties from gaining access to your account just because they might have stolen your password. A quite common 2nd-factor is a One-Time Password (OTP) generated by a so-called OTP-App you install and initialize once on one of your personal devices. This OTP-app then provides (in our case every 30 seconds) a new one-time password that needs to be entered on the login page.     </p> Basic Principle <p>       These two factors for authentication combine the building blocks knowledge and possession in the login procedure.     </p> <ul> <li>Knowledge - The secret knowledge is the password you enter.</li> <li>Possession - With the one-time password you show that you are in possession of a certain device (e.g., your smartphone), because only the OTP-App, installed on that device, can generate it.</li> </ul> <p>Source: Bundesamt f\u00fcr Sicherheit in der Informationstechnik</p> Algorithm <p>       The OTP-App can calculate personal one-time passwords completely autonomously from the outside world using a standardized and open algorithm for the generation of Time-based One-Time Passwords (TOTP).     </p> <p>       The TOTP algorithm was published in 2011 by the Internet Engineering Task Force (IETF) as RFC 6238. The TOTP algorithm is a hash function in which a secret code is hashed together with the current time.     </p> <p>       Behind the hash function is the HMAC-based One-time Password Algorithm according to RFC 4226 - in simple terms nothing more than a standard that forms a hash in a certain way.     </p> <p>       The calculation includes both a \"secret initialization code\", that is known to both the server and the client, and the current time. The final one-time password is generated from these two inputs and is valid for a certain period of time (in our case for 30 seconds). The procedure can be implemented in such a way that slight differences in time between client and server are accepted.     </p> <p>       Hence, any one-time password is time-based, calculated locally, and always unique.     </p> <p>Two-factor authentication is not implemented by Jupyter4NFDI or JSC-Login. Instead, you need to enable it in JuDoor (if you are logging in with a JSC account) or through the Helmholtz ID. Below, we will outline the activation process for both services.</p>"},{"location":"2fa/#setup","title":"Setup","text":"<p>2-Factor Authentication (2FA) better protects both your user credentials and the resources that you can access. JuDoor and Helmholtz ID both use the time-based One-Time Password (OTP) generated by an OTP-App as a 2nd factor.</p>"},{"location":"2fa/#install-an-otp-app","title":"Install an OTP-App","text":"<p>On one of your personal devices (e.g., your smartphone), install an OTP-App: - FreeOTP (iOS, Android) - KeeWeb (Linux, macOS, Windows, Online)  </p> More Apps. Free, but closed source: <ul> <li>Authy (iOS, Android, Windows, macOS, Linux)</li> <li>Protectimus Smart OTP (iOS, Android)</li> <li>Google Authenticator (iOS, Android )</li> <li>Microsoft Authenticator (iOS, Android, Windows 10 Mobile)</li> </ul>"},{"location":"2fa/#option-a-judoor","title":"Option A: JuDoor","text":"<ol> <li>Visit JuDoor and sign-in using your JSC account.</li> <li> <p>In the top right corner, open the dropdown menu and click on Account Security.  </p> </li> <li> <p>Click on Start MFA Setup...</p> </li> <li>Scan the QR Code (for OTP-App on phones), or enter the Secret into your installed OTP-App.</li> <li>Enter your current JSC account password into Current password for account1.</li> <li>Enter the current One-Time-Password (generated by your OTP-App) into the field below.</li> <li>DOWNLOAD AND PRINT THE SHOWN RESET CODES</li> </ol>"},{"location":"2fa/#option-b-helmholtz-id","title":"Option B: Helmholtz ID","text":"<ol> <li>Visit Helmholtz ID and sign-in using your home IdP.</li> <li> <p>Select Credentials in the left sidebar.  </p> </li> <li> <p>Activate Enable two-step authentication if possible </p> </li> <li> <p>Click Setup for One time password for second factor authentication </p> </li> <li> <p>Scan the QR Code (for OTP-App on phones), or click Can't scan the code and enter the secret into your installed OTP-App.</p> </li> <li>Enter the current One-Time-Password (generated by your OTP-App) and click on the checkmark.  </li> </ol>"},{"location":"2fa/#disable-2-factor-authentication","title":"Disable 2-Factor authentication","text":"<p>To disable 2FA you have to disable it at JuDoor / Helmholtz ID.</p>"},{"location":"2fa/#judoor","title":"JuDoor","text":"<ol> <li>Visit JuDoor and sign-in using your JSC account.</li> <li> <p>In the top right corner, open the dropdown menu and click on Account Security.  </p> </li> <li> <p>Click on Disable MFA...</p> </li> <li>Option A: Use second factor - requires your OTP-App.    Option B: Use reset code - requires your reset codes.</li> </ol>"},{"location":"2fa/#helmholtz-id","title":"Helmholtz ID","text":"<ol> <li>Visit Helmholtz ID and sign-in using your home IdP.</li> <li> <p>Select Credentials in the left sidebar.  </p> </li> <li> <p>Disable Enable two-step authentication if possible </p> </li> </ol> <p>You can disable 2FA on Helmholtz ID, but you cannot delete the secret yourself. For assistance with removal, please contact their support team ( support at hifis.net ).</p>"},{"location":"authentication/","title":"Jupyter4NFDI Login","text":"<p>Jupyter4NFDI relies on the Helmholtz ID system for user authentication.</p> <p>This federated login provides a wide selection of identity providers (IdPs), allowing users to log in with institutional credentials or social IdPs, like GitHub, Google or ORCID.</p> <p>A complete list of connected organizations is available here.</p> <p>Once IAM4NFDI is implemented, Jupyter4NFDI will switch to this as AAI solution.</p>"},{"location":"authentication/#1-visit-the-jupyter4nfdi-login-page","title":"1. Visit the Jupyter4NFDI Login Page","text":"<p>Go to hub.nfdi-jupyter.de and click the Sign In button.</p> <p>The web pages displayed during your initial registration may differ from the screenshots in this documentation. The registration process is handled by Helmholtz ID or the connected identity providers, so updates may change the appearance of these pages.</p>"},{"location":"authentication/#2-sign-via-home-idp-or-social-idp","title":"2. Sign via Home IdP or Social IdP","text":"<p>Choose the Identity Provider (IdP) you would like to use. Use the search field to find your provider and login using the credentials of your provider.</p> <p>If you encounter an error message after this step, it means that your Identity Provider (IdP) has not provided the necessary attributes to the Helmholtz ID. In this case, reach out to your IdP to request that they address the issue. If they need further assistance, they can contact the Helmholtz ID administrators directly.</p>"},{"location":"authentication/#register-at-helmholtz-id","title":"Register at Helmholtz ID","text":"If you're a first-time user of Helmholtz ID, you'll be prompted to register. Click to expand for more information.   Depending on the attributes sent by your Identity Provider to Helmholtz ID, you may need to provide additional information, such as your email address. You will also need to read and accept the Acceptable Use Policy.     Your registration request has been submitted. You will receive an email with a link that you need to click to confirm your email address.     After your account registration was successful you have to [login](#1-visit-the-Jupyter4NFDI-login-page) once more."},{"location":"authentication/#3-consent-confirmation","title":"3. Consent confirmation","text":"<p>You need to confirm that you agree to allow the Helmholtz ID service to use the information provided by the Identity Provider.</p> <p>The information displayed on this page is what Jupyter4NFDI will receive from the AAI. This data is used to determine your access to specific resources. If you need additional attributes to be sent to Jupyter4NFDI, please request your Identity Provider to follow the AARC-G002 guidelines and include the necessary information in the eduPersonEntitlement attribute.</p>"},{"location":"authentication/#faq","title":"FAQ","text":""},{"location":"authentication/#why-cant-i-change-the-account-in-helmholtz-id","title":"Why can't I change the account in Helmholtz ID","text":"<p>When you click on Logout in Jupyter4NFDI, you will be logged out from Jupyter4NFDI, but you will remain logged into the Helmholtz ID service. To log out from Helmholtz ID, please visit the Helmholtz ID website and click on Logout. Afterward, you will have the option to choose a different provider during the login process.</p>"},{"location":"authentication/#how-do-i-get-access-to-a-system","title":"How do I get access to a system","text":"<p>More information about access to the systems is documented here.</p>"},{"location":"features/","title":"Available Resources and Tools","text":"<p>Jupyter4NFDI provides a variety of options and features to enhance your interactive computing experience. Here\u2019s an overview of what you can expect:</p>"},{"location":"features/#1-systems-available","title":"1. Systems Available","text":""},{"location":"features/#cloud","title":"Cloud","text":"<p>deNBI-Cloud is accessible to everyone, providing flexible cloud resources. For users utilizing JSC-Cloud, we offer several resource configurations, including:</p> <ul> <li>2GB RAM, 1 CPU for 2 hours (mostly used for Repo2Docker shared sessions)</li> <li>2GB RAM, 1 CPU for 5 days</li> <li>4GB RAM, 1 CPU for 2 days</li> <li>8GB RAM, 2 CPUs for 10 hours</li> </ul> <p>JSC-Cloud is accessible to everyone, providing flexible cloud resources. For users utilizing JSC-Cloud, we offer several resource configurations, including:</p> <ul> <li>2GB RAM, 1 CPU for 7 days</li> <li>4GB RAM, 1 CPU for 2 days</li> <li>8GB RAM, 2 CPUs for 10 hours</li> </ul> <p>Please note that these flavors may change in the future and are dependent on the available resources.</p> <p>With deNBI-Cloud and JSC-Cloud, each user enjoys 25GB of persistent storage, allowing you to keep your important work safe and accessible. This feature is available not only in the default JupyterLab versions but also when using custom Docker images or Repo2Docker. Whether you're developing in a standard environment or tailoring your setup with your own images, you can rest assured that your data is securely stored and easily retrievable.</p> <p>We will add more systems to Jupyter4NFDI in the future. </p>"},{"location":"features/#2-different-jupyterlab-versions","title":"2. Different JupyterLab Versions","text":"<p>Jupyter4NFDI supports multiple versions of JupyterLab, allowing users to select the environment that best suits their needs. This flexibility ensures compatibility with various extensions and workflows.</p> <p>Currently available JupyterLab versions:</p> <ul> <li>JupyterLab - A default setup based on the official jupyter/minimal-notebook image.</li> <li>JupyterLab XL - A JupyterLab setup with multiple pre-installed kernels and environments. </li> <li>Custom Docker Image - Use your own docker image. More details in Custom Docker Images. <p>The mount path for your persistent storage is configurable. This flexibility ensures that the storage location does not interfere with the specific requirements of the Docker image you provide. You can easily adapt the mounting path to suit your environment, allowing for a seamless integration of your custom setup.</p> </li> <li>Repo2Docker ( Binder ) - Build docker images directly from GitHub, GitLab, Zenodo or other sources. More details in Repo2docker Integration.</li> </ul> <p>Explore these options to make the most out of your experience with Jupyter4NFDI, whether you are conducting research, teaching, or learning!</p>"},{"location":"imprint/","title":"Imprint","text":""},{"location":"imprint/#forschungszentrum-julich-gmbh","title":"Forschungszentrum J\u00fclich GmbH","text":"<p>Wilhelm-Johnen-Stra\u00dfe 52428 J\u00fclich</p> <p>Entered in the Commercial Register of the District Court of D\u00fcren, Germany: No. HR B 3498</p> <p>Value Added Tax ID No. in accordance with \u00a7 27 a of the German VAT Law (Umsatzsteuergesetz): DE 122624631 Tax No.: 213/5700/0033</p> <p>Board of Directors Prof. Dr. Astrid Lambrecht (Chair of the Board of Directors) Karsten Beneke (Vice-Chairman) Prof. Dr. Ir. Pieter Jansens</p> <p>Supervisory Board Ministerialdirektor Stefan M\u00fcller</p>"},{"location":"imprint/#contact","title":"Contact","text":"<p>General inquiries: +49 2461 61-0 General fax no.: +49 2461 61-8100 Internet: http://www.fz-juelich.de Email address: info@fz-juelich.de</p>"},{"location":"imprint/#copyright","title":"Copyright","text":"<p>Copyright and all other rights concerning this website are held by Forschungszentrum J\u00fclich GmbH. Use of the information contained on the website, including excerpts, is permitted for educational, scientific or private purposes, provided the source is quoted (unless otherwise expressly stated on the respective website). Use for commercial purposes is not permitted unless explicit permission has been granted by Forschungszentrum J\u00fclich.</p>"},{"location":"imprint/#disclaimer","title":"Disclaimer","text":"<p>Contents of this Website This website has been compiled with due diligence. However, Forschungszentrum J\u00fclich neither guarantees nor accepts liability for the information being continual up-to-date, complete or accurate.</p>"},{"location":"imprint/#links-to-external-websites","title":"Links to External Websites","text":"<p>This website may contain links to external third-party websites. These links to third party sites do not imply approval of their contents. Responsibility for the content of these websites lies solely with the respective provider or operator of the site. Illegal contents were not recognizable at the time of setting the link. We do not accept any liability for the continual accessibility or up-to- dateness, completeness or correctness of the contents of such websites. If we become aware of any infringements of the law, we will remove such links immediately.</p>"},{"location":"imprint/#data-protection","title":"Data protection","text":"<p>Every time a user accesses a website hosted by Forschungszentrum J\u00fclich GmbH and every time a file is requested, data connected to these processes are stored in a log. These data do not contain personal information; we are unable to trace which user accessed what information. Personal user profiles therefore cannot be created. The data that is saved and will be used for statistical purposes only. This information will not be disclosed to third parties.</p>"},{"location":"support/","title":"Support","text":""},{"location":"support/#email","title":"Email","text":"<p>Contact us at <code>jupyter4nfdi at lists.nfdi.de</code></p>"},{"location":"support/#technical-support","title":"Technical support","text":"<p>For technical support and feedback related to the JupyterHub, don't hesitate to contact us at <code>ds-support at fz-juelich.de</code>.  </p>"},{"location":"support/#chat-tools","title":"Chat Tools","text":"<p>NFDI Mattermost (Channel <code>#jupyter4nfdi</code>)</p>"},{"location":"workshops/","title":"Workshops","text":"<p>There are no special requirements to use Jupyter4NFDI for a workshop, you can simply use the platform as you normally would. Participants gain access by using one of the available authentication methods. In this section, we cover some best practices for workshops.</p> <p>If you plan to host a workshop, we kindly ask you to let us know in advance ( Contact ). This helps us take your event into account when scheduling maintenance and ensures a smooth experience for all participants.</p>"},{"location":"workshops/#motivation","title":"Motivation","text":"<p>Organizing workshops can be a complex task. Instructors must coordinate participant access, prepare materials such as presentations and Jupyter notebooks, and ensure that all components run reliably for every participant. Due to the wide range of options available when starting a service, users may inadvertently select incorrect configurations, such as the wrong system, kernel, or Docker image. These misconfigurations may not trigger immediate errors, but they can result in a non-functional or inconsistent runtime environment.</p> <p>To address these challenges and streamline the workshop experience, we offer the ability to create a dedicated Workshop Website. This site allows instructors to define a controlled environment for their workshop, which can then be shared with participants.</p>"},{"location":"workshops/#managing-workshops-for-instructors","title":"Managing Workshops (for Instructors)","text":""},{"location":"workshops/#available-options","title":"Available Options","text":"<p>As a workshop instructor, you may want to provide participants with a specific environment for your course. Depending on your needs, we offer three different ways to share your desired configuration:</p> <ol> <li> <p>Share Links: A fixed configuration shared via a link that cannot be changed afterward.  </p> <ul> <li>Pro: Secrets (such as credentials for a private Docker registry) remain hidden from participants.  </li> <li>Pro: Works with any type of configuration.  </li> <li>Contra: Any changes to the configuration require generating a new link.</li> </ul> </li> <li> <p>Repo2Docker Direct Links: Links that point directly to your Git repository.  </p> <ul> <li>Pro: Supports various external sources like Git repositories, Zenodo, and more (Repo2Docker).  </li> <li>Contra: Configuration changes may require a minor update to the link.  </li> <li>Contra: Only works with Repo2Docker.</li> </ul> </li> <li> <p>Workshop Configuration: A curated selection of allowed environments.  </p> <ul> <li>Pro: Define a controlled set of available options for your participants.  </li> <li>Pro: You can update the configurations at any time without changing the link.</li> </ul> </li> </ol>"},{"location":"workshops/#share-links","title":"Share Links","text":"<p>To use Share Links in your workshop, go to the Jupyter4NFDI service, log in, and configure the environment you want participants to use. Once everything is set up, click the Share button to generate a unique link, which you can then distribute to your participants.</p> <p>Keep in mind: if you make any changes to the configuration, a new share link will be generated. Be sure to share the updated link with your participants if any modifications are made.</p> <p>If a configuration includes secrets, they will remain hidden from other users. Instead of the actual values, participants will only see placeholders \u2014 but the original secrets entered when creating the share link will still be applied during startup.</p>"},{"location":"workshops/#repo2docker-direct-links","title":"Repo2Docker Direct Links","text":"<p>Repo2Docker Direct Links are a great option when you want to launch a specific Git repository \u2014 other sources like Zenodo are also supported. Simply place your notebooks and their dependencies into the repository (see the Repo2Docker / Binder Documentation) to define your custom environment. All required packages will be automatically installed.</p> <p>By using the <code>urlpath</code> or <code>labpath</code> query parameters, participants can jump directly into JupyterLab with the desired file already open.</p> <p>If you use <code>HEAD</code> as the reference, the Direct Link will always reflect the latest version of your repository. This makes it easy to update notebooks or dependencies without needing to change the link.</p>"},{"location":"workshops/#workshop-configuration","title":"Workshop Configuration","text":"<p>Instructors can visit the Workshop Manager Website to configure and manage their own workshops. This will create a subset of the available options in Jupyter4NFDI.</p> <p>https://hub.nfdi-jupyter.de/workshopmanager</p> <p>Each instructor can define a subset of configuration options that are permitted during the workshop. These settings are then made accessible to participants via a unique \"Workshop Link.\" You may edit your workshop configuration at any time. Clicking \"Create\" (or \"Share\" for existing workshops) will provide you with a personalized link to distribute.</p>"},{"location":"workshops/#workshop-id","title":"Workshop ID","text":"<p>By default, a randomly generated ID is assigned when a new workshop is created. This ID forms the URL for the workshop, such as:</p> <p>https://hub.nfdi-jupyter.de/workshops/id</p> <p>If you prefer a custom identifier (e.g., <code>myworkshop2025</code>), please contact support to enable this feature for your account.</p>"},{"location":"workshops/#description","title":"Description","text":"<p>Include a short description of your workshop. This will be displayed on the corresponding workshop page, helping users verify they are on the correct site.</p>"},{"location":"workshops/#configuration-options","title":"Configuration Options","text":"<p>Each available option includes a checkbox. If a checkbox is not selected, users will retain access to all available values for that option. To restrict user selection, ensure the checkbox is checked and specify the allowed values.</p>"},{"location":"workshops/#dropdown-menus","title":"Dropdown Menus","text":"<p>For dropdown selections, multiple values may be chosen using CTRL+Click or SHIFT+Click. At least one value must be selected for the configuration to be valid. If multiple values are selected, a default value can be specified.</p>"},{"location":"workshops/#input-fields","title":"Input Fields","text":"<p>Input fields can be used to enforce specific values (e.g., setting the runtime to 30 minutes or nodes to 1). If the checkbox next to an input field is selected, the defined value will be enforced. If the checkbox is left unchecked, users may input their own value when starting a service.</p>"},{"location":"workshops/#expert-mode","title":"Expert Mode","text":"<p>Instructors who are part of the Workshop Instructor group gain access to additional features, such as:</p> <ul> <li>Creating custom workshop IDs</li> <li>Activating Expert Mode during workshop creation</li> </ul> <p>Expert Mode enables the selection of multiple services and systems. However, this mode is disabled by default, as it introduces a higher risk of invalid configurations. For instance, selecting both JURECA and JUWELS as systems, but allowing only the partition <code>dc-cpu</code> (which is not available on JUWELS), will result in an unusable setup.</p> <p>To join the Workshop Instructor group contact support.</p>"},{"location":"workshops/#workshop-website","title":"Workshop Website","text":"<p>The workshop website will show the regular configuration interface. However, only the options pre-defined by the instructor will be available for selection.</p> <p>Having issues setting up your workshop? Feel free to contact us.</p>"},{"location":"hubs/","title":"Jupyter Services Overview","text":"<p>This site provides an overview of avaiable Jupyter Services for researchers in within Germany and within the NFDI. </p> <p>Please be aware that we do not offer support or have detailed information about the JupyterHub or Binder services listed. Access to these services may be restricted, and their environments are tailored to specific use cases. If you're unsure which JupyterHub to select, the Jupyter4NFDI instance serves as an excellent starting point.</p> <p>If your instance is missing, have a look at our contribution page. If you are interessted in current statistics, have a look here.</p> <p>Jupyter-Cloud</p> <p>Provider: GWDG <p>Target Group: Users having a full GWDG account (which can include people working in partner projects)</p>  Service Details  Login </p> <p>GESIS Notebooks</p> <p>Provider: GESIS \u2013 Leibniz Institute for the Social Sciences <p>Target Group: Open, with a focus on Computational Social Science</p>  Service Details  Login </p> <p>NFDI4Ing JupyterHub</p> <p>Provider: University of Stuttgart <p>Target Group: Researchers in Engineering</p>  Service Details  Login </p> <p>Jupyter4NFDI</p> <p>Provider: Juelich Supercomputing Centre <p>Target Group: Users within NFDI</p>  Service Details  Login </p> <p>HoreKa Jupyterhub</p> <p>Provider: Karlsruhe Institute of Technology <p>Target Group: Researchers, Users upon project application, Helmholtz users</p>  Service Details  Login </p> <p>PC\u00b2 JupyterHub</p> <p>Provider: Paderborn Center for Parallel Computing, University of Paderborn <p>Target Group: All users of a computing time project at PC\u00b2</p>  Service Details  Login </p> <p>SCC Jupyterhub</p> <p>Provider: GWDG <p>Target Group: Users with a full GWDG account (including people working in partner projects).</p>  Service Details  Login </p> <p>MPCDF JupyterHub</p> <p>Provider: Max Planck Computing and Data Facility <p>Target Group: Researchers of the Max Planck Society</p>  Service Details  Login </p> <p>RWTH HPC JupyterHub</p> <p>Provider: ITC RWTH Aachen University <p>Target Group: Researchers, RWTH Students/Employees/Guests, Juelich Members, Users sponsored by other Users, Users upon project application</p>  Service Details  Login </p> <p>Webbasiertes Data Science und Machine Learning mit Jupyter</p> <p>Provider: University of Leipzig <p>Target Group: Students and employees of University of Leipzig</p>  Service Details  Login </p> <p>University of M\u00fcnster JupyterHub</p> <p>Provider: University of M\u00fcnster <p>Target Group: Students and employees of University of M\u00fcnster, members of PUNCH4NFDI (soon)</p>  Service Details  Login </p> <p>Jupyter-JSC</p> <p>Provider: Juelich Supercomputing Centre <p>Target Group: HPC users of JSC. Helmholtz users in general</p>  Service Details  Login </p> <p>Interactive Tools of European Galaxy Server</p> <p>Provider: University of Freiburg <p>Target Group: Open for everyone</p>  Service Details  Login </p>"},{"location":"hubs/stats/","title":"Statistics about the Jupyter Services collected","text":"<p>Currently, 11 providers host 12 Jupyter services:</p> <p> Map of Jupyter Providers in Germany</p> <p>The following NFDI consortia contribute to one or more of the collected services:</p> <p> </p> <p> </p> <p> </p> <p> </p> <p>Curious about further statistics? Come back later - there's more to come!</p>"},{"location":"hubs/template/","title":"Join the list","text":"<p>To become part of the list of Jupyter services for German researchers you have to provide a yaml-file with the information listed in the table below.  You can check out existing yaml-files in the data folder. In the same folder there is also a template you can base on. To add a logo of your service provide one in the assets folder.  When everything is ready, please add a pull request to the main branch of this repository.  If you need further assistance or have other questions,  do not hesitate to open an issue.</p>"},{"location":"hubs/template/#template","title":"Template","text":"<pre><code># Service name. If too general, should include a provider or project context.\ntitle:\n# All service providers\nprovider:\n# Link address to the entrypoint for users\nservice_url:\n# If the service_url is not public available, the requirements to reach it\nservice_url_requirement:\n# Email address where to get help\nsupport:\n# Healthcheck URL\nhealth_api_url:\n# Service specific documentation for users\ndocumentation_url:\n# Roles, domain, NFDI consortia, University, etc.\ntarget_group_open_for:\n# Whether any researcher in Germany can use the service (true / false)\nrestricted:\n# How is the login performed; Login-URL\nlogin_process:\nfeatures: # What the service offers.\n  # version of JupyterHub; classic notebook or lab view?\n  version:\n  # List of supported programming languages (kernels)\n  programming_languages: []\n  # List of supported environments (e.g., Python virtualenv) configured as kernels\n  environments: []\n  # Link to information about the supported environments, if not included under documentation_url\n  environments_info:\n  # List of pre-installed JupyterHub extensions\n  extensions: []\n  # List of server-proxy featured applications\n  proxy_apps: []\n  # Whether it is allowed to install further packages, kernels, extensions (true / false)\n  install:\n  # Whether there is a folder to share documents with others (true / false)\n  shared_folder:\n  # Whether files can survive the docker session (true / false)\n  persistent_storage:\n  # List of other features you find relevant\n  misc: []\ntechnicals: # Information about the technology stack used\n  # The underlying system below JupyterHub, e.g., HPC, Openstack\n  platform:\n  # The way Jupyter is installed on the system, e.g., Docker, Kubernetes\n  deployment:\n  # Link to more (technical) information or a (Git) repository about the deployment or other administration tasks\n  deployment_url:\n  # List of required attributes, entitlements or memberships for login\n  login_attributes: []\n  # Where the resources (compute / storage) are located\n  hardware_location:\n  # List of other technicals you find relevant\n  misc: []\nresources: # Information about available resources on the instance\n  # Default number of Jupyter servers per user\n  default_server_user:\n  # Maximum number of Jupyter servers per user\n  max_server_user:\n  # Default number of CPU for a Jupyter server\n  default_cpu:\n  # Maximum number of CPU for a Jupyter server\n  max_cpu:\n  # Guarantied total number of CPUs for the whole Jupyterhub instance\n  total_cpu:\n  # Scaled total number of CPUs for the whole JupyterHub instance. Normally not exclusive, depends on other factors.\n  burst_total_cpu:\n  # Default CPU time for a Jupyter server\n  default_cpu_time:\n  # Maximum CPU time for a Jupyter server\n  max_cpu_time:\n  # Default amount of memory for a Jupyter server\n  default_memory:\n  # Maximum amount of memory for a Jupyter server\n  max_memory:\n  # Guarantied total amount of memory for the whole Jupyterhub instance\n  total_memory:\n  # Scaled total amount of memory for the whole JupyterHub instance. Normally not exclusive, depends on other factors.\n  burst_total_memory:\n  # Default number of GPU for a Jupyter server\n  default_gpu:\n  # Maximum number of GPU for a Jupyter server\n  max_gpu:\n  # Guarantied total number of GPUs for the whole Jupyterhub instance\n  total_gpu:\n  # Scaled total number of GPUs for the JupyterHub instance. Normally not exclusive, depends on other factors.\n  burst_total_gpu:\n  # Default amount of disk space (maybe temporary) for a Jupyter server\n  default_disk:\n  # Maximum amount of disk space (maybe temporary) for a Jupyter server\n  max_disk:\n  # Default amount of disk space that survives a Jupyter session\n  default_persistent_disk:\n  # Maximum amount of disk space that survives a Jupyter session\n  max_persistent_disk:\n  # Guarantied total amount of disk space for the whole Jupyterhub instance\n  total_disk:\n  # Scaled total amount of disk space for the whole JupyterHub instance. Normally not exclusive, depends on other factors.\n  burst_total_disk:\nusage: # Statistical information about the Jupyterhub instance\n  # Average number of Jupyter sessions per day\n  average_daily_sessions:\n</code></pre>"},{"location":"hubs/details/GESIS-Notebooks/","title":"GESIS Notebooks","text":"<p>The GESIS Notebooks can be reached here and is provided by GESIS \u2013 Leibniz Institute for the Social Sciences.</p>"},{"location":"hubs/details/GESIS-Notebooks/#short-facts","title":"Short Facts","text":"Service URL <p>http://notebooks.gesis.org</p> Target group <p>Open, with a focus on Computational Social Science</p> Login process <p>Open</p> Support <p>notebooks@gesis.org</p> Documentation <p>https://the-turing-way.netlify.app/communication/binder/zero-to-binder.html</p>"},{"location":"hubs/details/GESIS-Notebooks/#features","title":"Features","text":"<p>GESIS Notebooks offers:</p> GeneralKernelsExtensions <ul> <li> <p>Version(s): JupyterHub 3.0.0-beta.1, BinderHub</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> <li> <p>Part of the BinderHub Federation</p> </li> </ul> <p>Programming Languages:</p> <ul> <li>configurable by the user</li> </ul> <p>Environments:</p> <ul> <li>configurable by the user</li> </ul> <ul> <li>configurable by the user</li> </ul>"},{"location":"hubs/details/GESIS-Notebooks/#resources","title":"Resources","text":"<p>GESIS Notebooks provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 250 Number of CPUs 1 1 CPU time 20 min 6 h Amount of memory 2 GB 4 GB Number of GPUs 0 0 Disk space 10 GB 10 GB Persistent disk space 0 0"},{"location":"hubs/details/GESIS-Notebooks/#technicals","title":"Technicals","text":"<p>Some technical insights about GESIS Notebooks:</p>"},{"location":"hubs/details/RWTH-NFDI-Jupyter-Service/","title":"RWTH HPC JupyterHub","text":"<p>The RWTH HPC JupyterHub can be reached here and is provided by ITC RWTH Aachen University.</p>"},{"location":"hubs/details/RWTH-NFDI-Jupyter-Service/#short-facts","title":"Short Facts","text":"Service URL <p>https://jupyterhub.hpc.itc.rwth-aachen.de:9651/</p> Target group <p>Researchers, RWTH Students/Employees/Guests, Juelich Members, Users sponsored by other Users, Users upon project application</p> Login process <p>Login with RWTH HPC Account through most NHR or NRW VPNs</p> Support <p>servicedesk@itc.rwth-aachen.de</p> Documentation <p>https://help.itc.rwth-aachen.de/service/rhr4fjjutttf/article/689934fec5a34c909c54606f6bc2e827/</p>"},{"location":"hubs/details/RWTH-NFDI-Jupyter-Service/#features","title":"Features","text":"<p>RWTH HPC JupyterHub offers:</p> GeneralKernelsExtensionsWeb-proxy Applications <ul> <li> <p>Version(s): JupyterHub 3.0+, JupyterLab 3.4.7+</p> </li> <li> <p>Shared folder exists</p> </li> <li> <p>Persistent storage</p> </li> <li> <p>Available computing time (core-hours) vary based on user affiliation or project. Project application is necessary.</p> </li> <li> <p>Users installs planned, by request only at the moment.</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python 3.9</p> </li> <li> <p>Octave</p> </li> <li> <p>R</p> </li> <li> <p>C++ 11/14/17</p> </li> <li> <p>Matlab 2020b</p> </li> <li> <p>Matlab 2022b</p> </li> </ul> <p>Environments:</p> <ul> <li> <p>Python: Keras + Tensorflow</p> </li> <li> <p>Python: Tensorboard + Keras + Tensorflow</p> </li> <li> <p>Python: Pytorch</p> </li> <li> <p>Pytorch: Tensorboard</p> </li> <li> <p>Python: Gurobi</p> </li> <li> <p>Matlab: Gurobi</p> </li> <li> <p>Custom</p> </li> </ul> <ul> <li> <p>ipytree</p> </li> <li> <p>jupyterlab-drawio</p> </li> <li> <p>jupyterlab-plotly</p> </li> <li> <p>jupyterlab_iframe</p> </li> <li> <p>nbdime-jupyterlab</p> </li> <li> <p>jupyter-matplotlib</p> </li> <li> <p>jupyterlab_pygments</p> </li> <li> <p>jupyterlab/git</p> </li> <li> <p>jupyterlab/latex</p> </li> <li> <p>jupyter-widgets/jupyterlab-manager</p> </li> </ul> <ul> <li> <p>Matlab 2022b</p> </li> <li> <p>Matlab 2020b</p> </li> </ul>"},{"location":"hubs/details/RWTH-NFDI-Jupyter-Service/#resources","title":"Resources","text":"<p>RWTH HPC JupyterHub provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 5 Number of CPUs 1 48 CPU time 4h 172 h Amount of memory 4 GB 185 GB Number of GPUs 0 2 Disk space 400 GB 1 TB Persistent disk space 400 GB 1 TB"},{"location":"hubs/details/RWTH-NFDI-Jupyter-Service/#technicals","title":"Technicals","text":"<p>Some technical insights about RWTH HPC JupyterHub:</p> <ul> <li>Deployment: Runs on HPC Hardware under Slurm. </li> </ul>"},{"location":"hubs/details/gwdg/","title":"Jupyter-Cloud","text":"<p>The Jupyter-Cloud can be reached here and is provided by GWDG.</p>"},{"location":"hubs/details/gwdg/#short-facts","title":"Short Facts","text":"Service URL <p>https://jupyter-cloud.gwdg.de</p> Target group <p>Users having a full GWDG account (which can include people working in partner projects)</p> Login process <p>Login via Shibboleth (AcademicID - academiccloud.de)</p> Support <p>support@gwdg.de</p> Documentation <p>https://docs.gwdg.de/doku.php?id=en:services:application_services:jupyter:start</p>"},{"location":"hubs/details/gwdg/#features","title":"Features","text":"<p>Jupyter-Cloud offers:</p> GeneralKernelsExtensions <ul> <li> <p>Version(s): JupyterLab 3.5 (via JupyterHub)</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> <li> <p>Persistent storage</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python</p> </li> <li> <p>Julia</p> </li> <li> <p>R</p> </li> <li> <p>Bash</p> </li> </ul> <ul> <li> <p>git</p> </li> <li> <p>plotly</p> </li> <li> <p>matplotlib</p> </li> </ul>"},{"location":"hubs/details/gwdg/#resources","title":"Resources","text":"<p>Jupyter-Cloud provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 1 Number of CPUs 1 4 CPU time 24 h 24 h Amount of memory 15 GB 15 GB Number of GPUs 0 0 Disk space 10 GB 10 GB Persistent disk space 10 GB 10 GB"},{"location":"hubs/details/gwdg/#technicals","title":"Technicals","text":"<p>Some technical insights about Jupyter-Cloud:</p> <ul> <li>Deployment: Based on Jupyter Datascience Notebook image, extended with user-requested data science tools </li> </ul>"},{"location":"hubs/details/gwdg_hpc/","title":"SCC Jupyterhub","text":"<p>The SCC Jupyterhub can be reached here and is provided by GWDG.</p>"},{"location":"hubs/details/gwdg_hpc/#short-facts","title":"Short Facts","text":"Service URL <p>https://jupyter-hpc.gwdg.de</p> Target group <p>Users with a full GWDG account (including people working in partner projects).</p> Login process <p>Login via LDAP</p> Support <p>hpc-support@gwdg.de</p> Documentation <p>https://docs.gwdg.de/doku.php?id=en:services:application_services:jupyter:hpc</p>"},{"location":"hubs/details/gwdg_hpc/#features","title":"Features","text":"<p>SCC Jupyterhub offers:</p> GeneralKernelsExtensions <ul> <li> <p>Version(s): JupyterHub 1.0.0, Notebook Server 6.0.3</p> </li> <li> <p>Shared folder exists</p> </li> <li> <p>Persistent storage</p> </li> <li> <p>Own directory can be made writable for others.</p> </li> <li> <p>Project directories are possible (POSIX group members can get access).</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python</p> </li> <li> <p>R</p> </li> <li> <p>Bash</p> </li> </ul> <ul> <li>ipyparallel</li> </ul>"},{"location":"hubs/details/gwdg_hpc/#resources","title":"Resources","text":"<p>SCC Jupyterhub provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 1 Number of CPUs 12 24 CPU time 8h 8h Amount of memory 64GB 128GB Number of GPUs 0 1 Disk space 20 GB 0.5 PB available for all users Persistent disk space None 0.5PB available for all users"},{"location":"hubs/details/gwdg_hpc/#technicals","title":"Technicals","text":"<p>Some technical insights about SCC Jupyterhub:</p> <ul> <li>Scratch file system (very fast), and Stornext (slower, for home file system)</li> </ul>"},{"location":"hubs/details/jupyter-jsc.fz-juelich.de/","title":"Jupyter-JSC","text":"<p>The Jupyter-JSC can be reached here and is provided by Juelich Supercomputing Centre.</p>"},{"location":"hubs/details/jupyter-jsc.fz-juelich.de/#short-facts","title":"Short Facts","text":"Service URL <p>https://jupyter.jsc.fz-juelich.de</p> Target group <p>HPC users of JSC. Helmholtz users in general</p> Login process <p>Login via JSC account or Helmholtz AAI</p> Support <p>ds-support@fz-juelich.de</p> Documentation <p>https://docs.jupyter.jsc.fz-juelich.de</p>"},{"location":"hubs/details/jupyter-jsc.fz-juelich.de/#features","title":"Features","text":"<p>Jupyter-JSC offers:</p> GeneralKernelsExtensionsWeb-proxy Applications <ul> <li> <p>Version(s): JupyterHub 4.1.5; JupyterLab 3.6, 4.2, users may start their own docker images</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> <li> <p>Persistent storage</p> </li> <li> <p>Start on multiple (external) systems possible (including HPC). Resources depend highly on system</p> </li> <li> <p>2FA authentication available</p> </li> <li> <p>WebDAV connection possible</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Bash</p> </li> <li> <p>Cling</p> </li> <li> <p>JavaScript</p> </li> <li> <p>Julia</p> </li> <li> <p>Octave</p> </li> <li> <p>R</p> </li> <li> <p>Ruby</p> </li> </ul> <p>Environments:</p> <ul> <li> <p>PyDeepLearning</p> </li> <li> <p>PyQuantum</p> </li> <li> <p>PyVisualization</p> </li> <li> <p>Custom</p> </li> </ul> <ul> <li> <p>Bokeh</p> </li> <li> <p>JupyterLab Preview</p> </li> <li> <p>JupyterLab Manager</p> </li> <li> <p>JupyterLab Sidecar</p> </li> <li> <p>JupyterLab Git</p> </li> <li> <p>JupyterLab server proxy</p> </li> <li> <p>JupyterLab toc</p> </li> <li> <p>JupyterLab lsp</p> </li> <li> <p>JupyterLab quickopen</p> </li> <li> <p>JupyterLab pyviz</p> </li> <li> <p>JupyterLab Code Formatter</p> </li> <li> <p>BQPlot</p> </li> <li> <p>Dask Labextension</p> </li> <li> <p>IPyVolume</p> </li> <li> <p>ITKWidgets</p> </li> <li> <p>Leaflet</p> </li> <li> <p>Matplotlib</p> </li> <li> <p>ThreeJS</p> </li> <li> <p>Vue</p> </li> <li> <p>Vuetify</p> </li> <li> <p>JuypterLab Control</p> </li> <li> <p>JupyterLab Dash</p> </li> <li> <p>JupyterLab Datawidgets</p> </li> <li> <p>JupyterLab GitLab</p> </li> <li> <p>JupyterLab Lmod</p> </li> <li> <p>JupyterLab plotly</p> </li> <li> <p>JupyterLab System Monitor</p> </li> <li> <p>JupyterLAb Theme Toggle</p> </li> <li> <p>JupyterLab topbar extension</p> </li> <li> <p>JupyterLab iframe</p> </li> <li> <p>nbdime</p> </li> <li> <p>plotlywidget</p> </li> <li> <p>pvlink</p> </li> <li> <p>Jupyter Slurm Provisioner</p> </li> <li> <p>NVDashboard</p> </li> </ul> <ul> <li> <p>XPra</p> </li> <li> <p>NESTDesktop</p> </li> <li> <p>MatLab</p> </li> <li> <p>RStudio</p> </li> </ul>"},{"location":"hubs/details/jupyter-jsc.fz-juelich.de/#resources","title":"Resources","text":"<p>Jupyter-JSC provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 100 Number of CPUs 2 1024 CPU time 30 min 24 h Amount of memory 96 GB 768 GB Number of GPUs 0 4 Disk space 10 GB None Persistent disk space None None"},{"location":"hubs/details/jupyter-jsc.fz-juelich.de/#technicals","title":"Technicals","text":"<p>Some technical insights about Jupyter-JSC:</p> <ul> <li>SSL encryption between JupyterLab and JupyterHub</li> </ul>"},{"location":"hubs/details/jupyter4nfdi/","title":"Jupyter4NFDI","text":"<p>The Jupyter4NFDI can be reached here and is provided by Juelich Supercomputing Centre.</p>"},{"location":"hubs/details/jupyter4nfdi/#short-facts","title":"Short Facts","text":"Service URL <p>https://hub.nfdi-jupyter.de</p> Target group <p>Users within NFDI</p> Login process <p>Login via Helmholtz AAI. IAM4NFDI integration in the future.</p> Support <p>ds-support@fz-juelich.de</p> Documentation <p>https://docs.jupyter.jsc.fz-juelich.de</p>"},{"location":"hubs/details/jupyter4nfdi/#features","title":"Features","text":"<p>Jupyter4NFDI offers:</p> GeneralKernelsExtensionsWeb-proxy Applications <ul> <li> <p>Version(s): 4.1.5; JupyterLab 4.2, users may start their own docker images</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> <li> <p>Persistent storage</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python</p> </li> <li> <p>Bash</p> </li> <li> <p>Cling</p> </li> <li> <p>JavaScript</p> </li> <li> <p>Julia</p> </li> <li> <p>Octave</p> </li> <li> <p>R</p> </li> <li> <p>Ruby</p> </li> </ul> <p>Environments:</p> <ul> <li> <p>CreateYourOwnKernel</p> </li> <li> <p>PyDeepLearning</p> </li> <li> <p>PyQuantum</p> </li> <li> <p>PyVisualization</p> </li> </ul> <ul> <li> <p>Bokeh</p> </li> <li> <p>JupyterLab Preview</p> </li> <li> <p>JupyterLab Manager</p> </li> <li> <p>JupyterLab Sidecar</p> </li> <li> <p>JupyterLab Git</p> </li> <li> <p>JupyterLab server proxy</p> </li> <li> <p>JupyterLab toc</p> </li> <li> <p>JupyterLab lsp</p> </li> <li> <p>JupyterLab quickopen</p> </li> <li> <p>JupyterLab pyviz</p> </li> <li> <p>JupyterLab Code Formatter</p> </li> <li> <p>BQPlot</p> </li> <li> <p>Dask Labextension</p> </li> <li> <p>IPyVolume</p> </li> <li> <p>ITKWidgets</p> </li> <li> <p>Leaflet</p> </li> <li> <p>Matplotlib</p> </li> <li> <p>ThreeJS</p> </li> <li> <p>Vue</p> </li> <li> <p>Vuetify</p> </li> <li> <p>JuypterLab Control</p> </li> <li> <p>JupyterLab Dash</p> </li> <li> <p>JupyterLab Datawidgets</p> </li> <li> <p>JupyterLab GitLab</p> </li> <li> <p>JupyterLab Lmod</p> </li> <li> <p>JupyterLab plotly</p> </li> <li> <p>JupyterLab System Monitor</p> </li> <li> <p>JupyterLAb Theme Toggle</p> </li> <li> <p>JupyterLab topbar extension</p> </li> <li> <p>JupyterLab iframe</p> </li> <li> <p>nbdime</p> </li> <li> <p>plotlywidget</p> </li> <li> <p>pvlink</p> </li> <li> <p>Jupyter Slurm Provisioner</p> </li> <li> <p>NVDashboard</p> </li> </ul> <ul> <li> <p>XPra</p> </li> <li> <p>NESTDesktop</p> </li> <li> <p>RStudio</p> </li> </ul>"},{"location":"hubs/details/jupyter4nfdi/#resources","title":"Resources","text":"<p>Jupyter4NFDI provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 5 Number of CPUs 1 2 CPU time 5 days 5 days Amount of memory 2 GB 8 GB Number of GPUs 0 0 Disk space 25 GB 25 GB Persistent disk space 25 GB 25 GB"},{"location":"hubs/details/jupyter4nfdi/#technicals","title":"Technicals","text":"<p>Some technical insights about Jupyter4NFDI:</p> <ul> <li> <p>Platform: OpenStack</p> </li> <li> <p>Deployment: Kubernetes  Further information </p> </li> <li> <p>Hardware location: JSC, others will follow</p> </li> </ul>"},{"location":"hubs/details/kit-horeka/","title":"HoreKa Jupyterhub","text":"<p>The HoreKa Jupyterhub can be reached here and is provided by Karlsruhe Institute of Technology.</p>"},{"location":"hubs/details/kit-horeka/#short-facts","title":"Short Facts","text":"Service URL <p>https://hk-jupyter.scc.kit.edu</p> Target group <p>Researchers, Users upon project application, Helmholtz users</p> Login process <p>Login through Home Organizations, Helmholtz AAI</p> Support <p>https://support.nhr.kit.edu</p> Documentation <p>https://www.nhr.kit.edu/userdocs/jupyter</p>"},{"location":"hubs/details/kit-horeka/#features","title":"Features","text":"<p>HoreKa Jupyterhub offers:</p> GeneralKernelsExtensionsWeb-proxy Applications <ul> <li> <p>Version(s): Jupyterhub 3.1.1, Jupyterlab 3.4.8</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> <li> <p>Shared folder exists</p> </li> <li> <p>Persistent storage</p> </li> <li> <p>Available resources and apps may vary based on Cluster</p> </li> <li> <p>User can install own python kernels</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python</p> </li> <li> <p>Julia</p> </li> <li> <p>R</p> </li> </ul> <ul> <li> <p>jupyterlab-lmod</p> </li> <li> <p>dask-labextension</p> </li> <li> <p>jupyterlab-git</p> </li> <li> <p>jupyterlab-latex</p> </li> <li> <p>jupytext</p> </li> </ul> <ul> <li> <p>jupyter-codeserver-proxy</p> </li> <li> <p>jupyter-desktop-server</p> </li> </ul>"},{"location":"hubs/details/kit-horeka/#resources","title":"Resources","text":"<p>HoreKa Jupyterhub provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 1 Number of CPUs 72 72 CPU time None None Amount of memory 237 GB 488 GB Number of GPUs 0 4 Disk space None 800 GB Persistent disk space 10 TB 250 TB"},{"location":"hubs/details/kit-horeka/#technicals","title":"Technicals","text":"<p>Some technical insights about HoreKa Jupyterhub:</p> <ul> <li> <p>BEEGFS Filesystem can be mounted</p> </li> <li> <p>LSDF can be mounted</p> </li> <li> <p>Container integration via pyxis</p> </li> </ul>"},{"location":"hubs/details/mpcdf/","title":"MPCDF JupyterHub","text":"<p>The MPCDF JupyterHub can be reached here and is provided by Max Planck Computing and Data Facility.</p>"},{"location":"hubs/details/mpcdf/#short-facts","title":"Short Facts","text":"Service URL <p>https://notebooks.mpcdf.mpg.de</p> Target group <p>Researchers of the Max Planck Society</p> Login process <p>None</p> Support <p>support@mpcdf.mpg.de</p> Documentation <p>None</p>"},{"location":"hubs/details/mpcdf/#features","title":"Features","text":"<p>MPCDF JupyterHub offers:</p> GeneralKernels <ul> <li> <p>Version(s): JupyterHub 1.x (lab view)</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python</p> </li> <li> <p>Julia</p> </li> <li> <p>R</p> </li> </ul>"},{"location":"hubs/details/mpcdf/#resources","title":"Resources","text":"<p>MPCDF JupyterHub provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 1 Number of CPUs 1 4 CPU time 1 h 72 h Amount of memory 100 MB 4 GB Number of GPUs 0 0 Disk space 10 GB 10 GB Persistent disk space 0 GB 0 GB"},{"location":"hubs/details/nfdi4ing/","title":"NFDI4Ing JupyterHub","text":"<p>The NFDI4Ing JupyterHub can be reached here and is provided by University of Stuttgart.</p>"},{"location":"hubs/details/nfdi4ing/#short-facts","title":"Short Facts","text":"Service URL <p>https://jupyter.nfdi4ing.de</p> Target group <p>Researchers in Engineering</p> Login process <p>Login via Shibboleth (DFN-AAI)</p> Support <p>fokus@izus.uni-stuttgart.de</p> Documentation <p>None</p>"},{"location":"hubs/details/nfdi4ing/#features","title":"Features","text":"<p>NFDI4Ing JupyterHub offers:</p> GeneralKernels <ul> <li> <p>Version(s): JupyterHub 4.x, JupyterLab 4.x</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> <li> <p>Persistent storage</p> </li> <li> <p>WebDAV connection possible</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python</p> </li> <li> <p>Julia</p> </li> <li> <p>R</p> </li> </ul>"},{"location":"hubs/details/nfdi4ing/#resources","title":"Resources","text":"<p>NFDI4Ing JupyterHub provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 1 Number of CPUs 1 4 CPU time 1 h 72 h Amount of memory 250 MB 4 GB Number of GPUs 0 0 Disk space 10 GB 10 GB Persistent disk space 2 GB 2 GB"},{"location":"hubs/details/nfdi4ing/#technicals","title":"Technicals","text":"<p>Some technical insights about NFDI4Ing JupyterHub:</p> <ul> <li> <p>Platform: Linux Virtual Machine</p> </li> <li> <p>Deployment: Docker compose with pre-defined Jupyter Server images </p> </li> <li> <p>Required attributes, entitlements or memberships for Login: [   pairwise-id   displayName   mail ]</p> </li> <li> <p>Hardware location: Stuttgart, Germany</p> </li> </ul>"},{"location":"hubs/details/pc2-upb/","title":"PC\u00b2 JupyterHub","text":"<p>The PC\u00b2 JupyterHub can be reached here and is provided by Paderborn Center for Parallel Computing, University of Paderborn.</p>"},{"location":"hubs/details/pc2-upb/#short-facts","title":"Short Facts","text":"Service URL <p>https://jh.pc2.uni-paderborn.de</p> Target group <p>All users of a computing time project at PC\u00b2</p> Login process <p>Login via LDAP</p> Support <p>pc2-support@uni-paderborn.de</p> Documentation <p>https://pc2.uni-paderborn.de/go/jh</p>"},{"location":"hubs/details/pc2-upb/#features","title":"Features","text":"<p>PC\u00b2 JupyterHub offers:</p> GeneralKernelsExtensionsWeb-proxy Applications <ul> <li> <p>Version(s): JupyterHub 3.1.0, JupyterLab 3.6</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> <li> <p>Shared folder exists</p> </li> <li> <p>Persistent storage</p> </li> <li> <p>Pre-Set Environments</p> </li> <li> <p>Course functionality</p> </li> <li> <p>User home directory for e.g. user-specific packages</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python</p> </li> <li> <p>Julia</p> </li> <li> <p>R</p> </li> </ul> <ul> <li> <p>jupyterlab-nvdashboard</p> </li> <li> <p>jupyterlab-lmod</p> </li> <li> <p>jupyterlab-desktop</p> </li> <li> <p>jupyterlab-plotly</p> </li> <li> <p>jupyterlab-pygments</p> </li> </ul> <ul> <li> <p>Remote Desktop (noVNC)</p> </li> <li> <p>Full offered software on clusters with graphical interface (https://pc2.uni-paderborn.de/go/software)</p> </li> </ul>"},{"location":"hubs/details/pc2-upb/#resources","title":"Resources","text":"<p>PC\u00b2 JupyterHub provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 10 Number of CPUs None 143872 CPU time None 21 d Amount of memory None 347 TB Number of GPUs None 128 Disk space None 6 PB Persistent disk space None 185 TB"},{"location":"hubs/details/pc2-upb/#technicals","title":"Technicals","text":"<p>Some technical insights about PC\u00b2 JupyterHub:</p> <ul> <li> <p>Singularity integration (default + custom container)</p> </li> <li> <p>Remote Desktop with Slurm tools and module</p> </li> <li> <p>Remote Slurm kernel to start only kernels remote on cluster</p> </li> <li> <p>Direct connection of the cluster parallel filesystem</p> </li> </ul>"},{"location":"hubs/details/uni-leipzig/","title":"Webbasiertes Data Science und Machine Learning mit Jupyter","text":"<p>The Webbasiertes Data Science und Machine Learning mit Jupyter can be reached here and is provided by University of Leipzig.</p>"},{"location":"hubs/details/uni-leipzig/#short-facts","title":"Short Facts","text":"Service URL <p>https://lab.sc.uni-leipzig.de</p> Target group <p>Students and employees of University of Leipzig</p> Login process <p>Login via SC account</p> Support <p>sc-request@uni-leipzig.de</p> Documentation <p>https://www.sc.uni-leipzig.de, https://www.urz.uni-leipzig.de/unsere-services/servicedetail/service/webbasiertes-data-science-und-machine-learning-mit-jupyter</p>"},{"location":"hubs/details/uni-leipzig/#features","title":"Features","text":"<p>Webbasiertes Data Science und Machine Learning mit Jupyter offers:</p> GeneralKernelsExtensions <ul> <li> <p>Version(s): JupyterHub 3.1.0; JupyterLab 3.5.3</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> <li> <p>Shared folder exists</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python 3.11</p> </li> <li> <p>SageMath 10.0</p> </li> <li> <p>R 4.2.2</p> </li> <li> <p>Julia 1.8.5</p> </li> </ul> <p>Environments:</p> <ul> <li> <p>Python 3.9 OpenCV 4.7</p> </li> <li> <p>Python 3.9 PyTorch 1.10</p> </li> <li> <p>Python 3.9 TensorFlow 2.6.2</p> </li> </ul> <ul> <li> <p>server-proxy</p> </li> <li> <p>jupyterlab-manager</p> </li> <li> <p>webio-jupyterlab-provider</p> </li> <li> <p>jupyterlab_pygments</p> </li> <li> <p>jupyterlab_lmod</p> </li> </ul>"},{"location":"hubs/details/uni-leipzig/#resources","title":"Resources","text":"<p>Webbasiertes Data Science und Machine Learning mit Jupyter provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 1 Number of CPUs 1 8 CPU time 4h 4h Amount of memory 8GB 32GB Number of GPUs 0 1 Disk space None None Persistent disk space None None"},{"location":"hubs/details/uni-muenster/","title":"University of M\u00fcnster JupyterHub","text":"<p>The University of M\u00fcnster JupyterHub can be reached here and is provided by University of M\u00fcnster.</p>"},{"location":"hubs/details/uni-muenster/#short-facts","title":"Short Facts","text":"Service URL <p>https://jupyterhub.uni-muenster.de</p> Target group <p>Students and employees of University of M\u00fcnster, members of PUNCH4NFDI (soon)</p> Login process <p>Login via Shibboleth (DFN-AAI &amp; eduGAIN federation)</p> Support <p>None</p> Documentation <p>None</p>"},{"location":"hubs/details/uni-muenster/#features","title":"Features","text":"<p>University of M\u00fcnster JupyterHub offers:</p> GeneralKernelsExtensionsWeb-proxy Applications <ul> <li> <p>Version(s): JupyterHub 3.0, JupyterLab 3.6</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> <li> <p>Persistent storage</p> </li> <li> <p>Available resources and apps may vary based on user affiliation</p> </li> <li> <p>Sciebo cloud storage integration (beta)</p> </li> <li> <p>GUI apps via noVNC in browser window</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python</p> </li> <li> <p>Octave</p> </li> <li> <p>Julia</p> </li> <li> <p>R</p> </li> <li> <p>SageMath</p> </li> <li> <p>gnuplot</p> </li> <li> <p>Mathematica</p> </li> <li> <p>C++</p> </li> <li> <p>Rust</p> </li> <li> <p>Go</p> </li> <li> <p>Scheme</p> </li> </ul> <ul> <li> <p>jupyterlab_pygments</p> </li> <li> <p>ipyparallel-labextension</p> </li> <li> <p>jupyter-matplotlib</p> </li> <li> <p>jupyter-threejs</p> </li> <li> <p>jupyterlab-datawidgets</p> </li> <li> <p>bqplot</p> </li> <li> <p>ipysheet</p> </li> <li> <p>ipyvolume</p> </li> <li> <p>jupyter-leaflet</p> </li> <li> <p>jupyter-vue</p> </li> <li> <p>jupyter-vuetify</p> </li> <li> <p>jupyter-webrtc</p> </li> <li> <p>jupyterlab-drawio</p> </li> <li> <p>jupyterlab-plotly</p> </li> <li> <p>nglview-js-widgets</p> </li> <li> <p>jupyterlab-jupytext</p> </li> <li> <p>jupyterlab-logout</p> </li> <li> <p>jupyterlab-system-monitor</p> </li> <li> <p>jupyterlab-topbar-extension</p> </li> <li> <p>jupyterlab_iframe</p> </li> <li> <p>nbdime-jupyterlab</p> </li> <li> <p>@jupyter-widgets/jupyterlab-manager</p> </li> <li> <p>@jupyter-widgets/jupyterlab-sidecar</p> </li> <li> <p>@jupyterlab/git</p> </li> <li> <p>@jupyterlab/server-proxy</p> </li> <li> <p>@jupyterlab/latex</p> </li> <li> <p>@jupyterlab/mathjax3-extension</p> </li> <li> <p>@bokeh/jupyter_bokeh</p> </li> <li> <p>@agoose77/jupyterlab-markup</p> </li> <li> <p>@jupyter-server/resource-usage</p> </li> <li> <p>@lckr/jupyterlab_variableinspector</p> </li> <li> <p>@ryantam626/jupyterlab_code_formatter</p> </li> <li> <p>jupyterlab-controlpanel</p> </li> <li> <p>jupyterlab-helplinks</p> </li> <li> <p>jupyterlab-theme-toggle</p> </li> </ul> <ul> <li> <p>Matlab IDE</p> </li> <li> <p>RStudio</p> </li> <li> <p>VS Code</p> </li> <li> <p>Shiny</p> </li> <li> <p>Avogadro</p> </li> <li> <p>Blender</p> </li> <li> <p>Grace</p> </li> <li> <p>Mathematica</p> </li> <li> <p>MaxQuant</p> </li> <li> <p>OMERO</p> </li> <li> <p>ParaView</p> </li> <li> <p>Spyder</p> </li> <li> <p>TeXstudio</p> </li> <li> <p>VMD</p> </li> <li> <p>VoreenVE</p> </li> </ul>"},{"location":"hubs/details/uni-muenster/#resources","title":"Resources","text":"<p>University of M\u00fcnster JupyterHub provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 1 Number of CPUs 0.25 2 CPU time 6 h 6 h Amount of memory 1 GB 16 GB Number of GPUs 0 1 Disk space 5 GB 5 GB Persistent disk space 5 GB 5 GB"},{"location":"hubs/details/uni-muenster/#technicals","title":"Technicals","text":"<p>Some technical insights about University of M\u00fcnster JupyterHub:</p> <ul> <li>Deployment: Kubernetes </li> </ul>"},{"location":"hubs/details/usegalaxy.eu/","title":"Interactive Tools of European Galaxy Server","text":"<p>The Interactive Tools of European Galaxy Server can be reached here and is provided by University of Freiburg.</p>"},{"location":"hubs/details/usegalaxy.eu/#short-facts","title":"Short Facts","text":"Service URL <p>https://live.usegalaxy.eu</p> Target group <p>Open for everyone</p> Login process <p>Login via OpenIDC (LS-AAI, DataPLANT)</p> Support <p>contact@usegalaxy.eu</p> Documentation <p>https://training.galaxyproject.org</p>"},{"location":"hubs/details/usegalaxy.eu/#features","title":"Features","text":"<p>Interactive Tools of European Galaxy Server offers:</p> GeneralKernelsExtensionsWeb-proxy Applications <ul> <li> <p>Version(s): Galaxy 23.0 (Jupyterlab v3+)</p> </li> <li> <p>Temporarly install new packages by the user</p> </li> <li> <p>Shared folder exists</p> </li> <li> <p>Persistent storage</p> </li> <li> <p>Cloud storage can be accessed via Galaxy</p> </li> <li> <p>Notebooks can be combined with classical HPC workflows</p> </li> <li> <p>Part of the EOSC project EuroScienceGateway</p> </li> <li> <p>Community can contribute VREs</p> </li> <li> <p>Available resources and apps can vary based on user affiliation</p> </li> </ul> <p>Programming Languages:</p> <ul> <li> <p>Python</p> </li> <li> <p>Julia</p> </li> <li> <p>R</p> </li> <li> <p>Ansible</p> </li> <li> <p>Bash</p> </li> </ul> <p>Environments:</p> <ul> <li> <p>Jupyter ML</p> </li> <li> <p>MGnify</p> </li> <li> <p>Jupyter for Material Science</p> </li> <li> <p>Pangeo Jupyter</p> </li> <li> <p>Climate Jupyter</p> </li> </ul> <ul> <li> <p>bqplot</p> </li> <li> <p>jupyter-matplotlib</p> </li> <li> <p>jupyterlab-jupytext</p> </li> <li> <p>jupyterlab-manager</p> </li> <li> <p>fasta-extension</p> </li> <li> <p>geojson-extension</p> </li> <li> <p>katex-extension</p> </li> <li> <p>jupyterlab_hdf</p> </li> <li> <p>jupyterlab-execute-time</p> </li> <li> <p>jupyterlab-kernelspy</p> </li> <li> <p>jupyterlab-nvdashboard</p> </li> <li> <p>jupyterlab-system-monitor</p> </li> <li> <p>jupyterlab-topbar-extension</p> </li> <li> <p>jupyterlab_pygments</p> </li> <li> <p>nbdime-jupyterlab</p> </li> <li> <p>collapsible_headings</p> </li> <li> <p>code-snippet-extension</p> </li> <li> <p>code-viewer-extension</p> </li> <li> <p>metadata-extension</p> </li> <li> <p>pipeline-editor-extension</p> </li> <li> <p>python-editor-extension</p> </li> <li> <p>r-editor-extension</p> </li> <li> <p>scala-editor-extension</p> </li> <li> <p>script-debugger-extension</p> </li> <li> <p>theme-extension</p> </li> <li> <p>jupyterlab-lsp</p> </li> <li> <p>resource-usage</p> </li> <li> <p>jupyter-server-proxy</p> </li> <li> <p>git</p> </li> <li> <p>jupyterlab-preview</p> </li> </ul> <ul> <li> <p>RStudio</p> </li> <li> <p>AskOMICS</p> </li> <li> <p>BAM-iobio</p> </li> <li> <p>VCF-iobio</p> </li> <li> <p>BlobToolKit</p> </li> <li> <p>CellXGene</p> </li> <li> <p>Ethercalc</p> </li> <li> <p>Phinch</p> </li> <li> <p>MetaShARK</p> </li> <li> <p>MetaShrimp</p> </li> <li> <p>ODV</p> </li> <li> <p>Wallace</p> </li> <li> <p>iSEE</p> </li> <li> <p>Wilson</p> </li> <li> <p>Panoply netCDF Viewer</p> </li> <li> <p>HiGlass</p> </li> <li> <p>ParaView</p> </li> <li> <p>QGIS</p> </li> <li> <p>QuPath</p> </li> <li> <p>Radiant</p> </li> <li> <p>Scoop3-Agro</p> </li> <li> <p>VRM Editor</p> </li> <li> <p>Pavian</p> </li> <li> <p>OpenRefine</p> </li> <li> <p>Neo4J</p> </li> <li> <p>GeoExplorer</p> </li> <li> <p>NEAL</p> </li> </ul>"},{"location":"hubs/details/usegalaxy.eu/#resources","title":"Resources","text":"<p>Interactive Tools of European Galaxy Server provides Jupyter servers within the following resource limits:</p> Resource Default Maximum Number of Jupyter servers per user 1 1 Number of CPUs 1 4 CPU time 24 h 72 h Amount of memory 4 GB 256 GB Number of GPUs 1 1 Disk space 250 GB 2 TB Persistent disk space 250 GB 250 GB"},{"location":"hubs/plugins/gen_detail_pages/","title":"Gen detail pages","text":"In\u00a0[\u00a0]: Copied! <pre>import glob\nimport os\n</pre> import glob import os In\u00a0[\u00a0]: Copied! <pre>import mkdocs_gen_files\n</pre> import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre># get all data\ndata_dir = \"docs/hubs/plugins/data\"\nexclude = [\"template.yaml\", \"hooks.py\", \"cardinfo.yaml\"]\nfiles = glob.glob(os.path.join(data_dir, \"*.yaml\"))\nservices_names = [os.path.splitext(os.path.basename(file_name))[0] for file_name in files]\n</pre> # get all data data_dir = \"docs/hubs/plugins/data\" exclude = [\"template.yaml\", \"hooks.py\", \"cardinfo.yaml\"] files = glob.glob(os.path.join(data_dir, \"*.yaml\")) services_names = [os.path.splitext(os.path.basename(file_name))[0] for file_name in files] In\u00a0[\u00a0]: Copied! <pre># generate the pages\nfor file_name, service_name in zip(files, services_names):\n    if os.path.basename(file_name) in exclude:\n        continue\n    with open(file_name, 'r') as fh:\n        d = {\"yaml_str\": fh.read()}\n    target_name = os.path.join(\"hubs/details\", service_name + \".md\")\n    with mkdocs_gen_files.open(target_name, \"w\") as fh:\n        fh.write(\"---\\n\")\n        fh.write(d[\"yaml_str\"])\n        fh.write(\"---\\n\")\n        #fh.write(\"{{ macros_info() }}\\n\\n\")\n        fh.write(\"{% include 'details.md' %}\\n\")      \n        \n    mkdocs_gen_files.set_edit_path(os.path.join(\"hubs\", \"details\", service_name +\".md\"),\n                                   \"gen_detail_pages.py\")    \n</pre> # generate the pages for file_name, service_name in zip(files, services_names):     if os.path.basename(file_name) in exclude:         continue     with open(file_name, 'r') as fh:         d = {\"yaml_str\": fh.read()}     target_name = os.path.join(\"hubs/details\", service_name + \".md\")     with mkdocs_gen_files.open(target_name, \"w\") as fh:         fh.write(\"---\\n\")         fh.write(d[\"yaml_str\"])         fh.write(\"---\\n\")         #fh.write(\"{{ macros_info() }}\\n\\n\")         fh.write(\"{% include 'details.md' %}\\n\")                    mkdocs_gen_files.set_edit_path(os.path.join(\"hubs\", \"details\", service_name +\".md\"),                                    \"gen_detail_pages.py\")     In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"hubs/plugins/hooks/","title":"Hooks","text":"In\u00a0[\u00a0]: Copied! <pre>import glob\nimport os\nimport yaml\n</pre> import glob import os import yaml In\u00a0[\u00a0]: Copied! <pre>def generate_cards(*args, **kwargs):\n\n    # get all data\n    data_dir = \"docs/hubs/plugins/data\"\n    exclude = [\"template.yaml\",\"hooks.py\",\"cardinfo.yaml\"]\n    files = glob.glob(os.path.join(data_dir, \"*.yaml\"))\n    services_names = [os.path.splitext(os.path.basename(file_name))[0] for file_name in files]\n\n    # generate the pages\n    with open (f\"{data_dir}/cardinfo.yaml\", \"w\") as outfile:\n        for file_name, service_name in zip(files, services_names):\n            if os.path.basename(file_name) in exclude:\n                continue\n            with open(file_name, 'r') as fh:\n                d = yaml.safe_load(fh)\n                logo = d.get(\"logo\", None)\n                if logo is None:\n                    if os.path.exists(\"docs/hubs/plugins/assets/\"+ file_name.split(\"/\")[-1][:-4]+\"png\"):\n                        logo = file_name.split(\"/\")[-1][:-4]+\"png\"\n                    else:\n                        logo = \"default-logo.png\"\n                url_requires = d.get(\"service_url_requirement\", False)\n                if url_requires:\n                    service_url = \"#\"\n                    button_attr = \".md-button--disabled\"\n                else:\n                    service_url = d[\"service_url\"]\n                    button_attr = \".md-button .md-button--primary\"\n                lock = \":material-lock:\" if d.get(\"restricted\", True) else \":material-lock-open-variant:\"\n\n                outfile.write(\"- title: %s\\n\" % d[\"title\"])\n                outfile.write(\"\"\"  content: |\n    Provider: *%s*\n    &lt;p class=\\\"nt-card-text\\\"&gt;Target Group: %s&lt;/p&gt;\\n\n    &lt;div class=\\\"nfdi-card-link\\\"&gt;[:octicons-arrow-right-24: Service Details](details/%s.md)\\n\n    [%s Login](%s){%s}&lt;/div&gt;\\n\"\"\" % (d[\"provider\"],\n                                     d[\"target_group_open_for\"],\n                                     service_name,\n                                     lock,\n                                     service_url,\n                                     button_attr))\n                outfile.write(\"  image: plugins/assets/%s\\n\" % logo)\n                outfile.write(\"  icon: \\\":octicons-arrow-right-24:\\\"\\n\")\n</pre> def generate_cards(*args, **kwargs):      # get all data     data_dir = \"docs/hubs/plugins/data\"     exclude = [\"template.yaml\",\"hooks.py\",\"cardinfo.yaml\"]     files = glob.glob(os.path.join(data_dir, \"*.yaml\"))     services_names = [os.path.splitext(os.path.basename(file_name))[0] for file_name in files]      # generate the pages     with open (f\"{data_dir}/cardinfo.yaml\", \"w\") as outfile:         for file_name, service_name in zip(files, services_names):             if os.path.basename(file_name) in exclude:                 continue             with open(file_name, 'r') as fh:                 d = yaml.safe_load(fh)                 logo = d.get(\"logo\", None)                 if logo is None:                     if os.path.exists(\"docs/hubs/plugins/assets/\"+ file_name.split(\"/\")[-1][:-4]+\"png\"):                         logo = file_name.split(\"/\")[-1][:-4]+\"png\"                     else:                         logo = \"default-logo.png\"                 url_requires = d.get(\"service_url_requirement\", False)                 if url_requires:                     service_url = \"#\"                     button_attr = \".md-button--disabled\"                 else:                     service_url = d[\"service_url\"]                     button_attr = \".md-button .md-button--primary\"                 lock = \":material-lock:\" if d.get(\"restricted\", True) else \":material-lock-open-variant:\"                  outfile.write(\"- title: %s\\n\" % d[\"title\"])                 outfile.write(\"\"\"  content: |     Provider: *%s*     <p>Target Group: %s</p>\\n     [:octicons-arrow-right-24: Service Details](details/%s.md)\\n     [%s Login](%s){%s}\\n\"\"\" % (d[\"provider\"],                                      d[\"target_group_open_for\"],                                      service_name,                                      lock,                                      service_url,                                      button_attr))                 outfile.write(\"  image: plugins/assets/%s\\n\" % logo)                 outfile.write(\"  icon: \\\":octicons-arrow-right-24:\\\"\\n\")"},{"location":"providers/","title":"JupyterHub Outpost for Jupyter4NFDI","text":"<p>Welcome to the JupyterHub Outpost installation guide for external resource providers! This guide will help you set up a JupyterHub Outpost on your resources, allowing users within the Jupyter4NFDI community to benefit from access to diverse computational environments while you maintain control over your resources.</p>"},{"location":"providers/#why-join-jupyter4nfdi","title":"Why Join Jupyter4NFDI?","text":"<p>Jupyter4NFDI brings together resources from multiple providers to create a rich and collaborative environment, promoting knowledge sharing and enabling cutting-edge research. Here\u2019s why you should consider contributing:</p> <ul> <li>Security and Control: You control who may access your resources. Permissions and access rights remain fully in your hands.</li> <li>Visibility: By connecting your resources to Jupyter4NFDI, you increase their visibility and attract a wider range of users within the scientific community.</li> <li>Collaborative Community: Join a network of peers contributing to NFDI's vision of federated, accessible research infrastructure.</li> <li>Complementary Service: JupyterHub Outpost doesn't replace or compromise any existing JupyterHub instances you may be running. Instead, it provides an additional access point specifically configured for NFDI needs.</li> </ul> <p>JupyterHub Outpost is a powerful, flexible solution that works in tandem with your existing systems. The following sections will guide you through its architecture, installation, and configuration.</p>"},{"location":"providers/#features","title":"Features","text":"<ul> <li>Use a central JupyterHub to offer jupyter servers on multiple systems of potentially different types.</li> <li>User specific flavors allows administrators to configure resource limits for each user.</li> <li>Each (remote) system may use a different JupyterHub Spawner.</li> <li>Forward spawn events gathered by the remote Spawner to the user.</li> <li>Users may override the configuration of the remote Spawner at runtime (e.g. to select a different Docker Image), if allowed by JupyterHub Outpost administrators.</li> <li>Integrated SSH port forwarding solution to reach otherwise isolated remote jupyter servers.</li> <li>Supports the JupyterHub internal_ssl feature.</li> <li>One JupyterHub Outpost can be connected to multiple JupyterHubs without the Hubs interfering with each other.</li> <li>Configuration of JupyterHub Outpost similar to the JupyterHub configuration.</li> </ul>"},{"location":"providers/architecture/","title":"JupyterHub Outpost Architecture","text":"<p>Understanding the JupyterHub Outpost architecture will help you set up and manage Outpost instances effectively, while ensuring your resources remain secure. The architecture is divided into two main components: Local Cluster Components (associated with the Central JupyterHub) and Remote Cluster Components (related to the JupyterHub Outpost installed on a separate cluster from the Central JupyterHub).</p>"},{"location":"providers/architecture/#local-cluster-components","title":"Local Cluster Components","text":"<p>The following key components are part of the central JupyterHub.</p> <p>It's recommended to run it on a Kubernetes cluster. Other setups will work as well, but are not covered in this section.</p> 1. OutpostSpawner <p>The OutpostSpawner takes on a user's start request for a jupyter server. Instead of starting the server locally, it communicates with a JupyterHub Outpost REST API. It can be used with multiple JupyterHub Outposts, allowing the central JupyterHub to support countless remote systems. For more information look into the OutpostSpawner documentation.</p> 2. Kubernetes Service (optional)  <p>Each Jupyter server of a user will receive it's own Kubernetes Service. JupyterHub will be able to communicate with the remote Jupyter server via this local Kubernetes Service, by creating a ssh tunnel to the JupyterHub Outpost.</p> <p>If the Jupyter server of a user is reachable from the outside world, e.g. through a Proxy on the remote cluster, it is not required.</p>"},{"location":"providers/architecture/#remote-cluster-components","title":"Remote Cluster Components","text":"1. JupyterHub Outpost <p>The Outpost manages the users Jupyter Servers. It can be configured with any Spawner and has a additional features allowing administrators to be in charge of their own resources. For more information, check the installation and configuration sections.  </p> <p>It is recommended to install the JupyterHub Outpost on a Kubernetes cluster using this Helm Chart. Other setups like docker swarm will work as well, but might require some extra steps.  </p>"},{"location":"providers/architecture/#outpost-setup-scenarios","title":"Outpost Setup Scenarios","text":"<p>The diagrams below illustrate various setup configurations with the JupyterHub Outpost. You have the flexibility to add as many systems and Outposts to the architecture as needed.</p> <p>Check out the JupyterHub vanilla architecture for more information about the shown components.</p> One Remote System    <p>         A central JupyterHub initiates Jupyter servers on a remote Kubernetes cluster.          The JupyterHub Outpost listens on port          8080          for incoming requests and on port          22          for SSH tunnels, enabling the Jupyter servers (notebooks) to be accessible to the central JupyterHub.       </p> 1. Send Request <p>          The OutpostSpawner handles a user\u2019s request to launch a notebook server.                 Rather than starting the server itself, it gathers all the necessary details for initiating a single-user server. These typically include the          name,          environment, and          selected user options.          Additionally, optional data, such as certificates          or trust bundles (used for internal SSL),          is sent to the JupyterHub Outpost when required.        </p> 2. Spawner.start() <p>          The JupyterHub Outpost utilizes the configured          JupyterHub Spawner to launch the single-user server.                This process, typically managed directly by JupyterHub,          follows the same sequence of functions used during a standard startup, including          run_pre_spawn_hook,          move_certs, and          start.          Any events produced by _generate_progress()          are relayed back to JupyterHub, ensuring users receive all          critical updates without interruption.        </p> 3. Send service address <p>          JupyterHub requires the          service address          (typically a combination of IP and          port) to establish          SSH port forwarding.                This forwarding allows users to access          the remote single-user notebook server, even if it is operating within a restricted or isolated environment.        </p> 4. Port forwarding <p>          JupyterHub uses a random available local port (random_port)          to forward traffic for the single-user server to the JupyterHub Outpost.                 It employs          SSH multiplexing to minimize the number of connections.          In this setup, the JupyterHub Outpost must have access to the notebook server's          IP address (service_address)          and port (single-user_port).                  Simplified port forward command:       <pre>\n        <code>ssh -L 0.0.0.0:[random_port]:[service_address]:[single-user_port] jhuboutpost@[outpost-ip]</code>\n      </pre>         It is also possible to define a customized port forwarding function          (e.g., to delegate port-forwarding to an external pod, see external tunneling). Alternatively, you can          tunnel directly to the system where the notebook server is running          without routing through a JupyterHub Outpost, as described in delayed tunneling.        </p> 5. Create service <p>          At this step, the JupyterHub OutpostSpawner          will create a Kubernetes Service, enabling the Configurable HTTP Proxy to communicate with the single-user server via this service.                 In the default configuration, the Hub pod is the target of the Kubernetes service,          as it manages the SSH connections. Consequently, all traffic between the client and the single-user server is forwarded through the hub container.                   It is also possible to adjust the Kubernetes service selector          or to define a customized service creation function          (e.g., to delegate port-forwarding to an external pod).        </p> Remote + Local System    <p>       This architecture mirrors the one described in the previous section, with the key difference being the addition of a        local JupyterHub Outpost service running on the same        Kubernetes cluster as JupyterHub.        It highlights that, in the case of a local Outpost service, there is no need to enable SSH port-forwarding, as the        notebook servers will be directly accessible through        Kubernetes\u2019 internal DNS resolution.     </p> External Tunneling    <p>     In this scenario, an additional pod was created to manage the      port forwarding. This means the management of SSH tunnels      to single-user notebook servers is delegated from the JupyterHub pod      to the external port forwarding pod.   </p> <p>     With this setup, single-user servers remain reachable even if      JupyterHub itself is offline. Instead of tunneling through the      Hub pod, traffic between the client and the single-user server      travels through the port forwarding pod. The Kubernetes service      for the single-user server is then configured to target the port forwarding pod      rather than the Hub pod.   </p> Delayed Tunneling    <p>     In this scenario, an additional pod was created to manage the      port forwarding. This means the management of SSH tunnels      to single-user notebook servers is delegated from the JupyterHub pod      to the external port forwarding pod.   </p> <p>     With this setup, single-user servers remain reachable even if      JupyterHub itself is offline. Instead of tunneling through the      Hub pod, traffic between the client and the single-user server      travels through the port forwarding pod. The Kubernetes service      for the single-user server is then configured to target the port forwarding pod      rather than the Hub pod.   </p>"},{"location":"providers/configuration/","title":"Application Configuration","text":"<p>The JupyterHub Outpost uses a configuration file <code>outpost_config.py</code> similar to <code>jupyterhub_config.py</code> of JupyterHub. The Spawner configuration for the Outpost is therefore similar to the Spawner configuration in JupyterHub.  The easiest way is configure the Outpost's configuration file is via the <code>outpostConfig</code> key in the helm chart's <code>values.yaml</code> file.</p>"},{"location":"providers/configuration/#persistent-database","title":"Persistent database","text":"<p>To use a persistent database such as postgresql with JupyterHub Outpost, use <code>extraEnvVarsSecrets</code> in your <code>values.yaml</code> file. All possible values related to the database connection can be found in the source code itself.</p> <p>Ensure that you have a database such postgres installed and that a JupyterHub Outpost user and database exists.</p> <p>Example SQL commands for postgresql: <pre><code>CREATE USER jupyterhuboutpost WITH ENCRYPTED PASSWORD '...';\nCREATE DATABASE jupyterhuboutpost OWNER jupyterhuboutpost;\n</code></pre></p> <p>Create a secret in your Outpost namespace with the required values before installing JupyterHub Outpost:</p> <pre><code>kind: Secret\nmetadata:\n  name: my-db-secret\n...\nstringData:\n  SQL_TYPE: \"postgresql\"\n  SQL_USER: \"jupyterhuboutpost\"\n  SQL_PASSWORD: \"...\"\n  SQL_HOST: \"postgres.database.svc\"\n  SQL_PORT: \"5432\"\n  SQL_DATABASE: \"jupyterhuboutpost\"\n</code></pre> <p>And add the database secret to your Outpost values.yaml file:  </p> <pre><code>...\nextraEnvVarsSecrets:\n  - my-db-secret\n</code></pre>"},{"location":"providers/configuration/#simple-kubespawner","title":"Simple KubeSpawner","text":"<p>Jupyter4NFDI sends a profile to your Spawner. This is a small example which ignores the profile and always runs the Jupyter Server with the predefined setup.</p> <p>values.yaml file: <pre><code>outpostConfig: |\n  from kubespawner import KubeSpawner\n  c.JupyterHubOutpost.spawner_class = KubeSpawner\n\n  c.KubeSpawner.start_timeout = 600\n\n  async def profile_list(spawner):\n      jupyterhub_name = spawner.jupyterhub_name\n      spawner.log.info(f\"{spawner._log_name} - Received these user_options from {jupyterhub_name}-JupyterHub: {spawner.user_options}\")\n      slug = spawner.user_options.get(\"profile\", \"default\")\n      default_image = \"jupyter/minimal-notebook:notebook-7.0.3\"\n      return [\n        {\n            \"display_name\": slug,\n            \"slug\": slug,\n            \"kubespawner_override\": {\n                \"image\": default_image\n            }\n        }\n      ]\n\n  c.KubeSpawner.profile_list = profile_list\n</code></pre></p> <p>Update or install JupyterHub Outpost with values.yaml file: <pre><code>helm upgrade --install -f values.yaml --namespace outpost outpost jupyterhub-outpost/jupyterhub-outpost\n</code></pre></p> <p>In this example we use the KubeSpawner, but you can use any JupyterHub Spawner.</p>"},{"location":"providers/configuration/#customize-logging","title":"Customize Logging","text":"<p>For the logging configuration, the Outpost offers these options (corresponding to the logging options of JupyterHub): <pre><code>c.JupyterHubOutpost.log_level = ...\nc.JupyterHubOutpost.log_datafmt = ...\nc.JupyterHubOutpost.log_format = ...\n</code></pre></p> <p>If more customization is required, one can do this directly in the <code>outpost_config.py</code> file itself (possible via the <code>outpostConfig</code> key of the helm chart). <pre><code># Suppress /ping loggings, created by k8s livenessprobe\nuvicorn_access = logging.getLogger(\"uvicorn.access\")\nclass UvicornFilter(logging.Filter):\n    def filter(self, record):\n        try:\n            if \"/ping\" in record.args:\n                return False\n        except:\n            pass\n        return True\n\nuvicorn_access.addFilter(UvicornFilter())\n\n# Suppress missing static files by Tornado Logger\ntornado_general = logging.getLogger(\"tornado.general\")\nclass TornadoGeneralLoggingFilter(logging.Filter):\n  def filter(self, record):\n    # I don't want to see this log line generated by tornado\n    if str(record.msg).startswith(\"Could not open static file\"):\n      return False\n    return True\n\ntornado_general.addFilter(TornadoGeneralLoggingFilter())\n\nimport os\nlogged_logger_name = os.environ.get(\"LOGGER_NAME\", \"MyOutpostInstance\")\nc.JupyterHubOutpost.log_format = f\"%(color)s[%(levelname)1.1s %(asctime)s.%(msecs).03d {logged_logger_name} %(name)s %(module)s:%(lineno)d]%(end_color)s %(message)s\"\n</code></pre></p>"},{"location":"providers/configuration/#sanitize-spawnerstart-response","title":"Sanitize Spawner.start response","text":"<p>JupyterHub Outpost relies on the <code>start</code> function of the configured SpawnerClass to determine where the single-user server will run. For instance, with KubeSpawner, the <code>KubeSpawner.start()</code> function might return a URL like <code>http://jupyter-&lt;id&gt;-&lt;user_id&gt;:&lt;port&gt;</code>, which Outpost will pass along to JupyterHub.</p> <p>The OutpostSpawner then uses this information to set up an SSH port-forwarding process with the command <code>-L 0.0.0.0:&lt;local_jhub_port&gt;:jupyter-&lt;id&gt;-&lt;user_id&gt;:&lt;port&gt;</code>. Afterward, JupyterHub will access the single-user server at <code>http://localhost:&lt;local_jhub_port&gt;</code>.</p> <p>If the response from the <code>start</code> function isn't correct, the OutpostSpawner and Outpost won't work together properly. However, to support most Spawners, you can customize the response that is sent to the OutpostSpawner.</p> <pre><code># In the `outpostConfig` key of your helm values.yaml file or your outpost_config.py file:\n\n# This may be a coroutine\ndef sanitize_start_response(spawner, original_response):\n  # ... determine the correct location for the new single-user server\n  return \"&lt;...&gt;\"\n\nc.JupyterHubOutpost.sanitize_start_response = sanitize_start_response\n</code></pre> <p>If you don't know where your single-user server will be running at the end of the <code>start</code> function, you have to return an empty string. In that case, JupyterHub OutpostSpawner won't create a ssh port-forwarding process. Instead, the start process of the single-user server has to send a POST request to the <code>$JUPYTERHUB_SETUPTUNNEL_URL</code> url. Have a look at the API Endpoints of the OutpostSpawner (https://jupyterhub-outpostspawner.readthedocs.io/en/latest/apiendpoints.html) for more information.</p>"},{"location":"providers/configuration/#disable-configuration-overwrite","title":"Disable configuration overwrite","text":"<p>By default, Jupyter4NFDI can overwrite the JupyterHub Outpost configuration with the OutpostSpawner's <code>custom_misc</code> function. As an administrator of the JupyterHub Outpost service, you can prevent this.  </p> <pre><code># In the `outpostConfig` key of your helm values.yaml file or your outpost_config.py file:\n\nasync def allow_override(jupyterhub_name, misc):\n    if jupyterhub_name == \"trustedhub\":\n        return True\n    if list(misc.keys()) != [\"image\"]:\n        return False\n    return misc.get(\"image\", \"None\") in [\"allowed_image1\", \"allowed_image2\"]\n\nc.JupyterHubOutpost.allow_override = allow_override\n</code></pre> <p>The above example leads to the following behaviour:  - JupyterHub with credential username \"trustedhub\" can overwrite anything.   - If a JupyterHub (other than trustedhub) tries to overwrite anything except the <code>image</code> key, it will not be allowed.  - The given image must be <code>allowed_image1</code> or <code>allowed_image2</code>.</p> <p>If <code>custom_misc</code> in the POST request is empty, the <code>allow_override</code> function will not be called. If <code>allow_override</code> returns False, the JupyterLab will not be started. An error message will be returned to the JupyterHub OutpostSpawner and shown to the user.</p>"},{"location":"providers/configuration/#recreate-ssh-tunnels-at-startup","title":"Recreate ssh tunnels at startup","text":"<p>If your JupyterHub Outpost is used as a ssh node in the JupyterHub OutpostSpawner, all port-forwarding processes have to be recreated if the JupyterHub Outpost service was restarted. While restarting, existing <code>ssh</code> port-forwarding processes will fail after a few seconds and the user's single-user server would be unreachable.  </p> <p>By default tunnels will be recreated at JupyterHub Outpost restarts. You can disable this behaviour with the <code>ssh_recreate_at_start</code> key.  </p> <pre><code># In the `outpostConfig` key of your helm values.yaml file or your outpost_config.py file:\n\nasync def restart_tunnels(wrapper, jupyterhub_credential):\n    if jupyterhub_credential == \"local_jupyterhub\":\n        return False\n    return True\n\nc.JupyterHubOutpost.ssh_recreate_at_start = restart_tunnels\n# c.JupyterHubOutpost.ssh_recreate_at_start = False\n</code></pre> <p>JupyterHub Outpost will use the stored JupyterHub API token to recreate the port-forwarding process. If the API token is no longer valid, this will fail. The single-user server would then be unreachable and must be restarted by the user.</p>"},{"location":"providers/configuration/#flavors","title":"Flavors","text":""},{"location":"providers/configuration/#overview","title":"Overview","text":"<p>Flavors define preconfigured resource templates for User sessions. They specify runtime limits and user constraints, helping you manage system load and provide differentiated access based on user groups or hub configurations.</p> <p>Flavors are mandatory and part of the default configuration of the Outpost. All users will have access to the default flavors unless specified otherwise.</p>"},{"location":"providers/configuration/#basic-flavor-structure","title":"Basic Flavor Structure","text":"<p>A flavor configuration typically looks like this:</p> <pre><code>flavors:\n  flavors:\n    default:\n      max: 20\n      maxPerUser: 3\n      weight: 11\n      display_name: \"Default\"\n      description: \"Service will run with normal resources for max 5 days\"\n      runtime:\n        hours: 120\n      resources:\n        cpu_guarantee: 0.1\n        cpu_limit: 1\n        mem_guarantee: \"256M\"\n        mem_limit: \"2048M\"\n</code></pre> <p>The flavors <code>default</code> and <code>minimal</code> are always active. Set them to <code>{}</code> to deactivate them. Or add a hub specific configuration (see below) and don't include <code>default</code> and <code>minimal</code> in the supported flavors for this hub.</p> <p>Resources must be used by your Spawner Configuration. </p>"},{"location":"providers/configuration/#parameters","title":"Parameters","text":"Key Description <code>display_name</code> User-facing name of the flavor <code>description</code> Description of resources or limitations <code>runtime</code> Maximum lifetime of a session using this flavor. Supported keys: days, hours, minutes <code>resources</code> Can be used to define allowed resources <code>max</code> Maximum total number of concurrent sessions using this flavor <code>maxPerUser</code> Maximum number of sessions per user using this flavor <code>weight</code> Controls the ordering in the flavor list; higher weights appear first"},{"location":"providers/configuration/#per-user-flavor-control","title":"Per-User Flavor Control","text":"<p>You can assign flavors to users based on their authentication attributes (like name, email). This allows differentiated access control. Ask the JupyterHub authenticator for the attributes, or set the log level to trace and check the Outpost logs.</p>"},{"location":"providers/configuration/#example-1-allow-minimal-flavor-for-non-company-users","title":"Example 1: Allow minimal flavor for non-company users","text":"<pre><code>users:\n  publicUsers:\n    negate_authentication: true \n    authentication:\n      name: \".*@mycompany.org\"\n    flavors: [\"minimal\"]\n    weight: 10\n</code></pre> <ul> <li>All users not ending with <code>@mycompany.org</code> are only allowed to use the <code>minimal</code> flavor.</li> </ul>"},{"location":"providers/configuration/#example-2-block-all-gmail-users","title":"Example 2: Block all Gmail users","text":"<pre><code>users:\n  googleUsers:\n    authentication:\n      name: \".*g(oogle)*mail.com$\"\n    forbidden: true\n    weight: 20\n</code></pre> <ul> <li>Users with Gmail or Google Mail addresses will be denied access.</li> </ul> <p>Each field in <code>authentication</code> (like <code>name</code>, <code>email</code>, etc.) supports multiple match types:</p> <ul> <li>A regular expression (e.g., <code>\"^user[0-9]+@example.com$\"</code>)</li> <li>A glob-style pattern (e.g., <code>\"*@example.com\"</code>)</li> <li>A literal value (e.g., <code>\"admin@example.com\"</code>)</li> <li>Or a list of allowed literal values.</li> </ul> <p>The system will try to match in this order: Regex \u2192 Glob \u2192 Exact match.</p> <p>This gives you flexibility in how users are grouped and access is granted.</p>"},{"location":"providers/configuration/#per-hub-flavor-control","title":"Per-Hub Flavor Control","text":"<p>In environments with multiple JupyterHub instances, you can configure flavors per hub using the <code>hubs</code> section:</p> <pre><code>hubs:\n  minimalhub:\n    weight: 15\n    jupyterhub_name:\n      - hubmini\n    flavors:\n      - minimal\n\n  normalhubs:\n    weight: 10\n    jupyterhub_name:\n      - huba\n      - hubb\n    flavors:\n      - default\n</code></pre> <ul> <li><code>hubmini</code> will only offer the <code>minimal</code> flavor.</li> <li><code>huba</code> and <code>hubb</code> will offer the <code>default</code> flavor.</li> </ul> <p>The <code>weight</code> controls the priority if multiple groups match \u2014 the one with the highest weight takes precedence.</p>"},{"location":"providers/configuration/#default-behavior","title":"Default Behavior","text":"<p>If no user or hub restrictions are configured:</p> <ul> <li>All defined flavors will be available to all users.</li> <li>This behavior can be overridden by defining <code>users</code> or <code>hubs</code>.</li> </ul>"},{"location":"providers/configuration/#recommendations","title":"Recommendations","text":"<ul> <li>Start with a base set of flavors (<code>minimal</code>, <code>default</code>) and refine access over time.</li> <li>Use <code>negate_authentication</code> for simple allow/deny matching logic based on patterns.</li> <li>Always test your regex for <code>name</code> carefully to avoid unintentional matches.</li> <li>Use <code>weight</code> wisely to control precedence in overlapping rules.</li> </ul>"},{"location":"providers/configuration/#use-cases","title":"Use Cases","text":"<ul> <li>Blocked Users: Administrators can configure flavors for specific users that deny access, effectively blocking them from launching any jupyter servers.</li> <li>Prioritized Users: For power users, administrators can assign more resources (e.g., higher CPU, additional memory) to ensure they have the performance needed for demanding tasks.</li> <li>External Users: For guest or external users, administrators may provide a default, minimal resource allocation to prevent overuse of the system\u2019s resources.</li> </ul>"},{"location":"providers/configuration/#benefits","title":"Benefits","text":"<ul> <li>Resource Management: Fine-grained control over resource allocation ensures efficient use of system resources.</li> <li>User Control: Administrators can easily adjust resource access based on user needs or status (e.g., external user vs internal user).</li> <li>Scalability: As your user base grows, you can easily apply different flavors to new users without major changes to the overall configuration.</li> </ul>"},{"location":"providers/configuration/#update-tokens","title":"Update Tokens","text":"<p>The JupyterHub OutpostSpawner offers an APIEndpoint, which receives or offers the current Flavors of all connected JupyterHub Outposts. With this function the Outpost will inform the connected JupyterHubs at each start/stop of a notebook server, about the current flavor situation. The corresponding URL will be given by the OutpostSpawner.</p> <pre><code>import os\nasync def flavors_update_token(jupyterhub_name):\n    token = os.environ.get(f\"FLAVOR_{jupyterhub_name.upper()}_AUTH_TOKEN\", \"\")\n    if not token:\n        raise Exception(f\"Flavor auth token for {jupyterhub_name} not configured.\")\n    return token\nc.JupyterHubOutpost.flavors_update_token = flavors_update_token\n</code></pre> <p>In case of an exception the update is not send to JupyterHub. This will not interfere with the start of the notebook server. Each connected JupyterHub must provide a service token with scope <code>custom:outpostflavors:set</code> to the Outpost administrator.</p>"},{"location":"providers/installation/","title":"Installation","text":""},{"location":"providers/installation/#kubernetes","title":"Kubernetes","text":"<p>This section covers an example installation of the JupyterHub Outpost service via helm. </p>"},{"location":"providers/installation/#requirements","title":"Requirements","text":"<p>A Kubernetes Cluster up and running.</p>"},{"location":"providers/installation/#preparations","title":"Preparations","text":"<p>We assume that the Outpost service will run in the <code>outpost</code> namespace. To authenticate the JupyterHub instance, we have to create a Kubernetes secret with username+password. </p> <pre><code>OUTPOST_PASSWORD=$(uuidgen)\n\nkubectl -n outpost create secret generic --from-literal=usernames=jupyterhub --from-literal=passwords=${OUTPOST_PASSWORD} outpost-users\n</code></pre> <p>If you want to connect multiple JupyterHubs to one JupyterHub Outpost, you have to create a secret with semicolon-separated usernames and passwords. <code>kubectl create secret generics --from-literal=usernames=one;two;three --from-literal=passwords=pw1;pw2;pw3 outpost-users</code></p> <p>An encryption key is necessary to ensure that the data in the database is encrypted.</p> <pre><code>SECRET_KEY=$(python3 -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())')\n\nkubectl -n outpost create secret generic outpost-cryptkey --from-literal=secret_key=${SECRET_KEY}\n</code></pre>"},{"location":"providers/installation/#configuration","title":"Configuration","text":"<p>You have to ask the administrator of all JupyterHubs you want to connect for their ssh-publickey. In this scenario, we're using NodePort as service types. JupyterHub must be able to reach the JupyterHub Outpost service at the ports <code>30080</code> (access to the Outpost API) and <code>30022</code> (access to ssh daemon for port-forwarding). You can configure the ports to your liking, or choose a different Service type.</p> <p>In this scenario, the communication between JupyterHub and JupyterHub Outpost will not be encrypted. Do not use this in production. You'll find an example with encryption below.</p> <p>Helm values: <pre><code>cat &lt;&lt;EOF &gt;&gt; outpost_values.yaml\n# Name of database encryption key secret\ncryptSecret: outpost-cryptkey\n# Name of JupyterHub username+password secret\noutpostUsers: outpost-users\n# ssh-publickey of JupyterHub(s) to connect\nsshPublicKeys:\n  - restrict,port-forwarding,command=\"/bin/echo No commands allowed\" $(cat jupyterhub-sshkey.pub)\n# Kubernetes service for the Outpost API\nservice:\n  type: NodePort\n  ports:\n    nodePort: 30080\n# Kubernetes service for port-forwarding\nservicessh:\n  type: NodePort\n  ports:\n    nodePort: 30022\nEOF\n</code></pre></p> <p>Check out the available options for ssh public keys here. At least port-forwarding must be allowed.</p>"},{"location":"providers/installation/#installation_1","title":"Installation","text":"<pre><code># Add JupyterHub Outpost chart repository\nhelm repo add jupyter-jsc https://kaas.pages.jsc.fz-juelich.de/helm-charts/\nhelm repo update\n# Install the JupyterHub Outpost chart in the `outpost` namespace\nhelm upgrade --install --create-namespace --version 1.0.6 --namespace outpost -f outpost_values.yaml outpost jupyter-jsc/jupyterhub-outpost\n</code></pre> <p>Ensure that everything is up and running. Double check that the ports 30080 and 30022 are reachable for JupyterHub. Contact the Jupyter4NFDI administrators to let them know how to reach your JupyterHub Outpost.</p>"},{"location":"providers/installation/#encryption-via-ingress","title":"Encryption via ingress","text":"<p>When running JupyterHub Outpost in production, you should ensure a certain level of encryption. An easy way is to use an ingress controller with a certificate. For this example we've installed cert-manager with a let's encrypt issuer and ingress-nginx. If you already have a certificate, you will only need ingress-nginx.</p> <p>This example is an addition to the examples above.</p>"},{"location":"providers/installation/#configuration_1","title":"Configuration","text":"<pre><code>FLOATING_IP_SSH=&lt;EXTERNAL_IP_FOR_SSH_ACCESS&gt;\ncat &lt;&lt;EOF &gt;&gt; outpost_remote_values_ingress.yaml\n# Name of database encryption key secret\ncryptSecret: outpost-cryptkey\n# Name of JupyterHub username+password secret\noutpostUsers: outpost-users\n# ssh-publickey of JupyterHub(s) to connect\nsshPublicKeys:\n  - restrict,port-forwarding,command=\"/bin/echo No commands allowed\" $(cat jupyterhub-sshkey.pub)\n# Kubernetes service for port-forwarding\nservicessh:\n  type: LoadBalancer\n  loadBalancerIP: ${FLOATING_IP_SSH}\n# Use ingress with TLS instead of a Kubernetes service for the Outpost API\ningress:\n  enabled: true\n  # Annotations for using LetsEncrypt as a certificate issuer\n  annotations:\n    acme.cert-manager.io/http01-edit-in-place: \"true\"\n    cert-manager.io/cluster-issuer: letsencrypt-cluster-issuer\n  hosts:\n  - myremoteoutpost.com\n  tls:\n  - hosts:\n    - myremoteoutpost.com\n    # If using LetsEncrypt, the secret will be created automatically. Otherwise, please ensure the secret exists.\n    secretName: outpost-tls-certmanager\nEOF\n</code></pre> <p>JupyterHub will now be able to reach the JupyterHub Outpost API at <code>https://myremoteoutpost.com/services</code> and the ssh daemon for port-forwarding at <code>${FLOATING_IP_SSH}</code> on port 22. Contact the Jupyter4NFDI administrators to inform them about the new addresses.</p>"},{"location":"providers/installation_including_local_unused/","title":"Installation","text":"<p>This section covers example configurations and instructions to install the JupyterHub Outpost service via helm. </p>"},{"location":"providers/installation_including_local_unused/#local-installation","title":"Local installation","text":"This chapter shows a simple installation of the JupyterHub Outpost service on the same Kubernetes cluster as JupyterHub.    If you don't want to connect external JupyterHubs (meaning JupyterHubs running on a different Kubernetes cluster than your Outpost service) to your JupyterHub Outpost, you won't need ssh port-forwarding between JupyterHub and the Outpost service. The Kubernetes internal DNS can resolve the single-user notebook servers.   Requirements  One Kubernetes cluster up and running with at least one JupyterHub installation (recommended is the use of [Zero2JupyterHub](https://z2jh.jupyter.org/en/stable/)).  Preparations  We assume that the Outpost service will run in the `outpost` namespace. To authenticate the JupyterHub instance, we have to create a Kubernetes secret  in that namespace with username+password.   <pre><code>OUTPOST_PASSWORD=$(uuidgen)\n\nkubectl -n outpost create secret generic --from-literal=usernames=jupyterhub --from-literal=passwords=${OUTPOST_PASSWORD} outpost-users\n</code></pre>   &gt; If you want to connect multiple JupyterHubs to one JupyterHub Outpost, you have to create a secret with semicolon-separated usernames and passwords.  `kubectl create secret generics --from-literal=usernames=one;two;three --from-literal=passwords=pw1;pw2;pw3 outpost-users`  An encryption key is also required, so data in the database can be encrypted.  <pre><code>SECRET_KEY=$(python3 -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())')\n\nkubectl -n outpost create secret generic outpost-cryptkey --from-literal=secret_key=${SECRET_KEY}\n</code></pre> Configuration Helm values:  <pre><code>cat &lt;&lt;EOF &gt;&gt; outpost_values.yaml\n# Name of database encryption key secret\ncryptSecret: outpost-cryptkey\n# Name of JupyterHub username+password secret\noutpostUsers: outpost-users\nEOF\n</code></pre> Installation <pre><code># Add JupyterHub Outpost chart repository\nhelm repo add jupyter-jsc https://kaas.pages.jsc.fz-juelich.de/helm-charts/\nhelm repo update\n# Install the JupyterHub Outpost chart in the `outpost` namespace\nhelm upgrade --install --create-namespace --version &lt;version&gt; --namespace outpost -f outpost_values.yaml outpost jupyter-jsc/jupyterhub-outpost\n</code></pre>  Afterwards, the administrator of each connected JupyterHub has to [update the JupyterHub OutpostSpawner configuration](https://jupyterhub-outpostspawner.readthedocs.io/en/latest/usage/installation.html) with the correct IP address + credentials for this JupyterHub Outpost service."},{"location":"providers/installation_including_local_unused/#remote-installation","title":"Remote installation","text":"This chapter shows a simple installation of the JupyterHub Outpost service on a different Kubernetes cluster than the JupyterHub.    Requirements  Two Kubernetes clusters up and running.   One with at least one JupyterHub installation (recommended is the use of [Zero2JupyterHub](https://z2jh.jupyter.org/en/stable/)), the other is used to install the JupyterHub Outpost service.  Preparations  We assume that the Outpost service will run in the `outpost` namespace. To authenticate the JupyterHub instance, we have to create a Kubernetes secret in that namespace with username+password.   <pre><code>OUTPOST_PASSWORD=$(uuidgen)\n\nkubectl -n outpost create secret generic --from-literal=usernames=jupyterhub --from-literal=passwords=${OUTPOST_PASSWORD} outpost-users\n</code></pre>  &gt; If you want to connect multiple JupyterHubs to one JupyterHub Outpost, you have to create a secret with semicolon-separated usernames and passwords.   &gt; `kubectl create secret generics --from-literal=usernames=one;two;three --from-literal=passwords=pw1;pw2;pw3 outpost-users`  An encryption key is also required, so data in the database can be encrypted.  <pre><code>SECRET_KEY=$(python3 -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())')\n\nkubectl -n outpost create secret generic outpost-cryptkey --from-literal=secret_key=${SECRET_KEY}\n</code></pre> Configuration  You have to ask the administrator of all JupyterHubs you want to connect for their ssh-publickey. In this scenario, we're using NodePort as service types. JupyterHub must be able to reach the JupyterHub Outpost service at the ports `30080` (access to the Outpost API) and `30022` (access to ssh daemon for port-forwarding).   ```{admonition} Warning In this scenario, the communication between JupyterHub and JupyterHub Outpost will not be encrypted. Do not use this in production. You'll find an example with encryption below. <pre><code>Helm values:\n```bash\ncat &lt;&lt;EOF &gt;&gt; outpost_values.yaml\n# Name of database encryption key secret\ncryptSecret: outpost-cryptkey\n# Name of JupyterHub username+password secret\noutpostUsers: outpost-users\n# ssh-publickey of JupyterHub(s) to connect\nsshPublicKeys:\n  - restrict,port-forwarding,command=\"/bin/echo No commands allowed\" $(cat jupyterhub-sshkey.pub)\n# Kubernetes service for the Outpost API\nservice:\n  type: NodePort\n  ports:\n    nodePort: 30080\n# Kubernetes service for port-forwarding\nservicessh:\n  type: NodePort\n  ports:\n    nodePort: 30022\nEOF\n</code></pre>  ```{admonition} Note  You can use the same [options](https://manpages.debian.org/experimental/openssh-server/authorized_keys.5.en.html#AUTHORIZED_KEYS_FILE_FORMAT) for each public key as in ~/.ssh/authorized_keys. At least port-forwarding must be allowed. <pre><code>&lt;h3&gt;Installation&lt;/h3&gt;\n\n```bash\n# Add JupyterHub Outpost chart repository\nhelm repo add jupyter-jsc https://kaas.pages.jsc.fz-juelich.de/helm-charts/\nhelm repo update\n# Install the JupyterHub Outpost chart in the `outpost` namespace\nhelm upgrade --install --create-namespace --version &lt;version&gt; --namespace outpost -f outpost_values.yaml outpost jupyter-jsc/jupyterhub-outpost\n</code></pre>  Ensure that everything is running. Double check that the ports 30080 and 30022 are reachable from JupyterHub.   Afterwards, you have to [update the JupyterHub OutpostSpawner configuration](https://jupyterhub-outpostspawner.readthedocs.io/en/latest/usage/installation.html) with the correct IP address + credentials for this JupyterHub Outpost service."},{"location":"providers/installation_including_local_unused/#encryption-via-ingress","title":"Encryption via ingress","text":"<p>When running JupyterHub Outpost on production, you should ensure a certain level of encryption. An easy way is to use an ingress controller with a certificate. For this example we've installed cert-manager, hairpin-proxy, let's encrypt issuer and ingress-nginx. If you already have a certificate, you will only need ingress-nginx.</p> <p>This example is an addition to the examples above.</p> Configuration <pre><code>FLOATING_IP_SSH=&lt;EXTERNAL_IP_FOR_SSH_ACCESS&gt;\ncat &lt;&lt;EOF &gt;&gt; outpost_remote_values_ingress.yaml\n# Name of database encryption key secret\ncryptSecret: outpost-cryptkey\n# Name of JupyterHub username+password secret\noutpostUsers: outpost-users\n# ssh-publickey of JupyterHub(s) to connect\nsshPublicKeys:\n  - restrict,port-forwarding,command=\"/bin/echo No commands allowed\" $(cat jupyterhub-sshkey.pub)\n# Kubernetes service for port-forwarding\nservicessh:\n  type: LoadBalancer\n  loadBalancerIP: ${FLOATING_IP_SSH}\n# Use ingress with TLS instead of a Kubernetes service for the Outpost API\ningress:\n  enabled: true\n  # Annotations for using LetsEncrypt as a certificate issuer\n  annotations:\n    acme.cert-manager.io/http01-edit-in-place: \"false\"\n    cert-manager.io/cluster-issuer: letsencrypt-cluster-issuer\n  hosts:\n  - myremoteoutpost.com\n  tls:\n  - hosts:\n    - myremoteoutpost.com\n    # If using LetsEncrypt, the secret will be created automatically. Otherwise, please ensure the secret exists.\n    secretName: outpost-tls-certmanager\nEOF\n</code></pre> <p>JupyterHub will now be able to reach the JupyterHub Outpost API at <code>https://myremoteoutpost.com/services</code> and the ssh daemon for port-forwarding at <code>${FLOATING_IP_SSH}</code> on port 22. You have to send each connected JupyterHub its credentials (defined in <code>outpost-users</code>), the <code>servicessh</code> loadBalancerIP address and the URL of your outpost service.</p>"},{"location":"users/rtc/","title":"Real-Time-Collaboration (RTC)","text":"<p>Jupyter4NFDI makes it easy to collaborate live in your JupyterLab environment. With the Real-Time Collaboration (RTC) feature, multiple users can edit notebooks, run code, and explore data together \u2014 all in the same session.</p>"},{"location":"users/rtc/#how-it-works","title":"How it works","text":"<ol> <li>Start your JupyterLab as usual.</li> <li>Go to the Jupyter4NFDI website and click on the RTC button.</li> <li>Copy the generated link and share it with your collaborators.</li> <li>They can use this link to join your running JupyterLab.</li> </ol>"},{"location":"users/rtc/#important-notes","title":"Important notes","text":"<ul> <li>Anyone with the link has full access to all files and notebooks in your JupyterLab session.</li> <li>When your session stops, all RTC shares are automatically revoked.</li> </ul> <p>\u26a0\ufe0f Be careful who you share the link with. Only give access to trusted collaborators.</p>"},{"location":"users/share/","title":"Share Button","text":"<p>In Jupyter4NFDI you can share your current configuration with your colleagues. In combination with the CustomDockerImage or Repo2Docker (Binder) services, it allows you to easily create FAIR digital objects.  </p>"},{"location":"users/share/#create-share-link","title":"Create share link","text":"<ol> <li>Click on the share button in the bottom left corner of your configuration.</li> </ol> <ol> <li>That's it. You can copy it and share it with your colleagues.</li> </ol>"},{"location":"users/share/#use-a-share-link","title":"Use a share link","text":"<ol> <li> <p>Follow the link.</p> <p>If you're not already authenticated, you have to log in first. For more information check this section. Afterwards you'll be forwarded to the desired destination.</p> </li> <li> <p>You will see the shared configuration. Click on Start to start the service.</p> </li> </ol>"},{"location":"users/storage/","title":"JupyterLab DataMount","text":""},{"location":"users/storage/#overview","title":"Overview","text":"<p>Jupyter4NFDI uses the JupyterLab DataMount extension to provide seamless access to external storage services directly within JupyterLab. By integrating multiple storage backends, it allows users to mount and interact with remote data effortlessly. The extension is especially useful for researchers and data analysts who need quick and secure access to large datasets.</p> <p>For more information about this extension click here</p>"},{"location":"users/storage/#frontend-integration","title":"Frontend Integration","text":"<p>The JupyterLab DataMount extension allows users to configure mount points before starting a JupyterLab. In Jupyter4NFDI users you do this by clicking on \"Add Storage Mount\" in the \"Storage\" tab.</p> <p>You can configure multiple storage locations from different location, or use the same location mulitple times.</p>"},{"location":"users/storage/#share-button-storage-mount","title":"Share Button + Storage Mount","text":"<p>\u26a0\ufe0f Warning: We recommend to only share readonly storage mounts. Sharing mounts with read-write access allows other users to write, manipulate, or delete your data. While technically possible, read-write sharing should only be used if you fully trust your collaborators. Anyone who knows the share ID can access the mount\u2014it's not listed publicly, but you should still treat the link as sensitive.</p> <p>The JupyterLab DataMount extension, in combination with the Share Button, enables secure and seamless collaboration using external storage\u2014without ever exposing your credentials.</p>"},{"location":"users/storage/#secure-by-design","title":"Secure by Design","text":"<ul> <li>When mounting external storage (e.g., S3, WebDAV, B2DROP), your secrets stay private.</li> <li>All sensitive information (access tokens, passwords, etc.) is stored encrypted in the backend and never exposed to other users.</li> <li>The actual mounting process runs in a dedicated sidecar container, isolated from the JupyterLab user environment\u2014so users cannot inspect, extract, or misuse secrets, even with full shell access.</li> </ul>"},{"location":"users/storage/#share-without-risk","title":"Share Without Risk","text":"<ul> <li>Use the Share Button to grant collaborators access to your mounted storage\u2014without giving them your credentials.</li> <li>Recipients get temporary, secure access to the mount itself, not the underlying secrets.</li> <li>You control visibility, scope, and revocation.</li> </ul>"},{"location":"users/storage/#example-use-cases","title":"Example Use Cases","text":"<ul> <li>A data steward sets up a shared WebDAV folder and gives researchers access via the Share Button.</li> <li>A lab technician mounts an S3 bucket with experimental data and shares read-only access with collaborators in another institution.</li> <li>A team leader creates a B2DROP mount for a shared project folder and distributes access to students\u2014with zero configuration needed on their side.</li> <li>Check out this example Repository: https://github.com/kreuzert/DataMount-ShareButton-Example</li> </ul>"},{"location":"users/storage/#why-it-matters","title":"Why It Matters","text":"<p>This approach is one-of-a-kind in the Jupyter ecosystem, as far as we know. While some services allow mounting external storage, very few (if any) combine it with user-level sharing and strict secret isolation\u2014all without requiring users to write a single line of code.</p> <p>Together, the Share Button and DataMount extension unlock the full collaborative potential of Jupyter4NFDI: making storage sharing as easy as notebook sharing, while keeping security airtight.</p>"},{"location":"users/storage/#feedback-welcome","title":"Feedback Welcome!","text":"<p>Is your preferred storage system not yet supported? Do you need a specific protocol, platform, or authentication method?</p> <p>We\u2019re actively improving the DataMount extension\u2014and your feedback helps us prioritize new features.</p> <p>Please create an issue at our GitHub repository: https://github.com/jsc-jupyter/jupyterlab-data-mount/issues</p>"},{"location":"users/jupyterlab/kernels_pyenv/","title":"Kernels pyenv","text":"Author: Jens Henrik G\u00f6bbert Index Create your own Jupyter Kernel with pyenv <p>Often the standard kernel do not provide all features you need for your work. This might be that certain modules are not loaded or packages are not installed. With your own kernel you can overcome that problem easily and define your own environment, in which you work.</p> <p>This notebook shows you how you can build your own kernel for a pyenv environment.</p> Attention: pyenv is a wonderful tool for managing multiple Python versions. You can easily try out new language features or help contribute to a project that is on a different version of Python. Using pyenv is also a great way to install pre-release versions of Python so that you can test them for bugs.  BUT, if this is not your intention and you are fine with the default Python version of your current software stage. DO NOT use pyenv - please have a look at the general (PyPI) howto called \"Create_JupyterKernel_general.ipynb\" instead.  Attention: This notebook is meant to run out of a JupyterLab on JSC's HPC systems.  In\u00a0[\u00a0]: Copied! <pre># INPUT NEEDED:\nKERNEL_NAME=${USER}_kernel_pyenv\n\nexport KERNEL_NAME=$(echo \"${KERNEL_NAME}\" | awk '{print tolower($0)}')\necho ${KERNEL_NAME} # double check\n</pre> # INPUT NEEDED: KERNEL_NAME=${USER}_kernel_pyenv  export KERNEL_NAME=$(echo \"${KERNEL_NAME}\" | awk '{print tolower($0)}') echo ${KERNEL_NAME} # double check In\u00a0[\u00a0]: Copied! <pre># define KERNEL_SPECS_DIR\nexport KERNEL_SPECS_PREFIX=${HOME}/.local\nif [ ! -d \"$KERNEL_SPECS_PREFIX\" ]; then\n  echo \"ERROR: please create directory $KERNEL_SPECS_PREFIX\"\nfi\nexport KERNEL_SPECS_DIR=${KERNEL_SPECS_PREFIX}/share/jupyter/kernels\n\n# check if kernel name is unique\nif [ -d \"${KERNEL_SPECS_DIR}/${KERNEL_NAME}\" ]; then\n  echo \"ERROR: Kernel already exists in ${KERNEL_SPECS_DIR}/${KERNEL_NAME}\"\n  echo \"       Rename kernel name or remove directory.\"\nfi\n\n# print the location of the new kernel\necho ${KERNEL_SPECS_DIR}/${KERNEL_NAME} \n</pre> # define KERNEL_SPECS_DIR export KERNEL_SPECS_PREFIX=${HOME}/.local if [ ! -d \"$KERNEL_SPECS_PREFIX\" ]; then   echo \"ERROR: please create directory $KERNEL_SPECS_PREFIX\" fi export KERNEL_SPECS_DIR=${KERNEL_SPECS_PREFIX}/share/jupyter/kernels  # check if kernel name is unique if [ -d \"${KERNEL_SPECS_DIR}/${KERNEL_NAME}\" ]; then   echo \"ERROR: Kernel already exists in ${KERNEL_SPECS_DIR}/${KERNEL_NAME}\"   echo \"       Rename kernel name or remove directory.\" fi  # print the location of the new kernel echo ${KERNEL_SPECS_DIR}/${KERNEL_NAME}  In\u00a0[\u00a0]: Copied! <pre># define KERNEL_VENVS_DIR\nexport KERNEL_VENVS_DIR=${PROJECT}/${USER}/jupyter/kernels\nmkdir -p ${KERNEL_VENVS_DIR}\n\n# print the location of the new kernel's environment\necho ${KERNEL_VENVS_DIR}\n</pre> # define KERNEL_VENVS_DIR export KERNEL_VENVS_DIR=${PROJECT}/${USER}/jupyter/kernels mkdir -p ${KERNEL_VENVS_DIR}  # print the location of the new kernel's environment echo ${KERNEL_VENVS_DIR} <p>For a pyenv environment we do not use any prebuild modules of the system. Instead we install everything from scratch with PyEnv - even Python itself.</p> <p>Just a simple command is needed to install pyenv in $PYENV_ROOT. For simplicity we install a unique pyenv environment per kernel. (more)</p> In\u00a0[\u00a0]: Copied! <pre>export PYENV_ROOT=${KERNEL_VENVS_DIR}/${KERNEL_NAME}\nif [ -d \"${PYENV_ROOT}\" ]; then\n  echo \"ERROR: Directory for the pyenv installation already exists: ${PYENV_ROOT}\"\n  echo \"       Rename kernel name or remove directory.\"\nelse\n  export PATH=\"$PYENV_ROOT/bin:$PATH\"\n  curl https://pyenv.run | bash\n  echo ${PYENV_ROOT} # double check\nfi\n\n# print the location of the new pyenv environment\necho ${PYENV_ROOT}\n</pre> export PYENV_ROOT=${KERNEL_VENVS_DIR}/${KERNEL_NAME} if [ -d \"${PYENV_ROOT}\" ]; then   echo \"ERROR: Directory for the pyenv installation already exists: ${PYENV_ROOT}\"   echo \"       Rename kernel name or remove directory.\" else   export PATH=\"$PYENV_ROOT/bin:$PATH\"   curl https://pyenv.run | bash   echo ${PYENV_ROOT} # double check fi  # print the location of the new pyenv environment echo ${PYENV_ROOT} In\u00a0[\u00a0]: Copied! <pre>export PATH=\"$PYENV_ROOT/bin:$PATH\"\neval \"$(pyenv init --path)\"\neval \"$(pyenv init -)\"\neval \"$(pyenv virtualenv-init -)\"\n</pre> export PATH=\"$PYENV_ROOT/bin:$PATH\" eval \"$(pyenv init --path)\" eval \"$(pyenv init -)\" eval \"$(pyenv virtualenv-init -)\" <p>For these steps, make sure to have a clean &amp; basic environment before starting this process.</p> In\u00a0[\u00a0]: Copied! <pre>module purge\nmodule load Stages/2025\n</pre> module purge module load Stages/2025 <ul> <li>Install a python version (e.g. <code>3.12.3</code>)</li> </ul> Attention: You are free to change the Python version here.  In\u00a0[\u00a0]: Copied! <pre>export PYTHON_VER=3.12.3\npyenv install ${PYTHON_VER}\n</pre> export PYTHON_VER=3.12.3 pyenv install ${PYTHON_VER} <ul> <li>Double check the installation</li> </ul> In\u00a0[\u00a0]: Copied! <pre>which python\nwhich pip\npython --version  # should show system python version - not the version installed above because we have not activated a virtual environment, yet.\npip list\n</pre> which python which pip python --version  # should show system python version - not the version installed above because we have not activated a virtual environment, yet. pip list In\u00a0[\u00a0]: Copied! <pre>export PYENV_ENV=${KERNEL_NAME}\nexport VIRTUAL_ENV=${KERNEL_VENVS_DIR}/${KERNEL_NAME}/versions/${PYTHON_VER}/envs/${PYENV_ENV}\nif [ -d \"${VIRTUAL_ENV}\" ]; then\n  echo \"ERROR: Directory for virtual environment already ${VIRTUAL_ENV}\"\n  echo \"       Rename kernel name or remove directory.\"\nelse\n  pyenv virtualenv ${PYTHON_VER} ${PYENV_ENV}\n  echo ${VIRTUAL_ENV} # double check\nfi\n</pre> export PYENV_ENV=${KERNEL_NAME} export VIRTUAL_ENV=${KERNEL_VENVS_DIR}/${KERNEL_NAME}/versions/${PYTHON_VER}/envs/${PYENV_ENV} if [ -d \"${VIRTUAL_ENV}\" ]; then   echo \"ERROR: Directory for virtual environment already ${VIRTUAL_ENV}\"   echo \"       Rename kernel name or remove directory.\" else   pyenv virtualenv ${PYTHON_VER} ${PYENV_ENV}   echo ${VIRTUAL_ENV} # double check fi In\u00a0[\u00a0]: Copied! <pre>pyenv deactivate\npyenv activate ${PYENV_ENV}\n</pre> pyenv deactivate pyenv activate ${PYENV_ENV} <p>Jupyter requires the <code>ipykernel</code> module and its dependencies.</p> In\u00a0[\u00a0]: Copied! <pre>which python\npython --version  # should show new installed python version (here 3.12.3)\n</pre> which python python --version  # should show new installed python version (here 3.12.3) Attention: Now you can add extra Python packages you need.  In\u00a0[\u00a0]: Copied! <pre>if [ -z \"${VIRTUAL_ENV}\" ]; then\n  echo \"ERROR: Virtual environment not successfully initialized.\"\nelse\n  echo \"Installing custom Python packages using pip from the virtual environment:\"\n  which pip\n  pip install ipykernel\n  # pip install &lt;python-package you need&gt;\nfi\n</pre> if [ -z \"${VIRTUAL_ENV}\" ]; then   echo \"ERROR: Virtual environment not successfully initialized.\" else   echo \"Installing custom Python packages using pip from the virtual environment:\"   which pip   pip install ipykernel   # pip install  fi In\u00a0[\u00a0]: Copied! <pre># double check\necho ${PYENV_ENV}\necho ${PYENV_ROOT}\necho ${VIRTUAL_ENV}\n</pre> # double check echo ${PYENV_ENV} echo ${PYENV_ROOT} echo ${VIRTUAL_ENV} In\u00a0[\u00a0]: Copied! <pre>echo '#!/bin/bash\n\nmodule purge\nmodule load Stages/2025\n\nexport PYENV_ROOT='\"$PYENV_ROOT\"'\nexport PATH='\"$PYENV_ROOT\"'/bin:'\"$PATH\"'\neval \"$(pyenv init --path)\"\neval \"$(pyenv init -)\"\neval \"$(pyenv virtualenv-init -)\"\n\n# Activate your Python virtual environment\npyenv activate '\"${PYENV_ENV}\"'\n\nexec python -Xfrozen_modules=off -m ipykernel $@' &gt; ${VIRTUAL_ENV}/kernel.sh\nchmod +x ${VIRTUAL_ENV}/kernel.sh\n\necho ${VIRTUAL_ENV}/kernel.sh\ncat ${VIRTUAL_ENV}/kernel.sh # double check\n</pre> echo '#!/bin/bash  module purge module load Stages/2025  export PYENV_ROOT='\"$PYENV_ROOT\"' export PATH='\"$PYENV_ROOT\"'/bin:'\"$PATH\"' eval \"$(pyenv init --path)\" eval \"$(pyenv init -)\" eval \"$(pyenv virtualenv-init -)\"  # Activate your Python virtual environment pyenv activate '\"${PYENV_ENV}\"'  exec python -Xfrozen_modules=off -m ipykernel $@' &gt; ${VIRTUAL_ENV}/kernel.sh chmod +x ${VIRTUAL_ENV}/kernel.sh  echo ${VIRTUAL_ENV}/kernel.sh cat ${VIRTUAL_ENV}/kernel.sh # double check In\u00a0[\u00a0]: Copied! <pre>export VIRTUAL_ENV_KERNELS=${VIRTUAL_ENV}/share/jupyter/kernels\necho ${VIRTUAL_ENV_KERNELS}\n</pre> export VIRTUAL_ENV_KERNELS=${VIRTUAL_ENV}/share/jupyter/kernels echo ${VIRTUAL_ENV_KERNELS} In\u00a0[\u00a0]: Copied! <pre>mkdir -p ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}\n\necho '{\n  \"argv\": [\n    \"'${VIRTUAL_ENV}/kernel.sh'\",\n    \"-m\",\n    \"ipykernel_launcher\",\n    \"-f\",\n    \"{connection_file}\"\n  ],\n  \"display_name\": \"'${KERNEL_NAME}'\",\n  \"language\": \"python\",\n  \"metadata\": {\n   \"debugger\": true\n  }\n}' &gt; ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json\n\necho ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json\ncat ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json # double check\n</pre> mkdir -p ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}  echo '{   \"argv\": [     \"'${VIRTUAL_ENV}/kernel.sh'\",     \"-m\",     \"ipykernel_launcher\",     \"-f\",     \"{connection_file}\"   ],   \"display_name\": \"'${KERNEL_NAME}'\",   \"language\": \"python\",   \"metadata\": {    \"debugger\": true   } }' &gt; ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json  echo ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json cat ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json # double check In\u00a0[\u00a0]: Copied! <pre>mkdir -p ${KERNEL_SPECS_DIR}\ncd ${KERNEL_SPECS_DIR}\nln -s ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME} .\n\necho -e \"\\n\\nThe new kernel '${KERNEL_NAME}' was added to your kernels in '${KERNEL_SPECS_DIR}/'\\n\"\nls ${KERNEL_SPECS_DIR} # double check\n</pre> mkdir -p ${KERNEL_SPECS_DIR} cd ${KERNEL_SPECS_DIR} ln -s ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME} .  echo -e \"\\n\\nThe new kernel '${KERNEL_NAME}' was added to your kernels in '${KERNEL_SPECS_DIR}/'\\n\" ls ${KERNEL_SPECS_DIR} # double check"},{"location":"users/jupyterlab/kernels_pyenv/#building-your-own-jupyter-kernel-is-a-four-step-process","title":"Building your own Jupyter kernel is a four step process\u00b6","text":"<ol> <li>Install pyenv<ul> <li>run the pyenv installation</li> </ul> </li> <li>Create/Pimp new virtual Python environment<ul> <li>venv</li> </ul> </li> <li>Create/Edit launch script for the Jupyter kernel<ul> <li>kernel.sh</li> </ul> </li> <li>Create/Edit Jupyter kernel configuration<ul> <li>kernel.json</li> </ul> </li> </ol>"},{"location":"users/jupyterlab/kernels_pyenv/#settings","title":"Settings\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#set-the-kernel-name","title":"Set the kernel name\u00b6","text":"<ul> <li>must be lower case</li> <li>change if you like</li> </ul>"},{"location":"users/jupyterlab/kernels_pyenv/#set-the-kernel-directory","title":"Set the kernel directory\u00b6","text":"<ul> <li>check that the kernel name is unique</li> <li>print the location of the new kernel</li> </ul>"},{"location":"users/jupyterlab/kernels_pyenv/#set-the-kernels-pyenv-environment","title":"Set the kernel's pyenv environment\u00b6","text":"<ul> <li>by default it is located at $PROJECT</li> <li>print the location of the new kernels pyenv environment</li> </ul>"},{"location":"users/jupyterlab/kernels_pyenv/#1-install-a-new-pyenv","title":"1. Install a new PyEnv\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#11-get-all-needed-data-for-a-pyenv-installation","title":"1.1 - Get all needed data for a pyenv installation\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#12-initialize-the-pyenv-installation","title":"1.2 - Initialize the pyenv installation\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#13-install-basic-packages-in-the-new-pyenv-installation","title":"1.3 - Install basic packages in the new pyenv installation\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#2-createpimp-new-virtual-python-environment","title":"2. Create/Pimp new virtual Python environment\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#21-create-and-activate-a-virtual-environment-for-the-kernel","title":"2.1 - Create and activate a virtual environment for the kernel\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#22-install-whatever-else-you-need-in-your-python-virtual-environment-using-pip","title":"2.2 - Install whatever else you need in your Python virtual environment (using pip)\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#3-createedit-launch-script-for-the-jupyter-kernel","title":"3. Create/Edit launch script for the Jupyter kernel\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#31-create-launch-script-which-loads-your-python-virtual-environment-and-starts-the-ipykernel-process-inside","title":"3.1 - Create launch script, which loads your Python virtual environment and starts the ipykernel process inside:\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#4-createedit-jupyter-kernel-configuration","title":"4. Create/Edit Jupyter kernel configuration\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#41-create-and-adjust-the-kerneljson-file","title":"4.1 - Create and adjust the kernel.json file\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#42-create-link-to-kernel-specs","title":"4.2 - Create link to kernel specs\u00b6","text":""},{"location":"users/jupyterlab/kernels_pyenv/#43-use-the-kernel","title":"4.3 - Use the kernel\u00b6","text":"<ul> <li>You can select the new kernel in the top right corner of your notebook or from JupyterLab's Launchpad</li> <li>The kernel icon will be added to your launcher, after a while by JupyterLab automatically or once you've restarted the JupyterLab</li> </ul>"},{"location":"users/jupyterlab/4.3/","title":"JupyterLab XL","text":"<p>This is the current default version of JupyterLab on Jupyter4NFDI. In the next sections we will describe how you can modify it to fit your needs, and give a brief overview of the installed software.</p>"},{"location":"users/jupyterlab/4.3/#systems-available","title":"Systems Available","text":"<p>JupyterLab XL is available on these systems:</p> <ul> <li>JSC-Cloud</li> </ul> <p>On JSC-Cloud only files in <code>/home/jovyan</code> are stored persistently. Everything else will be lost after a restart.</p>"},{"location":"users/jupyterlab/4.3/#pre-installed-kernels","title":"Pre-installed kernels","text":"<p>The kernels listed in this documentation may not always be up-to-date, as they can change periodically. For the current list of available kernels, please check the web service. The configuration files used to install these kernels are stored here in our GitHub repository.</p> <ul> <li>Bash</li> <li>Cling</li> <li>Java</li> <li>Julia</li> <li>LFortran</li> <li>Octave</li> <li>PyHPC</li> <li>PyDeepLearning</li> <li>PyEarthSystem</li> <li>PyVisualization</li> <li>R</li> <li>Ruby</li> </ul> <p>You can select them by navigating to the Kernels and Extensions tab on the left side of your configuration.</p>"},{"location":"users/jupyterlab/4.3/#kernel-customization","title":"Kernel customization","text":"<p>It might be easier to create your own environment using Repo2Docker.  </p> <p>Since JupyterLab 4.3 uses software loaded via lmod, one cannot simply install a kernel without loading these modules first. Please follow the steps in the these guides to create your own kernel.  </p> <p>Having trouble setting up kernels? Check the logs at <code>/tmp/custom/logs/stdout</code> in your JupyterLab.</p> <ul> <li>Create kernel with virtualenv</li> </ul>"},{"location":"users/jupyterlab/4.3/#extensions","title":"Extensions","text":"<p>The extensions listed in this documentation may not always be up-to-date, as they can change periodically. For the current list of available extensions, please check the web service. The configuration files used to install these extensions are stored here in our GitHub repository.</p> <ul> <li>Jupyter AI</li> <li>Jupyter Archive</li> <li>Jupyter Bokeh</li> <li>Jupyter Collaboration</li> <li>Jupyter Resource Usage</li> <li>Jupyter Server Proxy</li> <li>Jupyter Slurm Provisioner</li> <li>JupyterLab Code Formatter</li> <li>JupyterLab favorites</li> <li>JupyterLab Git</li> <li>JupyterLab GitHub</li> <li>JupyterLab GitLab</li> <li>JupyterLab H5Web</li> <li>ipyvue</li> <li>Kernel Gateway</li> <li>JupyterLab LaTeX</li> <li>nbdev</li> <li>NGLview</li> <li>JupyterLab nvdashboard</li> <li>JupyterLab Sidecar</li> <li>JupyterLab Spellchecker</li> <li>JupyterLab Tour</li> <li>JupyterLab Trame Manager</li> <li>JupyterLab VariableInspector</li> <li>JupyterView</li> <li>Voila</li> </ul> <p>Most extensions are always loaded. Others can be activated to your liking in the Kernels and Extensions tab in your JupyterLab configuration.</p>"},{"location":"users/jupyterlab/4.3/#proxies","title":"Proxies","text":"<ul> <li>Xpra Remote Desktop</li> <li>VSCode</li> <li>RStudio</li> <li>NEST Desktop</li> </ul>"},{"location":"users/jupyterlab/4.3/kernels_venv/","title":"Kernels venv","text":"Author: Jens Henrik G\u00f6bbert Index Create your own Jupyter Kernel <p>Often the standard kernel do not provide all features you need for your work. This might be that certain modules are not loaded or packages are not installed. With your own kernel you can overcome that problem easily and define your own environment, in which you work.</p> <p>This notebook shows you how you can build your own kernel for a python environment.</p> Attention: This notebook is meant to run out of a JupyterLab on JSC's HPC systems.  In\u00a0[1]: Copied! <pre># INPUT NEEDED:\nKERNEL_NAME=MyKernel\n\nexport KERNEL_NAME=$(echo \"${KERNEL_NAME}\" | awk '{print tolower($0)}')\necho ${KERNEL_NAME} # double check\n</pre> # INPUT NEEDED: KERNEL_NAME=MyKernel  export KERNEL_NAME=$(echo \"${KERNEL_NAME}\" | awk '{print tolower($0)}') echo ${KERNEL_NAME} # double check <pre>mykernel\n</pre> In\u00a0[3]: Copied! <pre># define KERNEL_SPECS_DIR\nexport KERNEL_SPECS_PREFIX=${HOME}/.local\nif [ ! -d \"$KERNEL_SPECS_PREFIX\" ]; then\n  echo \"ERROR: please create directory $KERNEL_SPECS_PREFIX\"\nfi\nexport KERNEL_SPECS_DIR=${KERNEL_SPECS_PREFIX}/share/jupyter/kernels\n\n# check if kernel name is unique\nif [ -d \"${KERNEL_SPECS_DIR}/${KERNEL_NAME}\" ]; then\n  echo \"ERROR: Kernel already exists in ${KERNEL_SPECS_DIR}/${KERNEL_NAME}\"\n  echo \"       Rename kernel name or remove directory.\"\nfi\n\n# print the location of the new kernel\necho ${KERNEL_SPECS_DIR}/${KERNEL_NAME} \n</pre> # define KERNEL_SPECS_DIR export KERNEL_SPECS_PREFIX=${HOME}/.local if [ ! -d \"$KERNEL_SPECS_PREFIX\" ]; then   echo \"ERROR: please create directory $KERNEL_SPECS_PREFIX\" fi export KERNEL_SPECS_DIR=${KERNEL_SPECS_PREFIX}/share/jupyter/kernels  # check if kernel name is unique if [ -d \"${KERNEL_SPECS_DIR}/${KERNEL_NAME}\" ]; then   echo \"ERROR: Kernel already exists in ${KERNEL_SPECS_DIR}/${KERNEL_NAME}\"   echo \"       Rename kernel name or remove directory.\" fi  # print the location of the new kernel echo ${KERNEL_SPECS_DIR}/${KERNEL_NAME}  <pre>/home/jovyan/.local/share/jupyter/kernels/mykernel\n</pre> In\u00a0[5]: Copied! <pre># define KERNEL_VENVS_DIR\nexport KERNEL_VENVS_DIR=/home/jovyan/jupyter/kernels\nmkdir -p ${KERNEL_VENVS_DIR}\n\n# print the location of the new kernels virtual environment\necho ${KERNEL_VENVS_DIR}\n</pre> # define KERNEL_VENVS_DIR export KERNEL_VENVS_DIR=/home/jovyan/jupyter/kernels mkdir -p ${KERNEL_VENVS_DIR}  # print the location of the new kernels virtual environment echo ${KERNEL_VENVS_DIR} <pre>/home/jovyan/jupyter/kernels\n</pre> In\u00a0[6]: Copied! <pre>module purge\nmodule load Stages/2025 # any stage can be used\nmodule load GCC\nmodule load Python      # only Python is mandatory\n</pre> module purge module load Stages/2025 # any stage can be used module load GCC module load Python      # only Python is mandatory <pre>The following modules were not unloaded:\n  (Use \"module --force purge\" to unload all):\n\n  1) Stages/2025\n</pre> In\u00a0[7]: Copied! <pre># get Python version\nexport PYV=$(python -c 'import sys; print(\".\".join(map(str, sys.version_info[:2])))')\necho $PYV\n</pre> # get Python version export PYV=$(python -c 'import sys; print(\".\".join(map(str, sys.version_info[:2])))') echo $PYV <pre>3.12\n</pre> In\u00a0[\u00a0]: Copied! <pre># module load &lt;module you need&gt;\n</pre> # module load  In\u00a0[8]: Copied! <pre>export VIRTUAL_ENV=${KERNEL_VENVS_DIR}/${KERNEL_NAME}\nif [ -d \"${VIRTUAL_ENV}\" ]; then\n  echo \"ERROR: Directory for virtual environment already ${VIRTUAL_ENV}\"\n  echo \"       Rename kernel name or remove directory.\"\nelse\n  python -m venv --system-site-packages ${VIRTUAL_ENV}\n  source ${VIRTUAL_ENV}/bin/activate\n  export PYTHONPATH=${VIRTUAL_ENV}/lib/python${PYV}/site-packages:${PYTHONPATH}\n  echo ${VIRTUAL_ENV} # double check\nfi\n</pre> export VIRTUAL_ENV=${KERNEL_VENVS_DIR}/${KERNEL_NAME} if [ -d \"${VIRTUAL_ENV}\" ]; then   echo \"ERROR: Directory for virtual environment already ${VIRTUAL_ENV}\"   echo \"       Rename kernel name or remove directory.\" else   python -m venv --system-site-packages ${VIRTUAL_ENV}   source ${VIRTUAL_ENV}/bin/activate   export PYTHONPATH=${VIRTUAL_ENV}/lib/python${PYV}/site-packages:${PYTHONPATH}   echo ${VIRTUAL_ENV} # double check fi <pre>/home/jovyan/jupyter/kernels/mykernel\n</pre> In\u00a0[9]: Copied! <pre>which pip\nif [ -z \"${VIRTUAL_ENV}\" ]; then\n  echo \"ERROR: Virtual environment not successfully initialized.\"\nelse\n  pip install ipykernel\nfi\n</pre> which pip if [ -z \"${VIRTUAL_ENV}\" ]; then   echo \"ERROR: Virtual environment not successfully initialized.\" else   pip install ipykernel fi <pre>~/jupyter/kernels/mykernel/bin/pip\nCollecting ipykernel\n  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\nCollecting comm&gt;=0.1.1 (from ipykernel)\n  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\nCollecting debugpy&gt;=1.6.5 (from ipykernel)\n  Downloading debugpy-1.8.13-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nCollecting ipython&gt;=7.23.1 (from ipykernel)\n  Downloading ipython-9.0.2-py3-none-any.whl.metadata (4.3 kB)\nCollecting jupyter-client&gt;=6.1.12 (from ipykernel)\n  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\nCollecting jupyter-core!=5.0.*,&gt;=4.12 (from ipykernel)\n  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\nCollecting matplotlib-inline&gt;=0.1 (from ipykernel)\n  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\nCollecting nest-asyncio (from ipykernel)\n  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: packaging in /p/software/jsccloud/stages/2025/software/Python/3.12.3-GCCcore-13.3.0/lib/python3.12/site-packages (from ipykernel) (24.0)\nCollecting psutil (from ipykernel)\n  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\nCollecting pyzmq&gt;=24 (from ipykernel)\n  Downloading pyzmq-26.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.2 kB)\nCollecting tornado&gt;=6.1 (from ipykernel)\n  Downloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nCollecting traitlets&gt;=5.4.0 (from ipykernel)\n  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\nCollecting decorator (from ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\nCollecting ipython-pygments-lexers (from ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\nCollecting jedi&gt;=0.16 (from ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\nCollecting pexpect&gt;4.3 (from ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\nCollecting prompt_toolkit&lt;3.1.0,&gt;=3.0.41 (from ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading prompt_toolkit-3.0.50-py3-none-any.whl.metadata (6.6 kB)\nCollecting pygments&gt;=2.4.0 (from ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\nCollecting stack_data (from ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\nCollecting python-dateutil&gt;=2.8.2 (from jupyter-client&gt;=6.1.12-&gt;ipykernel)\n  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\nCollecting platformdirs&gt;=2.5 (from jupyter-core!=5.0.*,&gt;=4.12-&gt;ipykernel)\n  Downloading platformdirs-4.3.7-py3-none-any.whl.metadata (11 kB)\nCollecting parso&lt;0.9.0,&gt;=0.8.4 (from jedi&gt;=0.16-&gt;ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\nCollecting ptyprocess&gt;=0.5 (from pexpect&gt;4.3-&gt;ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting wcwidth (from prompt_toolkit&lt;3.1.0,&gt;=3.0.41-&gt;ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\nCollecting six&gt;=1.5 (from python-dateutil&gt;=2.8.2-&gt;jupyter-client&gt;=6.1.12-&gt;ipykernel)\n  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\nCollecting executing&gt;=1.2.0 (from stack_data-&gt;ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\nCollecting asttokens&gt;=2.1.0 (from stack_data-&gt;ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\nCollecting pure-eval (from stack_data-&gt;ipython&gt;=7.23.1-&gt;ipykernel)\n  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 117.2/117.2 kB 4.2 MB/s eta 0:00:00\nDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\nDownloading debugpy-1.8.13-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 4.2/4.2 MB 19.7 MB/s eta 0:00:00:00:01\nDownloading ipython-9.0.2-py3-none-any.whl (600 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 600.5/600.5 kB 3.5 MB/s eta 0:00:00:00:01\nDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 106.1/106.1 kB 4.7 MB/s eta 0:00:00\nDownloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\nDownloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\nDownloading pyzmq-26.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (859 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 859.9/859.9 kB 6.6 MB/s eta 0:00:00:00:01\nDownloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 437.2/437.2 kB 7.1 MB/s eta 0:00:00:00:01\nDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 85.4/85.4 kB 3.5 MB/s eta 0:00:00\nDownloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\nDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 278.0/278.0 kB 4.0 MB/s eta 0:00:00:00:01\nDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.6/1.6 MB 18.4 MB/s eta 0:00:00:00:01\nDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 63.8/63.8 kB 2.3 MB/s eta 0:00:00\nDownloading platformdirs-4.3.7-py3-none-any.whl (18 kB)\nDownloading prompt_toolkit-3.0.50-py3-none-any.whl (387 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 387.8/387.8 kB 4.2 MB/s eta 0:00:00:00:01\nDownloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 1.2/1.2 MB 9.4 MB/s eta 0:00:000:00:01\nDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 229.9/229.9 kB 2.5 MB/s eta 0:00:00:00:01\nDownloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\nDownloading ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\nDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\nDownloading asttokens-3.0.0-py3-none-any.whl (26 kB)\nDownloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\nDownloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n   \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 103.7/103.7 kB 4.1 MB/s eta 0:00:00\nDownloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\nDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\nDownloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\nDownloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\nInstalling collected packages: wcwidth, pure-eval, ptyprocess, traitlets, tornado, six, pyzmq, pygments, psutil, prompt_toolkit, platformdirs, pexpect, parso, nest-asyncio, executing, decorator, debugpy, asttokens, stack_data, python-dateutil, matplotlib-inline, jupyter-core, jedi, ipython-pygments-lexers, comm, jupyter-client, ipython, ipykernel\nSuccessfully installed asttokens-3.0.0 comm-0.2.2 debugpy-1.8.13 decorator-5.2.1 executing-2.2.0 ipykernel-6.29.5 ipython-9.0.2 ipython-pygments-lexers-1.1.1 jedi-0.19.2 jupyter-client-8.6.3 jupyter-core-5.7.2 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 parso-0.8.4 pexpect-4.9.0 platformdirs-4.3.7 prompt_toolkit-3.0.50 psutil-7.0.0 ptyprocess-0.7.0 pure-eval-0.2.3 pygments-2.19.1 python-dateutil-2.9.0.post0 pyzmq-26.3.0 six-1.17.0 stack_data-0.6.3 tornado-6.4.2 traitlets-5.14.3 wcwidth-0.2.13\n\n[notice] A new release of pip is available: 24.0 -&gt; 25.0.1\n[notice] To update, run: pip install --upgrade pip\n</pre> In\u00a0[\u00a0]: Copied! <pre>#pip install &lt;python-package you need&gt;\n</pre> #pip install  In\u00a0[10]: Copied! <pre>echo '#!/bin/bash'\"\n\n# Load basic Python module\nmodule purge\nmodule load Stages/2025\nmodule load GCC\nmodule load Python\n\n# Load extra modules you need for your kernel (as you did in step 1.2)\n#module load &lt;module you need&gt;\n\n# Activate your Python virtual environment\nsource ${VIRTUAL_ENV}/bin/activate\n    \n# Ensure python packages installed in the virtual environment are always prefered\nexport PYTHONPATH=${VIRTUAL_ENV}/lib/python${PYV}/site-packages:\"'${PYTHONPATH}'\"\n    \nexec python -m ipykernel \"'$@' &gt; ${VIRTUAL_ENV}/kernel.sh\nchmod +x ${VIRTUAL_ENV}/kernel.sh\n\ncat ${VIRTUAL_ENV}/kernel.sh # double check\n</pre> echo '#!/bin/bash'\"  # Load basic Python module module purge module load Stages/2025 module load GCC module load Python  # Load extra modules you need for your kernel (as you did in step 1.2) #module load   # Activate your Python virtual environment source ${VIRTUAL_ENV}/bin/activate      # Ensure python packages installed in the virtual environment are always prefered export PYTHONPATH=${VIRTUAL_ENV}/lib/python${PYV}/site-packages:\"'${PYTHONPATH}'\"      exec python -m ipykernel \"'$@' &gt; ${VIRTUAL_ENV}/kernel.sh chmod +x ${VIRTUAL_ENV}/kernel.sh  cat ${VIRTUAL_ENV}/kernel.sh # double check <pre>#!/bin/bash\n\n# Load basic Python module\nmodule purge\nmodule load Stages/2025\nmodule load GCC\nmodule load Python\n\n# Load extra modules you need for your kernel (as you did in step 1.2)\n#module load &lt;module you need&gt;\n\n# Activate your Python virtual environment\nsource /home/jovyan/jupyter/kernels/mykernel/bin/activate\n    \n# Ensure python packages installed in the virtual environment are always prefered\nexport PYTHONPATH=/home/jovyan/jupyter/kernels/mykernel/lib/python3.12/site-packages:${PYTHONPATH}\n    \nexec python -m ipykernel $@\n</pre> In\u00a0[11]: Copied! <pre>python -m ipykernel install --name=${KERNEL_NAME} --prefix ${VIRTUAL_ENV}\nexport VIRTUAL_ENV_KERNELS=${VIRTUAL_ENV}/share/jupyter/kernels\n</pre> python -m ipykernel install --name=${KERNEL_NAME} --prefix ${VIRTUAL_ENV} export VIRTUAL_ENV_KERNELS=${VIRTUAL_ENV}/share/jupyter/kernels <pre>Installed kernelspec mykernel in /home/jovyan/jupyter/kernels/mykernel/share/jupyter/kernels/mykernel\n</pre> In\u00a0[12]: Copied! <pre>mv ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json.orig\n\necho '{\n  \"argv\": [\n    \"'${KERNEL_VENVS_DIR}/${KERNEL_NAME}/kernel.sh'\",\n    \"-m\",\n    \"ipykernel_launcher\",\n    \"-f\",\n    \"{connection_file}\"\n  ],\n  \"display_name\": \"'${KERNEL_NAME}'\",\n  \"language\": \"python\",\n  \"metadata\": {\n   \"debugger\": true\n  }\n}' &gt; ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json\n\ncat ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json # double check\n</pre> mv ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json.orig  echo '{   \"argv\": [     \"'${KERNEL_VENVS_DIR}/${KERNEL_NAME}/kernel.sh'\",     \"-m\",     \"ipykernel_launcher\",     \"-f\",     \"{connection_file}\"   ],   \"display_name\": \"'${KERNEL_NAME}'\",   \"language\": \"python\",   \"metadata\": {    \"debugger\": true   } }' &gt; ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json  cat ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME}/kernel.json # double check <pre>{\n  \"argv\": [\n    \"/home/jovyan/jupyter/kernels/mykernel/kernel.sh\",\n    \"-m\",\n    \"ipykernel_launcher\",\n    \"-f\",\n    \"{connection_file}\"\n  ],\n  \"display_name\": \"mykernel\",\n  \"language\": \"python\",\n  \"metadata\": {\n   \"debugger\": true\n  }\n}\n</pre> In\u00a0[13]: Copied! <pre>mkdir -p ${KERNEL_SPECS_DIR}\ncd ${KERNEL_SPECS_DIR}\nln -s ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME} .\n\necho -e \"\\n\\nThe new kernel '${KERNEL_NAME}' was added to your kernels in '${KERNEL_SPECS_DIR}/'\\n\"\nls ${KERNEL_SPECS_DIR} # double check\n</pre> mkdir -p ${KERNEL_SPECS_DIR} cd ${KERNEL_SPECS_DIR} ln -s ${VIRTUAL_ENV_KERNELS}/${KERNEL_NAME} .  echo -e \"\\n\\nThe new kernel '${KERNEL_NAME}' was added to your kernels in '${KERNEL_SPECS_DIR}/'\\n\" ls ${KERNEL_SPECS_DIR} # double check <pre>\n\nThe new kernel 'mykernel' was added to your kernels in '/home/jovyan/.local/share/jupyter/kernels/'\n\nabc  mykernel\n</pre> In\u00a0[14]: Copied! <pre>deactivate\n</pre> deactivate In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"users/jupyterlab/4.3/kernels_venv/#building-your-own-jupyter-kernel-is-a-three-step-process","title":"Building your own Jupyter kernel is a three step process\u00b6","text":"<ol> <li>Create/Pimp new virtual Python environment<ul> <li>venv</li> </ul> </li> <li>Create/Edit launch script for the Jupyter kernel<ul> <li>kernel.sh</li> </ul> </li> <li>Create/Edit Jupyter kernel configuration<ul> <li>kernel.json</li> </ul> </li> </ol>"},{"location":"users/jupyterlab/4.3/kernels_venv/#settings","title":"Settings\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#set-the-kernel-name","title":"Set the kernel name\u00b6","text":"<ul> <li>must be lower case</li> <li>change if you like</li> </ul>"},{"location":"users/jupyterlab/4.3/kernels_venv/#set-the-kernel-directory","title":"Set the kernel directory\u00b6","text":"<ul> <li>check that the kernel name is unique</li> <li>print the location of the new kernel</li> </ul>"},{"location":"users/jupyterlab/4.3/kernels_venv/#set-the-kernels-virtual-environment","title":"Set the kernel's virtual environment\u00b6","text":"<ul> <li>by default it is located at $PROJECT</li> <li>print the location of the new kernels virtual environment</li> </ul>"},{"location":"users/jupyterlab/4.3/kernels_venv/#1-createpimp-new-virtual-python-environment","title":"1. Create/Pimp new virtual Python environment\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#11-load-basic-python-module","title":"1.1 - Load basic Python module\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#12-load-extra-modules-you-need-for-your-kernel","title":"1.2 - Load extra modules you need for your kernel\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#13-create-and-activate-a-virtual-environment-for-the-kernel","title":"1.3 - Create and activate a virtual environment for the kernel\u00b6","text":"<p>and ensure python packages installed in the virtual environment are always prefered</p>"},{"location":"users/jupyterlab/4.3/kernels_venv/#14-install-python-libraries-required-for-communication-with-jupyter","title":"1.4 - Install Python libraries required for communication with Jupyter\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#15-install-whatever-else-you-need-in-your-python-virtual-environment-using-pip","title":"1.5 - Install whatever else you need in your Python virtual environment (using pip)\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#2-createedit-launch-script-for-the-jupyter-kernel","title":"2. Create/Edit launch script for the Jupyter kernel\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#21-create-launch-script-which-loads-your-python-virtual-environment-and-starts-the-ipykernel-process-inside","title":"2.1 - Create launch script, which loads your Python virtual environment and starts the ipykernel process inside:\u00b6","text":"Attention: You MUST load the exactly the same modules as you did above for your virtual Python environment."},{"location":"users/jupyterlab/4.3/kernels_venv/#3-createedit-jupyter-kernel-configuration","title":"3. Create/Edit Jupyter kernel configuration\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#31-create-jupyter-kernel-configuration-directory-and-files","title":"3.1 - Create Jupyter kernel configuration directory and files\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#32-adjust-kerneljson-file","title":"3.2 - Adjust kernel.json file\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#33-create-link-to-kernel-specs","title":"3.3 - Create link to kernel specs\u00b6","text":""},{"location":"users/jupyterlab/4.3/kernels_venv/#34-use-the-kernel","title":"3.4 - Use the kernel\u00b6","text":"<ul> <li>You can select the new kernel in the top right corner of your notebook or from JupyterLab's Launchpad</li> <li>The kernel icon will be added to your launcher, after a while by JupyterLab automatically or once you've restarted the JupyterLab</li> </ul>"},{"location":"users/jupyterlab/4.3/kernels_venv/#4-cleanup","title":"4. Cleanup\u00b6","text":""},{"location":"users/jupyterlab/customdockerimage/","title":"Custom Docker Images","text":"<p>Users can leverage Custom Docker Images, enabling them to create and use tailored computing environments. This feature allows for pre-installed libraries and configurations specific to your project's requirements, enhancing reproducibility and collaboration. You can use one of the many jupyter images as a starting point, or start from scratch. The only requirement is that the Docker image must be capable of running the <code>jupyterhub-singleuser</code> command. This means it needs to have JupyterHub installed, ensuring compatibility with the JupyterHub infrastructure.</p>"},{"location":"users/jupyterlab/customdockerimage/#systems-available","title":"Systems Available","text":"<p>Custom Docker Images are available on these systems:</p> <ul> <li>deNBI-Cloud</li> <li>JSC-Cloud</li> </ul>"},{"location":"users/jupyterlab/customdockerimage/#options","title":"Options","text":""},{"location":"users/jupyterlab/customdockerimage/#image","title":"Image","text":"<p>You can specify an image from Docker Hub, such as <code>jupyter/datascience-notebook</code>. You can also provide a link to another container registry, including the desired image, such as <code>https://registry.example.com/myimage:latest</code>.</p> <p>When using a private registry, make sure to provide the complete path, even though the registry URL is repeated in the subsequent section.</p>"},{"location":"users/jupyterlab/customdockerimage/#private-registry","title":"Private Registry","text":"<p>If you wish to use a private registry, you must provide some additional information so that Jupyter4NFDI can retrieve the Docker image.</p> <ul> <li>Image Registry: Enter the URL of your private registry (e.g., <code>https://registry.example.com</code>).</li> <li>Username: Provide the username required to access the private registry.</li> <li>Password: Enter the password for accessing the private registry.</li> </ul> <p>It\u2019s recommended to use an access token or application credentials instead of your user account.</p> <p>The password will be stored in an encrypted format within the Jupyter4NFDI database. If you delete the JupyterLab configuration, the stored secret will be removed from the database.</p>"},{"location":"users/jupyterlab/customdockerimage/#user-data","title":"User data","text":"<p>The mount path for your persistent storage is optional and configurable. This flexibility ensures that the storage location does not interfere with the specific requirements of the Docker image you provide. You can easily adapt the mounting path to suit your environment, allowing for a seamless integration of your custom setup.</p>"},{"location":"users/jupyterlab/default/","title":"JupyterLab","text":""},{"location":"users/jupyterlab/default/#systems-available","title":"Systems Available","text":"<p>JupyterLab default version is available on these systems:</p> <ul> <li>deNBI-Cloud</li> <li>JSC-Cloud</li> </ul> <p>Files in <code>/home/jovyan</code> are stored persistently. Everything else will be lost after a restart.</p>"},{"location":"users/jupyterlab/default/#environment","title":"Environment","text":"<p>The default environment for JupyterLab is based on the official jupyter/minimal-notebook.  </p>"},{"location":"users/jupyterlab/default/#kernel-customization","title":"Kernel customization","text":"<p>To use your own environment and packages it is recommended to use the Repo2Docker option, as this provides way more options and is easier to use. To install a new kernel in your running JupyterLab simply run: <pre><code>python -m ipykernel install --user --name mykernel --display-name \"MyKernel\"\n</code></pre></p> <p>This will create a kernelspec file at <code>/home/jovyan/.local/share/jupyter/kernels/mykernel/kernel.json</code>. You can update this, to use any environment you like to use.  </p>"},{"location":"users/jupyterlab/default/#use-own-virtualenv","title":"Use own virtualenv","text":"<pre><code>1. python3 -m venv /home/jovyan/.local/share/jupyter/kernels/venv_mykernel\n2. /home/jovyan/.local/share/jupyter/kernels/venv_mykernel/bin/pip install ipykernel  # ipykernel is required in each environment\n3. # Replace \"/opt/conda/bin/python\" in /home/jovyan/.local/share/jupyter/kernels/mykernel/kernel.json with \"/home/jovyan/.local/share/jupyter/kernels/venv_mykernel/bin/python\"\n4. Using \"MyKernel\" will then use the newly created python environment\n</code></pre>"},{"location":"users/jupyterlab/repo2docker/","title":"Repo2Docker ( Binder )","text":"<p>Jupyter4NFDI offers Repo2Docker ( Binder ), which facilitates building Docker images directly from GitHub, GitLab, Zenodo or other sources. This capability allows users to easily set up environments that replicate their local development setups or share projects with others. Combined with the Direct Links or the share Button, it allows you easily to create FAIR digital objects.</p>"},{"location":"users/jupyterlab/repo2docker/#direct-links","title":"Direct Links","text":"<p>Jupyter4NFDI enables you to create links that automatically start a JupyterLab instance using the provided parameters. For example: https://hub.nfdi-jupyter.de/v2/gh/binder-examples/requirements/HEAD.  </p> <p>The general structure for these direct links is: <code>https://hub.nfdi-jupyter.de/v2/_repotype_/_repoowner_/_reponame_/_ref_</code></p> <p>In case you would like to add a badge to your Repository or Documentation:  </p> <pre><code>Markdown:\n[![NFDI](https://nfdi-jupyter.de/images/nfdi_badge.svg)](https://hub.nfdi-jupyter.de/v2/gh/_repoowner_/_repotype_/_ref_)\n\nRST:\n.. image:: https://nfdi-jupyter.de/images/nfdi_badge.svg\n :target: https://hub.nfdi-jupyter.de/v2/gh/_repoowner_/_repotype_/_ref_\n</code></pre> <pre><code>Markdown:\n[![Jupyter4NFDI](https://nfdi-jupyter.de/images/jupyter4nfdi_badge.svg)](https://hub.nfdi-jupyter.de/v2/gh/_repoowner_/_repotype_/_ref_)\n\n\nRST:\n.. image:: https://nfdi-jupyter.de/images/jupyter4nfdi_badge.svg\n :target: https://hub.nfdi-jupyter.de/v2/gh/_repoowner_/_repotype_/_ref_\n</code></pre>"},{"location":"users/jupyterlab/repo2docker/#parameters-in-the-link","title":"Parameters in the Link","text":"Parameter Description <code>_repotype_</code> Specifies the type of repository. <code>_repoowner_</code> Identifies the owner of the repository (e.g., an organization or username). <code>_reponame_</code> The name of the repository containing the JupyterLab resources. <code>_ref_</code> The branch, tag, or commit hash to use in the repository (e.g. <code>HEAD</code>, <code>main</code> or <code>requirements</code>)."},{"location":"users/jupyterlab/repo2docker/#query-arguments-in-the-link","title":"Query Arguments in the Link","text":"<p>The link also supports several optional query arguments to unlock additional features:</p> Parameter Description <code>labpath</code> Add a path (relative or absolute) to a file which will be opened when starting the session. Important: The path must be URL-encoded. For example, <code>/home/jovyan/README.md</code> should be written as <code>%2Fhome%2Fjovyan%2FREADME.md</code>. <code>urlpath</code> Add a path to a url in your JupyterLab which will be opened when starting the sessions - e.g <code>voila</code>. Important: The path must be URL-encoded. <code>system</code> Specifies the system on which to start the repository. Default: Any system available to the user. <code>localstoragepath</code> Mounts the user's persistent storage on the selected system into the running session. Important: The path must be URL-encoded. For example, <code>/home/jovyan/work</code> should be written as <code>%2Fhome%2Fjovyan%2Fwork</code>. <code>flavor</code> Defines a specific flavor for the session. The availability of flavors depends on the selected system. If unsure, consult technical support. <p>Example: https://hub.nfdi-jupyter.de/v2/gh/binder-examples/requirements/HEAD?localstoragepath=%2Fhome%2Fjovyan%2Fwork</p>"},{"location":"users/jupyterlab/repo2docker/#comparison-with-mybinder","title":"Comparison with MyBinder","text":"<p>The Direct Link feature is inspired by MyBinder and utilizes the same backend. However, by incorporating authentication, we can offer persistent storage, unlocking new capabilities.</p> <p>Unlike MyBinder, the data persists even after closing the browser window or revisiting the link at a later time\u2014whether it's two days or two weeks later.</p>"},{"location":"users/jupyterlab/repo2docker/#empowering-workshop-instructors","title":"Empowering Workshop Instructors","text":"<p>Workshop instructors can prepare their content on GitHub, and participants can easily access it by following a link like: https://hub.nfdi-jupyter.de/v2/gh/repoowner/repo/HEAD?localstoragepath=%2Fhome%2Fjovyan%2Fwork.</p> <p>With the Direct Link feature, workshop instructors gain the ability to: - Prepare Workshops in Advance: Instructors can set up their workshops ahead of time using GitHub, allowing participants to easily access the environment without additional setup. - Seamless Access for Participants: Attendees can join the workshop simply by clicking the prepared link, instantly accessing the environment with all resources loaded. - Persistent Data: Unlike MyBinder, where sessions are ephemeral, the data in the session persists even after the browser is closed, ensuring participants can pick up where they left off\u2014making it ideal for multi-day or follow-up workshops. - Custom Environments: Instructors can tailor the workshop environment to their specific needs, ensuring that all participants have the same setup and access to necessary resources.  </p> <p>This capability provides instructors with a streamlined, hassle-free experience when hosting workshops, and it enhances the overall learning experience for participants.</p>"},{"location":"users/jupyterlab/repo2docker/#more-to-come","title":"More to Come","text":"<p>In the future, we plan to introduce the option to mount external data storage locations, such as S3 buckets, directly into the running container. This feature will expand the potential for advanced data analysis and visualization.</p> <p>The ability to mount external storage opens up several exciting possibilities: - Separation of Data and Code: Users can keep their datasets in external storage while maintaining their code repositories separately, enabling better modularity and flexibility. - Scalable Data Access: Large datasets can remain in optimized external storage systems without requiring local copies, reducing resource usage and improving scalability. - Collaboration: Multiple users can access the same external datasets, making collaborative projects more streamlined. - Real-Time Updates: Changes to the external storage (e.g., updated data in an S3 bucket) can be reflected immediately in the container, supporting dynamic workflows.  </p> <p>These features will empower users to work more efficiently and tackle complex data workflows with ease.  </p>"},{"location":"users/jupyterlab/repo2docker/#systems-available","title":"Systems Available","text":"<p>Repo2Docker ( Binder ) is available on these systems:</p> <ul> <li>deNBI-Cloud</li> <li>JSC-Cloud</li> </ul>"},{"location":"users/jupyterlab/repo2docker/#options","title":"Options","text":""},{"location":"users/jupyterlab/repo2docker/#repository-type","title":"Repository Type","text":"<ul> <li>Description: Select the type of repository where your project is hosted. Currently only GitHub is supported. Other options will be added in the future:</li> <li>GitHub: The most common choice for code repositories.</li> <li>Purpose: This determines how Repo2Docker connects to and retrieves your repository content.</li> </ul>"},{"location":"users/jupyterlab/repo2docker/#url","title":"URL","text":"<ul> <li>Description: Enter the full URL of your repository. For GitHub, this is typically in the format <code>https://github.com/username/repository-name</code>.</li> <li>Purpose: This is the source that Repo2Docker will use to build your containerized environment. Make sure the URL is accessible and public or configured for access.</li> </ul>"},{"location":"users/jupyterlab/repo2docker/#git-ref","title":"Git Ref","text":"<ul> <li>Description: Specify a reference for the desired version of your repository.</li> <li>Branch name: e.g., <code>main</code>, <code>dev</code></li> <li>Tag: Use release tags, such as <code>v1.0</code></li> <li>Commit hash: Input a specific commit ID, useful for precise versions</li> <li>Custom references: Use <code>HEAD~n</code> or <code>@~n</code> to go back <code>n</code> commits from the latest commit.</li> <li>Purpose: Allows you to control exactly which version of the repository is used, ensuring reproducibility.</li> </ul>"},{"location":"users/jupyterlab/repo2docker/#path-to-a-notebook-file-or-url","title":"Path to a Notebook File or URL","text":"<ul> <li>Description: Optionally, provide the path to a specific notebook file within your repository, e.g. <code>notebooks/example.ipynb</code>, or a URL, e.g. <code>voila</code>/<code>doc/tree/example.ipynb</code>, to open.</li> <li>Purpose: If filled, the specified notebook will open automatically once the environment is launched, simplifying access to a main file.</li> </ul>"},{"location":"users/jupyterlab/repo2docker/#persistence-and-shared-environments","title":"Persistence and Shared Environments","text":"<p>Changes made within the running JupyterLab environment are persistent, if <code>Mount user data</code> is enbaled in the JupyterLab configuration. All files outside of the <code>Mount user data</code> directory are lost after a restart. </p> <ul> <li>No Shared State: If you share a link to your environment, other users who start a JupyterLab session from that link will see the repository's original content, not any changes you\u2019ve made in your session.</li> </ul>"},{"location":"users/others/Howto-load-additional-software-modules/","title":"Howto load additional software modules","text":"Author: Jens Henrik G\u00f6bbert Index Create your own Jupyter Kernel <p>Let's skip the pink box for now, as it is only relevant if we want to discuss authentication and authorization with Jupyter4NFDI. Hence, the pink box can be a \"black box\" for now.</p> <p>Just focus on</p> <ul> <li>JupyterLab (JavaScript/HTML in the browser) - the front-end</li> <li>Jupyter Notebook Server (Python on the hpc cluster) - the back-end</li> <li>JupyterLab Kernel (any language the kernel is made for)</li> </ul> <p>JupyterLab is made of a front-end running in your browser using JavaScript+HTML. This is the actual user interface - one could say that its purpose is nothing else than making JupyterLab visible to you and a back-end running on any machine your browser can connect to. This back-end machine can be the same machine the browser runs on, it can be a cloud server or -in our case - the hpc cluster.</p> <p>The actual code cells of your Jupyter notebook are executed in a separate process called Jupyter Kernel. The Jupyter Kernel runs in a complete separate shell and communicates with the Jupyter Notebook Server through a protocol with Jupyter-specific messages.</p> Attention: If you want to use a software module in your Jupyter Notebook, it must be loaded in the Jupyter Kernel's shell/environment.  <p>There are multiple ways to load software modules into the shell/environment of the Jupyter Kernel. Prioritized by best approach, the options are as follows:</p> <ul> <li>create your own Jupyter Kernel</li> <li>use the lmod extension</li> <li>load the software module before starting JupyterLab</li> <li>(restart the Jupyter Kernel's process with new environment settings)</li> </ul>"},{"location":"users/others/Howto-load-additional-software-modules/#how-to-load-additional-software-modules","title":"How to load additional software modules?\u00b6","text":"<p>lmod provides on our HPC systems a convenient way to dynamically change the users\u2019 environment. This includes easily adding or removing directories listed in environment variables like PATH or LD_LIBRARY_PATH. It is a common approach on high-performance clusters to manage/install/load software packages in multiple versions/optimizations/architectures on the same machine. If you login to a terminal you can easily load additional modules with <code>module load &lt;name&gt;</code> (for more details please read our documentation on software modules).</p> <p>But how can you make use of these installed software modules in a Jupyter environment?</p>"},{"location":"users/others/Howto-load-additional-software-modules/#introduction","title":"Introduction\u00b6","text":""},{"location":"users/others/Howto-load-additional-software-modules/#the-classical-approach-in-the-terminal","title":"The classical approach in the terminal\u00b6","text":"<p>If you want to use functionality of a certain software module it can mean that you need</p> <ul> <li>the path to its executables to be in the PATH environment variable.</li> <li>the path to its libraries to be in the LD_LIBRARY_PATH environment variable.</li> <li>the path to its python packages to be in the PYTHON_PATH environment variable.</li> <li>or any other software module specific environment variables to be set.</li> </ul> <p>In any case, running <code>module load &lt;name&gt;</code> in a terminal would ensure exactly that. It modifies the environment of the current shell, which ensures that you can use the software of the loaded modules.</p> <p>But with Jupyter this is a bit different.</p>"},{"location":"users/others/Howto-load-additional-software-modules/#why-is-jupyter-different-when-it-comes-to-loading-of-software-modules","title":"Why is Jupyter different when it comes to loading of software modules?\u00b6","text":""},{"location":"users/others/Howto-load-additional-software-modules/#jupyters-architecture","title":"Jupyter's architecture\u00b6","text":"<p>To understand how we can make additional software modules available in our Jupyter notebooks, we need to understand the basic software architecture of Jupyter first. </p>"},{"location":"users/others/Howto-load-additional-software-modules/#create-your-own-kernel","title":"Create your own kernel\u00b6","text":"<p>If the standard kernels do not provide all software modules you need for your work, you can create your own Jupyter Kernel and load the needed software modules before you start it.</p> Solution \"own kernel\": A Jupyter kernel is described in principle by no more than a JSON file. There you will find the command call that starts the kernel.   This command call can easily be a script, which calls a few extra `module load &lt;..&gt;` before.  <p>A detailed tutorial on how to build your own Jupyter Python kernel can be found here:</p> <ul> <li>using pip</li> <li>using conda</li> </ul> <p>It does not take longer than a few minutes and you are ready to go.</p>"},{"location":"users/others/Howto-load-additional-software-modules/#lmod-extension","title":"lmod extension\u00b6","text":"<p>The lmod extension allows users to load/unload software modules before launching kernels. You can find its UI in the left sidebar.</p> <p>A Jupyter Kernel copies the environment variables of the Jupyter Notebook Server to its own separate shell when it starts up. The extension takes advantage of that and modifies the current environment of the Jupyter Notebook Server.</p> Attention \"lmod\": - you need to use the lmod extension before launching kernels - changes also affect the environment of the running Jupyter Notebook Server (this can have side-effects) - a Jupyter kernel can purge its environment and therefore ignore the environment variables of the Jupyter Notebook Server (module purge)"},{"location":"users/others/Howto-load-additional-software-modules/#load-software-modules-before-starting-jupyterlab","title":"Load software modules before starting JupyterLab\u00b6","text":"<p>As you already know from the description above on the lmod extention: A Jupyter Kernel copies the environment variables of the Jupyter Notebook Server to its own separate shell when it starts up.</p> <p>Therefor, any software module loaded in the Jupyter Notebook Server's environment will likely be available in a standard Jupyter Kernel, too. If you have ensured that the extra software modules are loaded before JupyterLab is started.</p> <p>But Jupyter4NFDI hides the startup of JupyterLab - it loads modules and starts JupyterLab in the background. Luckily we allow you to modify this startup through the file <code>$HOME/jupyter/start_jupyter-jsc.sh</code>.</p> <p>If Jupyter4NFDI find the file <code>$HOME/jupyter/start_jupyter-jsc.sh</code> it sources this file instead of loading the default environment. Hence, you are free to load extra software modules there. Attention: do not forget to load the needed Jupyter modules, too.</p> <pre>module purge\nmodule use $OTHERSTAGES\nmodule load Stages/2020\nmodule load GCCcore/.9.3.0\nmodule load JupyterCollection/2020.2.6\n\nmodule load &lt;...&gt;\n</pre> Attention \"modify startup\": - the software modules are loaded every time - any change needs a restart of your JupyterLab - running multiple conflicting environments is impossible - changes also affect the environment of the running Jupyter Notebook Server (this can have side-effects) - a Jupyter kernel can purge its environment and therefore ignore the environment variables of the Jupyter Notebook Server (module purge) - you do not use the default JupyterLab environment and therefore will not see any updates and new features coming in the future"},{"location":"users/others/Howto-load-additional-software-modules/#restart-the-jupyter-kernels-process-from-within-the-jupyter-notebook","title":"Restart the Jupyter Kernel's process from within the Jupyter notebook\u00b6","text":"<p>If you love to live dangerously, then you can also secretly change the environment of a running Jupyter Kernel's environment. At least for Python there is a way to ask the current running Python interpreter to restart itself within a new/modified environment.</p> <p>Please check this howto for details: tricks with os.execve</p> Attention \"os.execve\": - only works with Python - is more a hack than a solution - \"pollutes\" the first code cells of your Jupyter notebooks the hack's commands"},{"location":"users/others/Markdown_Tipps-and-Tricks/","title":"Markdown Tipps &amp; Tricks (for Jupyter Notebook)","text":"Author: Jens Henrik G\u00f6bbert Index Markdown Tipps &amp; Tricks (for Jupyter Notebook) <p>This text will be italic This will also be italic</p> <p>This text will be bold This will also be bold</p> <p>You can combine them</p> <pre><code>code\n*This text will be italic*  \n_This will also be italic_  \n\n**This text will be bold**  \n__This will also be bold__  \n\n_You **can** combine them_  \n</code></pre> <p>This is a blockquote</p> <pre><code>code\n&gt; This is a blockquote\n</code></pre> <ul> <li>selected item</li> <li>unselected item</li> </ul> <pre>* [x] selected item  \n* [ ] unselected item\n</pre> <ul> <li>One simple way of adding an image to a Markdown cell is through the following syntax</li> <li>If you want to add a hover title to the image then you can simply add it at the end</li> </ul> <p></p> <pre>![](https://www.python.org/static/community_logos/python-logo-master-v3-TM.png \"Python Logo\")\n</pre> <ul> <li>You can also use the reference-style format for the images:</li> </ul> <p></p> <pre>![][some-id]\n\n[some-id]: https://www.python.org/static/community_logos/python-logo-master-v3-TM.png \"Python Logo\"\n</pre> <ul> <li>You can also control the size of the image and its position </li> </ul> <pre>&lt;div&gt;\n  &lt;img src=https://www.python.org/static/community_logos/python-logo-master-v3-TM.png title=\"Python Logo\" width=\"120\" style=\"float:left\"/&gt;\n  &lt;img src=https://www.python.org/static/community_logos/python-logo-master-v3-TM.png title=\"Python Logo\" width=\"240\" style=\"float:center\"/&gt;\n  &lt;img src=https://www.python.org/static/community_logos/python-logo-master-v3-TM.png title=\"Python Logo\" width=\"360\" style=\"float:right\"/&gt;\n&lt;/div&gt;\n</pre> <ul> <li>Drop-in image You can attach an image (or animated gif) to the notebook and make it part of the .ipynb file. Simply drag-and-drop it to the notebook. ATTENTION The image will be stored in the notebook. If you do not reference to them any more they will automatically be removed from the notebook!</li> </ul> <p></p> <pre><code>code\n![mind_blown.gif](attachment:23203f8f-980e-4dc6-a95d-fbaa16e37477.gif)\n</code></pre> Tip: Use blue boxes (alert-info) for tips and notes.  <pre>&lt;div class=\"alert alert-block alert-info\"&gt;\n&lt;b&gt;Tip:&lt;/b&gt;\nUse blue boxes (alert-info) for tips and notes.\n&lt;/div&gt;\n</pre> Example: Use yellow boxes for examples that are not inside code cells, or use for mathematical formulas if needed. Typically also used to display warning messages.  <pre>&lt;div class=\"alert alert-block alert-warning\"&gt;\n&lt;b&gt;Example:&lt;/b&gt;\nUse yellow boxes for examples that are not inside code cells, or use for mathematical formulas if needed.\nTypically also used to display warning messages.\n&lt;/div&gt;\n</pre> Success: This alert box indicates a successful or positive action.  <pre>&lt;div class=\"alert alert-block alert-success\"&gt;\n&lt;b&gt;Success:&lt;/b&gt;\nThis alert box indicates a successful or positive action.\n&lt;/div&gt;\n</pre>  \"alert alert-secondary\" role=\"alert\" Danger: This alert box indicates a dangerous or potentially negative action.  <pre>&lt;div class=\"alert alert-block alert-danger\"&gt;\n&lt;b&gt;Danger:&lt;/b&gt;\nThis alert box indicates a dangerous or potentially negative action.\n&lt;/div&gt;\n</pre> <code> Useful for highlighting to grab the attention of the reader towards certain points. </code> <pre>&lt;code style=\"background:yellow;color:black\"&gt;\nUseful for highlighting to grab the attention of the reader towards certain points.\n&lt;/code&gt;\n</pre> <p>Do not forget to buy milk today.</p> <pre>Do not forget to buy &lt;mark&gt;milk&lt;/mark&gt; today.\n</pre> <p>I also tend to use the following color style when adding a piece of terminal code to a Markdown cell:</p> <p> <code>C:\\Users\\YOUR_USERNAME&gt; pip3 install roughviz</code> </p> <pre>&lt;p style=\"background:black\"&gt;\n&lt;code style=\"background:black;color:white\"&gt;C:\\Users\\YOUR_USERNAME&gt; pip3 install roughviz&lt;/code&gt;\n&lt;/p&gt;\n</pre> <p> </p> <pre>&lt;video controls=\"controls\"\n       src=\"https://test-videos.co.uk/vids/bigbuckbunny/mp4/h264/720/Big_Buck_Bunny_720_10s_1MB.mp4\" \n       poster=\"https://upload.wikimedia.org/wikipedia/commons/2/2b/Big.Buck.Bunny.-.Frank.Rinky.Gimera.png\"\n       width=\"640\" height=\"360\" type=\"video/mp4\"&gt;\n    &lt;img alt=\"HTML5 MP4/H.264 Video\" \n         src=\"https://upload.wikimedia.org/wikipedia/commons/2/2b/Big.Buck.Bunny.-.Frank.Rinky.Gimera.png\" \n         title=\"No video playback capabilities\" \n         width=\"640\" height=\"360\"&gt;\n&lt;/video&gt;\n</pre> <ul> <li>YouTubes Videos</li> </ul> In\u00a0[4]: Copied! <pre>from IPython.display import YouTubeVideo\nYouTubeVideo('1j_HxD4iLn8', height=480, width=640, start=30)\n</pre> from IPython.display import YouTubeVideo YouTubeVideo('1j_HxD4iLn8', height=480, width=640, start=30) Out[4]: <ul> <li>HTPS-Webpages</li> </ul> In\u00a0[5]: Copied! <pre>from IPython.display import IFrame\nIFrame('https://en.wikipedia.org/wiki/HTTPS', width=800, height=450)\n</pre> from IPython.display import IFrame IFrame('https://en.wikipedia.org/wiki/HTTPS', width=800, height=450) Out[5]: <ul> <li>PDFs</li> </ul> In\u00a0[6]: Copied! <pre>from IPython.display import IFrame\nIFrame('https://arxiv.org/pdf/1406.2661.pdf', width=800, height=450)\n</pre> from IPython.display import IFrame IFrame('https://arxiv.org/pdf/1406.2661.pdf', width=800, height=450) Out[6]:"},{"location":"users/others/Markdown_Tipps-and-Tricks/#markdown-tipps-tricks-for-jupyter-notebook","title":"Markdown Tipps &amp; Tricks (for Jupyter Notebook)\u00b6","text":"<p>Markdown writing skills are essential to portray your work in the Jupyter notebook to offer the reader a sufficient explanation of both the code and the concept.</p> <p>I have collected informations for different sources. Thanks to them!</p> <ul> <li>Jupyter Notebook Dokumentation</li> <li>The Ultimate Markdown Guide for Jupyter Notebooks</li> <li>Daring Fireball\u00b4s Markdown documentation</li> <li>Bringing the Best out of Jupyter Notebooks</li> </ul>"},{"location":"users/others/Markdown_Tipps-and-Tricks/#whats-markdown","title":"What\u2019s Markdown?\u00b6","text":"<p>Markdown is a light markup language with a simple text syntax. Markdown should be easy to write and above all easy to read. John Gruber developed the Markdown language in 2004 in collaboration with Aaron Swartz with the goal of enabling people to \"write in an easy to read and easy to write plain text format and possibly convert it to structurally correct XHTML (or HTML)\". However, one should not assume that \"Markdown\" is a substitute for HTML. HTML is a format for publishing, while Markdown is a format for reading. The syntax of markup is minimal and only applies to a tiny portion of HTML tags. The idea of Markdown is to make it easier to read, write and edit prose, without the intention of creating a syntax that only serves to quickly add HTML tags. Therefore, the formatting syntax of Markdown deals only with questions that can be expressed in plain text. For everything else, use HTML. You don't have to make any preamble or delimitation to indicate that you are switching from Markdown to HTML - you simply use the tags.</p> <p>The following examples start with some simple examples and then show some not so common tricks. Have fun with them!</p>"},{"location":"users/others/Markdown_Tipps-and-Tricks/#emphasis","title":"EMPHASIS\u00b6","text":""},{"location":"users/others/Markdown_Tipps-and-Tricks/#blockquotes","title":"BLOCKQUOTES \u00b6","text":"<p>Blockquotes can hold the large chunk of text and are generally indented.</p>"},{"location":"users/others/Markdown_Tipps-and-Tricks/#task-lists","title":"TASK LISTS\u00b6","text":"<p>I have to admit, tasks lists are my favorite.</p>"},{"location":"users/others/Markdown_Tipps-and-Tricks/#graphics","title":"GRAPHICS\u00b6","text":"<p>You can attach graphics (such as images) to a notebook in Markdown cells.</p> <p>Note1: You can also Drag and Drop your images to the Markdown cell to attach it to the notebook.</p> <p>Note2: Below I have used links to images on the web but you can very well use an offline image by adding the complete filename (plus the file path if it is in a different directory other then the Jupyter Notebook).</p>"},{"location":"users/others/Markdown_Tipps-and-Tricks/#colored-note-boxes","title":"COLORED NOTE BOXES\u00b6","text":"<p>Use one of the following <code>&lt;div&gt;</code> tags to display text in a colored box. The color of the box is determined by the alert type that is specified.</p>"},{"location":"users/others/Markdown_Tipps-and-Tricks/#cell-background-color","title":"CELL BACKGROUND COLOR\u00b6","text":""},{"location":"users/others/Markdown_Tipps-and-Tricks/#videos","title":"VIDEOS\u00b6","text":""},{"location":"users/others/Markdown_Tipps-and-Tricks/#embedding-content-using-python","title":"EMBEDDING CONTENT USING PYTHON\u00b6","text":""},{"location":"users/others/install-singularity-jupyter-kernel/","title":"Install singularity jupyter kernel","text":"Author: Katharina H\u00f6flich Index Install containerized Jupyter kernel at Jupyter4NFDI <p>This Jupyter notebook will walk you through the installation of a containerized Jupyter kernel (for use at Jupyter4NFDI, but it should actually work with any Jupyter server on a system where Singularity is installed). Considerable performance improvements (especially with respect to kernel start-up times) over e.g. conda-based Jupyter kernels on distributed filesystems, as are typically installed on HPC systems, might be experienced. In the example below, the <code>base-notebook</code> from the Jupyter docker stacks is used as an IPython kernel (already having the required <code>ipykernel</code> package installed), the approach presented here might be extended to any other Jupyter kernel compatible programming language, though.</p> <p>Requirements:</p> <ul> <li>Python environment with an installed <code>ipykernel</code> package in a Docker (or Singularity) container</li> <li><code>container</code> group access for the JSC systems as described here in the docs</li> </ul> <p>Check that the Singularity container runtime is available via the JupyterLab environment,</p> In\u00a0[1]: Copied! <pre>singularity --version\n</pre> singularity --version <pre>singularity version 3.6.4-1.el8\n</pre> <p>Specify the filesystem location that stores the Singularity container image,</p> In\u00a0[2]: Copied! <pre>IMAGE_TARGET_DIR=/p/project/cesmtst/hoeflich1/jupyter-base-notebook\n</pre> IMAGE_TARGET_DIR=/p/project/cesmtst/hoeflich1/jupyter-base-notebook <p>Optional, if you already have a Singularity container image available at the above location: Convert a containerized Python environment (e.g. the Jupyter <code>base-notebook</code> that is available via Dockerhub) into a Singularity container image to be used as an example here,</p> In\u00a0[3]: Copied! <pre>mkdir -p ${IMAGE_TARGET_DIR}\n</pre> mkdir -p ${IMAGE_TARGET_DIR} <p>Note that pulling and converting the Dockerhub image will take a bit of time,</p> In\u00a0[4]: Copied! <pre>singularity pull ${IMAGE_TARGET_DIR}/jupyter-base-notebook.sif docker://jupyter/base-notebook &amp;&gt; singularity.log\n</pre> singularity pull ${IMAGE_TARGET_DIR}/jupyter-base-notebook.sif docker://jupyter/base-notebook &amp;&gt; singularity.log In\u00a0[5]: Copied! <pre>cat singularity.log | grep -v warn\n</pre> cat singularity.log | grep -v warn <pre>INFO:    Converting OCI blobs to SIF format\nINFO:    Starting build...\nGetting image source signatures\nCopying blob sha256:da7391352a9bb76b292a568c066aa4c3cbae8d494e6a3c68e3c596d34f7c75f8\nCopying blob sha256:14428a6d4bcdba49a64127900a0691fb00a3f329aced25eb77e3b65646638f8d\nCopying blob sha256:2c2d948710f21ad82dce71743b1654b45acb5c059cf5c19da491582cef6f2601\nCopying blob sha256:e3cbfeece0aec396b6793a798ed1b2aed3ef8f8693cc9b3036df537c1f8e34a1\nCopying blob sha256:48bd2a353bd8ed1ad4b841de108ae42bccecc44b3f05c3fcada8a2a6f5fa09cf\nCopying blob sha256:235d93b8ccf12e8378784dc15c5bd0cb08ff128d61b856d32026c5a533ac3c89\nCopying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1\nCopying blob sha256:b6c06056c45bc1da74604fcf368b02794fe4e36dcae881f4c6b4fa32b37a1385\nCopying blob sha256:60918bcbe6d44988e4e48db436996106cc7569a4b880488be9cac90ea6883ae0\nCopying blob sha256:762f9ebe4ddc05e56e33f7aba2cdd1be62f747ecd9c8f9eadcb379debf3ebe06\nCopying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1\nCopying blob sha256:1df9d491a0390ecc3f9fac4484c92b2a5f71a79450017f2fca1849f2d6e7f949\nCopying blob sha256:be84c8c720e3c53037ac2c5cbc53cf9a2a674503b2c995da1351e5560f60cc12\nCopying blob sha256:28807e96859dc8c00c96255dfa51a0822380638a092803e7143473d1870970fb\nCopying blob sha256:bcdaf848f29a8bf0efc18a5883dc65a4a7a6b2c6cf4094e5115188ed22165a00\nCopying blob sha256:49777cff52f155a9ba35e58102ecec7029dddf52aa4947f2cffbd1af12848e81\nCopying blob sha256:7fb3bffa2e730b052c0c7aabd715303cc5830a05b992f2d3d70afeffa0a9ed4f\nCopying blob sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1\nCopying config sha256:79f074439b14ae0634f2f217e5debc159c4e8c3a9ff2e0119e4dc88f9c7e21a5\nWriting manifest to image destination\nStoring signatures\n2021/01/19 11:59:33  info unpack layer: sha256:da7391352a9bb76b292a568c066aa4c3cbae8d494e6a3c68e3c596d34f7c75f8\n2021/01/19 11:59:34  info unpack layer: sha256:14428a6d4bcdba49a64127900a0691fb00a3f329aced25eb77e3b65646638f8d\n2021/01/19 11:59:34  info unpack layer: sha256:2c2d948710f21ad82dce71743b1654b45acb5c059cf5c19da491582cef6f2601\n2021/01/19 11:59:34  info unpack layer: sha256:e3cbfeece0aec396b6793a798ed1b2aed3ef8f8693cc9b3036df537c1f8e34a1\n2021/01/19 11:59:34  info unpack layer: sha256:48bd2a353bd8ed1ad4b841de108ae42bccecc44b3f05c3fcada8a2a6f5fa09cf\n2021/01/19 11:59:34  info unpack layer: sha256:235d93b8ccf12e8378784dc15c5bd0cb08ff128d61b856d32026c5a533ac3c89\n2021/01/19 11:59:34  info unpack layer: sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1\n2021/01/19 11:59:34  info unpack layer: sha256:b6c06056c45bc1da74604fcf368b02794fe4e36dcae881f4c6b4fa32b37a1385\n2021/01/19 11:59:34  info unpack layer: sha256:60918bcbe6d44988e4e48db436996106cc7569a4b880488be9cac90ea6883ae0\n2021/01/19 11:59:34  info unpack layer: sha256:762f9ebe4ddc05e56e33f7aba2cdd1be62f747ecd9c8f9eadcb379debf3ebe06\n2021/01/19 11:59:34  info unpack layer: sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1\n2021/01/19 11:59:34  info unpack layer: sha256:1df9d491a0390ecc3f9fac4484c92b2a5f71a79450017f2fca1849f2d6e7f949\n2021/01/19 11:59:36  info unpack layer: sha256:be84c8c720e3c53037ac2c5cbc53cf9a2a674503b2c995da1351e5560f60cc12\n2021/01/19 11:59:40  info unpack layer: sha256:28807e96859dc8c00c96255dfa51a0822380638a092803e7143473d1870970fb\n2021/01/19 11:59:40  info unpack layer: sha256:bcdaf848f29a8bf0efc18a5883dc65a4a7a6b2c6cf4094e5115188ed22165a00\n2021/01/19 11:59:40  info unpack layer: sha256:49777cff52f155a9ba35e58102ecec7029dddf52aa4947f2cffbd1af12848e81\n2021/01/19 11:59:40  info unpack layer: sha256:7fb3bffa2e730b052c0c7aabd715303cc5830a05b992f2d3d70afeffa0a9ed4f\n2021/01/19 11:59:40  info unpack layer: sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1\nINFO:    Creating SIF file...\n</pre> <p>Check that the Singularity image is available,</p> In\u00a0[6]: Copied! <pre>ls -lah ${IMAGE_TARGET_DIR}\n</pre> ls -lah ${IMAGE_TARGET_DIR} <pre>total 177M\ndrwxr-sr-x 2 hoeflich1 cesmtst 4.0K Jan 19 11:59 .\ndrwxr-sr-x 5 hoeflich1 cesmtst 4.0K Jan 19 11:59 ..\n-rwxr-xr-x 1 hoeflich1 cesmtst 183M Jan 19 11:59 jupyter-base-notebook.sif\n</pre> <p>Now, setup a Jupyter kernel specification with the <code>install-jupyter-kernel.sh</code> script from this repository (which basically writes a <code>kernel.json</code> file to the home directory location that Jupyter expects for user-specific kernels),</p> In\u00a0[7]: Copied! <pre>KERNEL_DISPLAY_NAME=Singularity-Python # don't use whitespaces here!\nSINGULARITY_IMAGE=${IMAGE_TARGET_DIR}/jupyter-base-notebook.sif\n</pre> KERNEL_DISPLAY_NAME=Singularity-Python # don't use whitespaces here! SINGULARITY_IMAGE=${IMAGE_TARGET_DIR}/jupyter-base-notebook.sif <p>Link to install-singularity-jupyter-kernel.sh</p> In\u00a0[8]: Copied! <pre>./install-singularity-jupyter-kernel.sh ${KERNEL_DISPLAY_NAME} ${SINGULARITY_IMAGE}\n</pre> ./install-singularity-jupyter-kernel.sh ${KERNEL_DISPLAY_NAME} ${SINGULARITY_IMAGE} <p>Check that the Jupyter kernel specification was written,</p> In\u00a0[9]: Copied! <pre>cat ${HOME}/.local/share/jupyter/kernels/${KERNEL_DISPLAY_NAME}/kernel.json\n</pre> cat ${HOME}/.local/share/jupyter/kernels/${KERNEL_DISPLAY_NAME}/kernel.json <pre>{\n \"argv\": [\n   \"singularity\",\n   \"exec\",\n   \"--cleanenv\",\n   \"/p/project/cesmtst/hoeflich1/jupyter-base-notebook/jupyter-base-notebook.sif\",\n   \"python\",\n   \"-m\",\n   \"ipykernel\",\n   \"-f\",\n   \"{connection_file}\"\n ],\n \"language\": \"python\",\n \"display_name\": \"Singularity-Python\"\n}\n</pre> <p>And that the above Singularity-Python kernel is visible by the Jupyter server,</p> In\u00a0[10]: Copied! <pre>jupyter kernelspec list\n</pre> jupyter kernelspec list <pre>Available kernels:\n  singularity-python    /p/home/jusers/hoeflich1/juwels/.local/share/jupyter/kernels/Singularity-Python\n  ruby                  /p/software/juwels/stages/Devel-2019a/software/JupyterKernel-Ruby/2.6.3-gcccoremkl-8.3.0-2019.3.199-2019a.2.4/share/jupyter/kernels/ruby\n  ir35                  /p/software/juwels/stages/Devel-2019a/software/JupyterKernel-R/3.5.3-gcccoremkl-8.3.0-2019.3.199-2019a.2.4/share/jupyter/kernels/ir35\n  pyquantum-1.0         /p/software/juwels/stages/Devel-2019a/software/JupyterKernel-PyQuantum/1.0-gcccoremkl-8.3.0-2019.3.199-2019a.2.4/share/jupyter/kernels/pyquantum-1.0\n  pyparaview-5.8        /p/software/juwels/stages/Devel-2019a/software/JupyterKernel-PyParaView/5.8.0-gcccoremkl-8.3.0-2019.3.199-2019a.2.4/share/jupyter/kernels/pyparaview-5.8\n  octave                /p/software/juwels/stages/Devel-2019a/software/JupyterKernel-Octave/5.1.0-gcccoremkl-8.3.0-2019.3.199-2019a.2.4/share/jupyter/kernels/octave\n  julia-1.4             /p/software/juwels/stages/Devel-2019a/software/JupyterKernel-Julia/1.4.2-gcccoremkl-8.3.0-2019.3.199-2019a.2.4/share/jupyter/kernels/julia-1.4\n  javascript            /p/software/juwels/stages/Devel-2019a/software/JupyterKernel-JavaScript/5.2.0-gcccoremkl-8.3.0-2019.3.199-2019a.2.4/share/jupyter/kernels/javascript\n  cling-cpp17           /p/software/juwels/stages/Devel-2019a/software/JupyterKernel-Cling/0.6-gcccoremkl-8.3.0-2019.3.199-2019a.2.4/share/jupyter/kernels/cling-cpp17\n  bash                  /p/software/juwels/stages/Devel-2019a/software/JupyterKernel-Bash/0.7.1-gcccoremkl-8.3.0-2019.3.199-2019a.2.4/share/jupyter/kernels/bash\n  python3               /p/software/juwels/stages/Devel-2019a/software/Jupyter/2019a.2.4-gcccoremkl-8.3.0-2019.3.199-Python-3.6.8/share/jupyter/kernels/python3\n</pre> <p>If so, you should be able to choose and connect to the containerized Python kernel from the drop down menu and/or the kernel launcher tab (a reload of the JupyterLab web page might be necessary).</p>"},{"location":"users/others/setup-singularity-jupyter-server/","title":"Setup singularity jupyter server","text":"Author: Katharina H\u00f6flich Index Setup containerized Jupyter server for Jupyter4NFDI <p>This Jupyter notebook will explain how to setup a containerized Jupyter server at Jupyter4NFDI. It makes use of the expert features described on page 22 (as of November 25th, 2020) of the training material available here. Please note, that setting up a containerized Jupyter server for the JupyterHub at JSC might introduce certain drawbacks to your Jupyter4NFDI experience. Specifically, you will be restricted to the software environment that is installed in your container environment only, which might introduce unwanted side-effects to your JupyterLab-based workflows on the JSC HPC systems. For example, usage of the SLURM batch scheduler commands is not possible, because the SLURM libraries are not visible from the container environment per default. Also, you won't be able to use the Lmod software environment modules provided by JSC. Please note, that if these kind of side-effects are not acceptable, you might rather use a containerized Jupyter kernel as described here. You could also setup your own non-containerized JupyterLab server.</p> <p>Please note, you can switch back to the default Jupyter4NFDI server environment anytime by deleting <code>$HOME/.jupyter/start_jupyter-jsc.sh</code> after login to the JSC systems via SSH.</p> <p>Requirements:</p> <ul> <li><code>container</code> group access for the JSC systems as described here in the docs</li> <li>Jupyter server environment in a Docker (or Singularity) container<ul> <li>install at least the python packages jupyterhub and jupyterlab.</li> </ul> </li> </ul> <p>Specify the filesystem location that stores the Singularity container image,</p> In\u00a0[1]: Copied! <pre>IMAGE_TARGET_DIR=/p/project/cesmtst/hoeflich1/jupyter-base-notebook\n</pre> IMAGE_TARGET_DIR=/p/project/cesmtst/hoeflich1/jupyter-base-notebook <p>Convert the example Jupyter base-notebook (that is available via Dockerhub) into a Singularity container image,</p> In\u00a0[2]: Copied! <pre>mkdir -p ${IMAGE_TARGET_DIR}\n</pre> mkdir -p ${IMAGE_TARGET_DIR} In\u00a0[3]: Copied! <pre>singularity pull --force ${IMAGE_TARGET_DIR}/jupyter-base-notebook.sif docker://jupyter/base-notebook &amp;&gt; singularity.log\n</pre> singularity pull --force ${IMAGE_TARGET_DIR}/jupyter-base-notebook.sif docker://jupyter/base-notebook &amp;&gt; singularity.log In\u00a0[4]: Copied! <pre>cat singularity.log | grep -v warn\n</pre> cat singularity.log | grep -v warn <pre>INFO:    Using cached SIF image\n</pre> <p>Check that the Singularity image is available,</p> In\u00a0[5]: Copied! <pre>ls -lah ${IMAGE_TARGET_DIR}\n</pre> ls -lah ${IMAGE_TARGET_DIR} <pre>total 177M\ndrwxr-sr-x 2 hoeflich1 cesmtst 4.0K Jan 19 18:50 .\ndrwxr-sr-x 5 hoeflich1 cesmtst 4.0K Jan 19 18:05 ..\n-rwxr-xr-x 1 hoeflich1 cesmtst 183M Jan 19 18:50 jupyter-base-notebook.sif\n</pre> <p>Now, manually (!) specify the Singularity image filesystem location in the <code>start_jupyter-jsc.sh</code> script and check that the specified path is correct,</p> In\u00a0[6]: Copied! <pre>cat start_jupyter-jsc.sh\n</pre> cat start_jupyter-jsc.sh <pre>#!/bin/bash\n\n# Author: Katharina H\u00f6flich\n# Repository: https://github.com/FZJ-JSC/jupyter-jsc-notebooks\n\nSINGULARITY_IMAGE=/p/project/cesmtst/hoeflich1/jupyter-base-notebook/jupyter-base-notebook.sif\nJUPYTERJSC_USER_CMD=\"singularity exec ${SINGULARITY_IMAGE} jupyterhub-singleuser --config ${JUPYTER_LOG_DIR}/config.py\"\n</pre> <p>And copy the <code>start_jupyter-jsc_singularity.sh</code> script to the filesystem location expected by Jupyter4NFDI (Link to start_jupyter-jsc_singularity.sh)</p> In\u00a0[\u00a0]: Copied! <pre>cp start_jupyter-jsc_singulartiy.sh $HOME/.jupyter/start_jupyter-jsc.sh\n</pre> cp start_jupyter-jsc_singulartiy.sh $HOME/.jupyter/start_jupyter-jsc.sh <p>Finally, opening a new Jupyter session via the Jupyter4NFDI control panel should now load the containerized Jupyter server that was setup here.</p>"}]}